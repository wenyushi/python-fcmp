{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swat import *\n",
    "import swat as sw\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\weshiz\\\\Documents\\\\GitHub\\\\modify\\\\python-dlpy')\n",
    "sys.path.append('C:\\\\Users\\\\weshiz\\\\Documents\\\\GitHub\\\\python-fcmp')\n",
    "from dlpy.layers import * \n",
    "from dlpy.applications import *\n",
    "from dlpy import Model, Sequential\n",
    "from dlpy.utils import *\n",
    "from dlpy.splitting import two_way_split\n",
    "from dlpy.images import *\n",
    "from dlpy.model import *\n",
    "from python_fcmp.parser import *\n",
    "from python_fcmp.decorator import *\n",
    "from python_fcmp import fcmp\n",
    "from dlpy.lr_scheduler import *\n",
    "from dlpy.network import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Added action set 'deeplearn'.\n",
      "NOTE: Added action set 'clustering'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; actionset</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>clustering</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00174s</span> &#183; <span class=\"cas-user\">user 0.00137s</span> &#183; <span class=\"cas-sys\">sys 0.000312s</span> &#183; <span class=\"cas-memory\">mem 0.209MB</span></small></p>"
      ],
      "text/plain": [
       "[actionset]\n",
       "\n",
       " 'clustering'\n",
       "\n",
       "+ Elapsed: 0.00174s, user: 0.00137s, sys: 0.000312s, mem: 0.209mb"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sw.CAS('dlgrd009', 13300)\n",
    "s.loadactionset('deeplearn')\n",
    "s.loadactionset('clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: 'CASUSER(weshiz)' is now the active caslib.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000262s</span> &#183; <span class=\"cas-user\">user 0.000106s</span> &#183; <span class=\"cas-sys\">sys 9.5e-05s</span> &#183; <span class=\"cas-memory\">mem 0.256MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.000262s, user: 0.000106s, sys: 9.5e-05s, mem: 0.256mb"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://go.documentation.sas.com/?docsetId=lesysoptsref&docsetTarget=n16rhscxem9ljwn1kuhn5170xkbg.htm&docsetVersion=9.4&locale=en\n",
    "s.sessionProp.setSessOpt(caslib='CASUSER', cmplib=\"CASUSER.fcmpfunction\", cmpopt=\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; CASLibInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Type\">Type</th>\n",
       "      <th title=\"Description\">Description</th>\n",
       "      <th title=\"Path\">Path</th>\n",
       "      <th title=\"Definition\">Definition</th>\n",
       "      <th title=\"Subdirs\">Subdirs</th>\n",
       "      <th title=\"Local\">Local</th>\n",
       "      <th title=\"Active\">Active</th>\n",
       "      <th title=\"Personal\">Personal</th>\n",
       "      <th title=\"Hidden\">Hidden</th>\n",
       "      <th title=\"Transient\">Transient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASTestTmp</td>\n",
       "      <td>PATH</td>\n",
       "      <td>castest's test files</td>\n",
       "      <td>/bigdisk/lax/castest/</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUSER(weshiz)</td>\n",
       "      <td>PATH</td>\n",
       "      <td>Personal File System Caslib</td>\n",
       "      <td>/u/weshiz/</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Formats</td>\n",
       "      <td>PATH</td>\n",
       "      <td>Format Caslib</td>\n",
       "      <td>/bigdisk/lax/formats/</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000363s</span> &#183; <span class=\"cas-user\">user 0.000191s</span> &#183; <span class=\"cas-sys\">sys 0.000158s</span> &#183; <span class=\"cas-memory\">mem 0.677MB</span></small></p>"
      ],
      "text/plain": [
       "[CASLibInfo]\n",
       "\n",
       "               Name  Type                  Description                   Path  \\\n",
       " 0       CASTestTmp  PATH         castest's test files  /bigdisk/lax/castest/   \n",
       " 1  CASUSER(weshiz)  PATH  Personal File System Caslib             /u/weshiz/   \n",
       " 2          Formats  PATH                Format Caslib  /bigdisk/lax/formats/   \n",
       " \n",
       "   Definition  Subdirs  Local  Active  Personal  Hidden  Transient  \n",
       " 0                 1.0    0.0     0.0       0.0     0.0        0.0  \n",
       " 1                 1.0    0.0     1.0       1.0     0.0        1.0  \n",
       " 2                 1.0    0.0     0.0       0.0     0.0        0.0  \n",
       "\n",
       "+ Elapsed: 0.000363s, user: 0.000191s, sys: 0.000158s, mem: 0.677mb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.caslibinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: No tables are available in caslib CASUSER(weshiz) of Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00025s</span> &#183; <span class=\"cas-user\">user 0.000118s</span> &#183; <span class=\"cas-sys\">sys 9.8e-05s</span> &#183; <span class=\"cas-memory\">mem 0.284MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.00025s, user: 0.000118s, sys: 9.8e-05s, mem: 0.284mb"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tableinfo(caslib='casuser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Triplet Loss Forward and Backward Function"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments, srcY, weights, y_out, are casted to array type\n",
      "Arguments, y_out, are declared as outargs.\n",
      "Arguments, srcY, Y, weights, deltas, gradient_out, srcDeltas_out, are casted to array type\n",
      "Arguments, gradient_out, srcDeltas_out, are declared as outargs.\n"
     ]
    }
   ],
   "source": [
    "@out_args('y_out')  # pass by reference\n",
    "@cast_array('srcY', 'weights', 'y_out')  # declare the arguments as array type\n",
    "def forward_prop(srcHeight, srcWidth, srcDepth, srcY, weights, y_out):\n",
    "    fcmp.reshape(weights, (1, 1, 1))\n",
    "    margin = 2.0\n",
    "    n_feature = int(srcWidth / 3)\n",
    "    ap = 0.0\n",
    "    an = 0.0\n",
    "    for i in range(n_feature):\n",
    "        ap = ap + (srcY[i] - srcY[n_feature + i]) ** 2\n",
    "        an = an + (srcY[i] - srcY[2 * n_feature + i]) ** 2\n",
    "    ap = ap ** 0.5\n",
    "    an = an ** 0.5\n",
    "    diff = ap - an + margin\n",
    "    y_out[0] = max(diff, 0.0)\n",
    "    return y_out[0]\n",
    "\n",
    "@out_args('gradient_out', 'srcDeltas_out')\n",
    "@cast_array('srcY', 'Y', 'weights', 'deltas', 'gradient_out', 'srcDeltas_out')\n",
    "def back_prop(srcHeight, srcWidth, srcDepth, srcY, Y, weights,\n",
    "              deltas, gradient_out, srcDeltas_out):\n",
    "    n_feature = int(srcWidth / 3)\n",
    "    for i in range(n_feature):\n",
    "        if Y[0] == 0.0:\n",
    "            srcDeltas_out[i] = 0.0\n",
    "            srcDeltas_out[n_feature + i ] = 0.0\n",
    "            srcDeltas_out[2 * n_feature + i] = 0.0\n",
    "        else:\n",
    "            srcDeltas_out[i] = deltas[0] * (srcY[2 * n_feature + i] - srcY[n_feature + i]) # anchor\n",
    "            srcDeltas_out[n_feature + i] = deltas[0] * (srcY[i] - srcY[n_feature + i]) # positive\n",
    "            srcDeltas_out[2 * n_feature + i] = deltas[0] * (srcY[2 * n_feature + i] - srcY[i]) # negative\n",
    "    return\n",
    "\n",
    "def dummy_loss(t, target):\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('function forward_prop(srcHeight, srcWidth, srcDepth, srcY[*], weights[*], y_out[*]);outargs y_out;\\n'\n",
      " '    margin = 2.0;\\n'\n",
      " '    n_feature = int((srcWidth / 3));\\n'\n",
      " '    ap = 0.0;\\n'\n",
      " '    an = 0.0;\\n'\n",
      " '    do i = 0 to n_feature - 1 by 1;\\n'\n",
      " '        ap = (ap + (srcY[i + 1] - srcY[(n_feature + i) + 1]) ** 2);\\n'\n",
      " '        an = (an + (srcY[i + 1] - srcY[((2 * n_feature) + i) + 1]) ** 2);\\n'\n",
      " '    end;\\n'\n",
      " '    ap = ap ** 0.5;\\n'\n",
      " '    an = an ** 0.5;\\n'\n",
      " '    diff = ((ap - an) + margin);\\n'\n",
      " '    y_out[1] = max(diff, 0.0);\\n'\n",
      " '    return (y_out[1]);\\n'\n",
      " 'endsub;\\n')\n"
     ]
    }
   ],
   "source": [
    "# get FCMP code of forward_prop\n",
    "forward_fcmp_code = python_to_fcmp(func=forward_prop, print=True)\n",
    "# 2 * 3 + 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('function back_prop(srcHeight, srcWidth, srcDepth, srcY[*], Y[*], weights[*], deltas[*], gradient_out[*], srcDeltas_out[*]);outargs gradient_out, srcDeltas_out;\\n'\n",
      " '    n_feature = int((srcWidth / 3));\\n'\n",
      " '    do i = 0 to n_feature - 1 by 1;\\n'\n",
      " '        if Y[1] eq 0.0 then do;\\n'\n",
      " '            srcDeltas_out[i + 1] = 0.0;\\n'\n",
      " '            srcDeltas_out[(n_feature + i) + 1] = 0.0;\\n'\n",
      " '            srcDeltas_out[((2 * n_feature) + i) + 1] = 0.0;\\n'\n",
      " '        end;\\n'\n",
      " '        else do;\\n'\n",
      " '            srcDeltas_out[i + 1] = (deltas[1] * (srcY[((2 * n_feature) + i) + 1] - srcY[(n_feature + i) + 1]));\\n'\n",
      " '            srcDeltas_out[(n_feature + i) + 1] = (deltas[1] * (srcY[i + 1] - srcY[(n_feature + i) + 1]));\\n'\n",
      " '            srcDeltas_out[((2 * n_feature) + i) + 1] = (deltas[1] * (srcY[((2 * n_feature) + i) + 1] - srcY[i + 1]));\\n'\n",
      " '        end;\\n'\n",
      " '    end;\\n'\n",
      " '    return ;\\n'\n",
      " 'endsub;\\n')\n"
     ]
    }
   ],
   "source": [
    "# get FCMP code of back_prop\n",
    "backward_fcmp_code = python_to_fcmp(func=back_prop, print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'function dummy_loss(t, target);\\n    return (t);\\nendsub;\\n'\n"
     ]
    }
   ],
   "source": [
    "dummy_loss_code = python_to_fcmp(dummy_loss, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'function back_prop(srcHeight, srcWidth, srcDepth, srcY[*], Y[*], weights[*], deltas[*], gradient_out[*], srcDeltas_out[*]);outargs gradient_out, srcDeltas_out;\\n    n_feature = int((srcWidth / 3));\\n    do i = 0 to n_feature - 1 by 1;\\n        if Y[1] eq 0.0 then do;\\n            srcDeltas_out[i + 1] = 0.0;\\n            srcDeltas_out[(n_feature + i) + 1] = 0.0;\\n            srcDeltas_out[((2 * n_feature) + i) + 1] = 0.0;\\n        end;\\n        else do;\\n            srcDeltas_out[i + 1] = (deltas[1] * (srcY[((2 * n_feature) + i) + 1] - srcY[(n_feature + i) + 1]));\\n            srcDeltas_out[(n_feature + i) + 1] = (deltas[1] * (srcY[i + 1] - srcY[(n_feature + i) + 1]));\\n            srcDeltas_out[((2 * n_feature) + i) + 1] = (deltas[1] * (srcY[((2 * n_feature) + i) + 1] - srcY[i + 1]));\\n        end;\\n    end;\\n    return ;\\nendsub;\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_fcmp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services saved the file FCMPFUNCTION.sashdat in caslib CASUSER(weshiz).\n"
     ]
    }
   ],
   "source": [
    "# register forward and backward function together\n",
    "register_fcmp_routines(s,\n",
    "                       routine_code=forward_fcmp_code + backward_fcmp_code + dummy_loss_code,\n",
    "                       function_tbl_name='fcmpfunction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Input layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Fully-connected layer added.\n",
      "NOTE: Output layer added.\n",
      "NOTE: Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(s, model_table='Simple_CNN')\n",
    "model.add(InputLayer(3, 48, 96, scale=1.0/255, random_mutation='none')) # input image is 48 by 96\n",
    "model.add(Conv2d(64, 7, include_bias=True, act='identity'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2)) # 3, 6\n",
    "model.add(Dense(16))\n",
    "model.add(OutputLayer(n=1, act='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch = model.to_functional_model(stop_layers=model.layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(**branch.layers[0].config, name='Input_layer_00') # tensor\n",
    "branch1 = branch(inp1) # tensor\n",
    "inp2 = Input(**branch.layers[0].config, name='Input_layer_01') # tensor\n",
    "branch2 = branch(inp2) # tensor\n",
    "inp3 = Input(**branch.layers[0].config, name='Input_layer_02') # tensor\n",
    "branch3 = branch(inp3) # tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat1 = Concat(name='Concat1')(branch1 + branch2 + branch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcmp1 = FCMPLayer(width=1, height=1, depth=1, n_weights=0, \n",
    "                  forward_func='forward_prop', backward_func='back_prop',\n",
    "                  name='FCMPLayer1')(concat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = OutputLayer(act='identity', fcmp_err='dummy_loss', error='FCMPERR', name='outputLayer_1',\n",
    "                   include_bias=False, full_connect=False)(fcmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = Model(s, inputs=[inp1, inp2, inp3], outputs=out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share weigths between each branch\n",
    "triplet_model.share_weights([{'Convo.1':['Convo.1_2', 'Convo.1_3']}, \n",
    "                             {'Convo.2':['Convo.2_2', 'Convo.2_3']}, \n",
    "                             {'Convo.3':['Convo.3_2', 'Convo.3_3']},\n",
    "                             {'Convo.4':['Convo.4_2', 'Convo.4_3']},\n",
    "                             {'F.C.1':['F.C.1_2', 'F.C.1_3']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "triplet_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Model_jcLygW Pages: 1 -->\r\n",
       "<svg width=\"707pt\" height=\"871pt\"\r\n",
       " viewBox=\"0.00 0.00 707.00 871.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 867)\">\r\n",
       "<title>Model_jcLygW</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-867 703,-867 703,4 -4,4\"/>\r\n",
       "<!-- Input_layer_00 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>Input_layer_00</title>\r\n",
       "<polygon fill=\"#3288bd\" fill-opacity=\"0.250980\" stroke=\"#3288bd\" points=\"0,-840.5 0,-862.5 221,-862.5 221,-840.5 0,-840.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110.5\" y=\"-847.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">96x48x3 Input_layer_00(input)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Convo.1</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"60.5,-770.5 60.5,-792.5 216.5,-792.5 216.5,-770.5 60.5,-770.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-777.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">7x7 Convo.1(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Input_layer_00&#45;&gt;Convo.1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>Input_layer_00&#45;&gt;Convo.1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M114.631,-840.466C118.767,-830.422 125.241,-814.7 130.404,-802.163\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"133.78,-803.154 134.352,-792.575 127.308,-800.489 133.78,-803.154\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-814\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 3 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool1 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>Pool1</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"94.5,-700.5 94.5,-722.5 224.5,-722.5 224.5,-700.5 94.5,-700.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"159.5\" y=\"-707.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool1(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1&#45;&gt;Pool1 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>Convo.1&#45;&gt;Pool1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M141.599,-770.466C144.7,-760.422 149.556,-744.7 153.428,-732.163\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"156.782,-733.162 156.389,-722.575 150.094,-731.097 156.782,-733.162\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-744\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>Convo.2</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"86.5,-630.5 86.5,-652.5 242.5,-652.5 242.5,-630.5 86.5,-630.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"164.5\" y=\"-637.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.2(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool1&#45;&gt;Convo.2 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>Pool1&#45;&gt;Convo.2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M160.238,-700.466C160.962,-690.623 162.086,-675.327 162.999,-662.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"166.516,-662.805 163.759,-652.575 159.535,-662.291 166.516,-662.805\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-674\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool2 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>Pool2</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"100.5,-560.5 100.5,-582.5 230.5,-582.5 230.5,-560.5 100.5,-560.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"165.5\" y=\"-567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool2(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2&#45;&gt;Pool2 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>Convo.2&#45;&gt;Pool2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M164.648,-630.466C164.792,-620.623 165.017,-605.327 165.2,-592.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"168.704,-592.625 165.352,-582.575 161.705,-592.522 168.704,-592.625\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-604\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>Convo.3</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"88.5,-490.5 88.5,-512.5 244.5,-512.5 244.5,-490.5 88.5,-490.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-497.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.3(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool2&#45;&gt;Convo.3 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>Pool2&#45;&gt;Convo.3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M165.648,-560.466C165.792,-550.623 166.017,-535.327 166.2,-522.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"169.704,-522.625 166.352,-512.575 162.705,-522.522 169.704,-522.625\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-534\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool3 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>Pool3</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"101.5,-420.5 101.5,-442.5 231.5,-442.5 231.5,-420.5 101.5,-420.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-427.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool3(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3&#45;&gt;Pool3 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>Convo.3&#45;&gt;Pool3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M166.5,-490.466C166.5,-480.623 166.5,-465.327 166.5,-452.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"170,-452.575 166.5,-442.575 163,-452.575 170,-452.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-464\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>Convo.4</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"88.5,-350.5 88.5,-372.5 244.5,-372.5 244.5,-350.5 88.5,-350.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-357.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.4(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool3&#45;&gt;Convo.4 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>Pool3&#45;&gt;Convo.4</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M166.5,-420.466C166.5,-410.623 166.5,-395.327 166.5,-382.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"170,-382.575 166.5,-372.575 163,-382.575 170,-382.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"194\" y=\"-394\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool4 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>Pool4</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"108.5,-280.5 108.5,-302.5 238.5,-302.5 238.5,-280.5 108.5,-280.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"173.5\" y=\"-287.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool4(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4&#45;&gt;Pool4 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>Convo.4&#45;&gt;Pool4</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M167.533,-350.466C168.556,-340.523 170.153,-325.014 171.437,-312.54\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"174.92,-312.881 172.463,-302.575 167.957,-312.164 174.92,-312.881\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-324\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>F.C.1</title>\r\n",
       "<polygon fill=\"#ffffbf\" fill-opacity=\"0.250980\" stroke=\"#aeae82\" points=\"105,-210.5 105,-232.5 250,-232.5 250,-210.5 105,-210.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177.5\" y=\"-217.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1152x16 F.C.1(fc)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool4&#45;&gt;F.C.1 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>Pool4&#45;&gt;F.C.1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M174.09,-280.466C174.669,-270.623 175.569,-255.327 176.299,-242.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"179.814,-242.763 176.907,-232.575 172.826,-242.352 179.814,-242.763\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"201.5\" y=\"-254\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 6 x 3 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Concat1 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>Concat1</title>\r\n",
       "<polygon fill=\"#f46d43\" fill-opacity=\"0.250980\" stroke=\"#f46d43\" points=\"273,-140.5 273,-162.5 426,-162.5 426,-140.5 273,-140.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-147.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">48 Concat1(concat)</text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1&#45;&gt;Concat1 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>F.C.1&#45;&gt;Concat1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M202.879,-210.466C232.477,-198.765 281.566,-179.358 314.704,-166.257\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"316.004,-169.506 324.017,-162.575 313.43,-162.997 316.004,-169.506\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"283\" y=\"-184\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 16 </text>\r\n",
       "</g>\r\n",
       "<!-- Input_layer_01 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>Input_layer_01</title>\r\n",
       "<polygon fill=\"#3288bd\" fill-opacity=\"0.250980\" stroke=\"#3288bd\" points=\"239,-840.5 239,-862.5 460,-862.5 460,-840.5 239,-840.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-847.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">96x48x3 Input_layer_01(input)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1_2 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>Convo.1_2</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"263,-770.5 263,-792.5 436,-792.5 436,-770.5 263,-770.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-777.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">7x7 Convo.1_2(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Input_layer_01&#45;&gt;Convo.1_2 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>Input_layer_01&#45;&gt;Convo.1_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-840.466C349.5,-830.623 349.5,-815.327 349.5,-802.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-802.575 349.5,-792.575 346,-802.575 353,-802.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-814\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 3 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool1_2 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>Pool1_2</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"276.5,-700.5 276.5,-722.5 422.5,-722.5 422.5,-700.5 276.5,-700.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-707.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool1_2(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1_2&#45;&gt;Pool1_2 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>Convo.1_2&#45;&gt;Pool1_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-770.466C349.5,-760.623 349.5,-745.327 349.5,-732.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-732.575 349.5,-722.575 346,-732.575 353,-732.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"380\" y=\"-744\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2_2 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>Convo.2_2</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"263,-630.5 263,-652.5 436,-652.5 436,-630.5 263,-630.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-637.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.2_2(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool1_2&#45;&gt;Convo.2_2 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>Pool1_2&#45;&gt;Convo.2_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-700.466C349.5,-690.623 349.5,-675.327 349.5,-662.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-662.575 349.5,-652.575 346,-662.575 353,-662.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"380\" y=\"-674\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool2_2 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>Pool2_2</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"276.5,-560.5 276.5,-582.5 422.5,-582.5 422.5,-560.5 276.5,-560.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool2_2(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2_2&#45;&gt;Pool2_2 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>Convo.2_2&#45;&gt;Pool2_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-630.466C349.5,-620.623 349.5,-605.327 349.5,-592.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-592.575 349.5,-582.575 346,-592.575 353,-592.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"380\" y=\"-604\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3_2 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>Convo.3_2</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"263,-490.5 263,-512.5 436,-512.5 436,-490.5 263,-490.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-497.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.3_2(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool2_2&#45;&gt;Convo.3_2 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>Pool2_2&#45;&gt;Convo.3_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-560.466C349.5,-550.623 349.5,-535.327 349.5,-522.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-522.575 349.5,-512.575 346,-522.575 353,-522.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"380\" y=\"-534\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool3_2 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>Pool3_2</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"276.5,-420.5 276.5,-442.5 422.5,-442.5 422.5,-420.5 276.5,-420.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-427.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool3_2(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3_2&#45;&gt;Pool3_2 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>Convo.3_2&#45;&gt;Pool3_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-490.466C349.5,-480.623 349.5,-465.327 349.5,-452.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-452.575 349.5,-442.575 346,-452.575 353,-452.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"380\" y=\"-464\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4_2 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>Convo.4_2</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"263,-350.5 263,-372.5 436,-372.5 436,-350.5 263,-350.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-357.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.4_2(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool3_2&#45;&gt;Convo.4_2 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>Pool3_2&#45;&gt;Convo.4_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-420.466C349.5,-410.623 349.5,-395.327 349.5,-382.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-382.575 349.5,-372.575 346,-382.575 353,-382.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-394\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool4_2 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>Pool4_2</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"276.5,-280.5 276.5,-302.5 422.5,-302.5 422.5,-280.5 276.5,-280.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-287.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool4_2(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4_2&#45;&gt;Pool4_2 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>Convo.4_2&#45;&gt;Pool4_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-350.466C349.5,-340.623 349.5,-325.327 349.5,-312.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-312.575 349.5,-302.575 346,-312.575 353,-312.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-324\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1_2 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>F.C.1_2</title>\r\n",
       "<polygon fill=\"#ffffbf\" fill-opacity=\"0.250980\" stroke=\"#aeae82\" points=\"269,-210.5 269,-232.5 430,-232.5 430,-210.5 269,-210.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-217.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1152x16 F.C.1_2(fc)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool4_2&#45;&gt;F.C.1_2 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>Pool4_2&#45;&gt;F.C.1_2</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-280.466C349.5,-270.623 349.5,-255.327 349.5,-242.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-242.575 349.5,-232.575 346,-242.575 353,-242.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"374.5\" y=\"-254\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 6 x 3 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1_2&#45;&gt;Concat1 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>F.C.1_2&#45;&gt;Concat1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-210.466C349.5,-200.623 349.5,-185.327 349.5,-172.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-172.575 349.5,-162.575 346,-172.575 353,-172.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-184\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 16 </text>\r\n",
       "</g>\r\n",
       "<!-- Input_layer_02 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>Input_layer_02</title>\r\n",
       "<polygon fill=\"#3288bd\" fill-opacity=\"0.250980\" stroke=\"#3288bd\" points=\"478,-840.5 478,-862.5 699,-862.5 699,-840.5 478,-840.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"588.5\" y=\"-847.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">96x48x3 Input_layer_02(input)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1_3 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>Convo.1_3</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"502,-770.5 502,-792.5 675,-792.5 675,-770.5 502,-770.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"588.5\" y=\"-777.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">7x7 Convo.1_3(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Input_layer_02&#45;&gt;Convo.1_3 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>Input_layer_02&#45;&gt;Convo.1_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M588.5,-840.466C588.5,-830.623 588.5,-815.327 588.5,-802.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"592,-802.575 588.5,-792.575 585,-802.575 592,-802.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"616\" y=\"-814\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 3 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool1_3 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>Pool1_3</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"488.5,-700.5 488.5,-722.5 634.5,-722.5 634.5,-700.5 488.5,-700.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"561.5\" y=\"-707.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool1_3(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.1_3&#45;&gt;Pool1_3 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>Convo.1_3&#45;&gt;Pool1_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M584.516,-770.466C580.528,-760.422 574.285,-744.7 569.307,-732.163\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"572.444,-730.577 565.5,-722.575 565.938,-733.161 572.444,-730.577\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"608\" y=\"-744\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 96 x 48 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2_3 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>Convo.2_3</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"457,-630.5 457,-652.5 630,-652.5 630,-630.5 457,-630.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"543.5\" y=\"-637.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.2_3(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool1_3&#45;&gt;Convo.2_3 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>Pool1_3&#45;&gt;Convo.2_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M558.844,-700.466C556.212,-690.523 552.107,-675.014 548.805,-662.54\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"552.109,-661.346 546.167,-652.575 545.342,-663.138 552.109,-661.346\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"585\" y=\"-674\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool2_3 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>Pool2_3</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"469.5,-560.5 469.5,-582.5 615.5,-582.5 615.5,-560.5 469.5,-560.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"542.5\" y=\"-567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool2_3(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.2_3&#45;&gt;Pool2_3 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>Convo.2_3&#45;&gt;Pool2_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M543.352,-630.466C543.208,-620.623 542.983,-605.327 542.8,-592.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"546.295,-592.522 542.648,-582.575 539.296,-592.625 546.295,-592.522\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"574\" y=\"-604\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 x 24 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3_3 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>Convo.3_3</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"454,-490.5 454,-512.5 627,-512.5 627,-490.5 454,-490.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"540.5\" y=\"-497.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.3_3(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool2_3&#45;&gt;Convo.3_3 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>Pool2_3&#45;&gt;Convo.3_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M542.205,-560.466C541.915,-550.623 541.466,-535.327 541.101,-522.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"544.589,-522.468 540.796,-512.575 537.592,-522.673 544.589,-522.468\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-534\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool3_3 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>Pool3_3</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"467.5,-420.5 467.5,-442.5 613.5,-442.5 613.5,-420.5 467.5,-420.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"540.5\" y=\"-427.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool3_3(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.3_3&#45;&gt;Pool3_3 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>Convo.3_3&#45;&gt;Pool3_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M540.5,-490.466C540.5,-480.623 540.5,-465.327 540.5,-452.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"544,-452.575 540.5,-442.575 537,-452.575 544,-452.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"571\" y=\"-464\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 24 x 12 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4_3 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>Convo.4_3</title>\r\n",
       "<polygon fill=\"#fee08b\" fill-opacity=\"0.250980\" stroke=\"#b58c15\" points=\"454,-350.5 454,-372.5 627,-372.5 627,-350.5 454,-350.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"540.5\" y=\"-357.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 Convo.4_3(convo)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool3_3&#45;&gt;Convo.4_3 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>Pool3_3&#45;&gt;Convo.4_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M540.5,-420.466C540.5,-410.623 540.5,-395.327 540.5,-382.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"544,-382.575 540.5,-372.575 537,-382.575 544,-382.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"568\" y=\"-394\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- Pool4_3 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>Pool4_3</title>\r\n",
       "<polygon fill=\"#66c2a5\" fill-opacity=\"0.250980\" stroke=\"#66c2a5\" points=\"460.5,-280.5 460.5,-302.5 606.5,-302.5 606.5,-280.5 460.5,-280.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"533.5\" y=\"-287.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2x2 Pool4_3(pool)</text>\r\n",
       "</g>\r\n",
       "<!-- Convo.4_3&#45;&gt;Pool4_3 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>Convo.4_3&#45;&gt;Pool4_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M539.467,-350.466C538.444,-340.523 536.847,-325.014 535.563,-312.54\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"539.043,-312.164 534.537,-302.575 532.08,-312.881 539.043,-312.164\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"565\" y=\"-324\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 12 x 6 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1_3 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>F.C.1_3</title>\r\n",
       "<polygon fill=\"#ffffbf\" fill-opacity=\"0.250980\" stroke=\"#aeae82\" points=\"449,-210.5 449,-232.5 610,-232.5 610,-210.5 449,-210.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"529.5\" y=\"-217.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1152x16 F.C.1_3(fc)</text>\r\n",
       "</g>\r\n",
       "<!-- Pool4_3&#45;&gt;F.C.1_3 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>Pool4_3&#45;&gt;F.C.1_3</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M532.91,-280.466C532.331,-270.623 531.431,-255.327 530.701,-242.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"534.174,-242.352 530.093,-232.575 527.186,-242.763 534.174,-242.352\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-254\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 6 x 3 x 64 </text>\r\n",
       "</g>\r\n",
       "<!-- F.C.1_3&#45;&gt;Concat1 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>F.C.1_3&#45;&gt;Concat1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M502.94,-210.466C471.966,-198.765 420.594,-179.358 385.915,-166.257\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"386.76,-162.835 376.169,-162.575 384.286,-169.383 386.76,-162.835\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"459\" y=\"-184\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 16 </text>\r\n",
       "</g>\r\n",
       "<!-- FCMPLayer1 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>FCMPLayer1</title>\r\n",
       "<polygon fill=\"#5e4fa2\" fill-opacity=\"0.125490\" stroke=\"#5e4fa2\" points=\"247.5,-70.5 247.5,-92.5 451.5,-92.5 451.5,-70.5 247.5,-70.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-77.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1x1x1 FCMPLayer1(FCMP)</text>\r\n",
       "</g>\r\n",
       "<!-- Concat1&#45;&gt;FCMPLayer1 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>Concat1&#45;&gt;FCMPLayer1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-140.466C349.5,-130.623 349.5,-115.327 349.5,-102.919\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-102.575 349.5,-92.5748 346,-102.575 353,-102.575\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-114\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 48 </text>\r\n",
       "</g>\r\n",
       "<!-- outputLayer_1 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>outputLayer_1</title>\r\n",
       "<polygon fill=\"#5e4fa2\" fill-opacity=\"0.125490\" stroke=\"#5e4fa2\" points=\"266,-0.5 266,-22.5 433,-22.5 433,-0.5 266,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">outputLayer_1(output)</text>\r\n",
       "</g>\r\n",
       "<!-- FCMPLayer1&#45;&gt;outputLayer_1 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>FCMPLayer1&#45;&gt;outputLayer_1</title>\r\n",
       "<path fill=\"none\" stroke=\"#5677f3\" d=\"M349.5,-70.4664C349.5,-60.6231 349.5,-45.327 349.5,-32.9189\"/>\r\n",
       "<polygon fill=\"#5677f3\" stroke=\"#5677f3\" points=\"353,-32.5748 349.5,-22.5748 346,-32.5748 353,-32.5748\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"372\" y=\"-44\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> 1 x 1 x 1 </text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1cd29ae9c18>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_model.plot_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.table.addcaslib(activeonadd=False,datasource={'srctype':'path'},\n",
    "                  name='dnfs',path='/cas/DeepLearn/data/scisports_2019/team_classification_tf_Mark/training',\n",
    "                  subdirectories=True)\n",
    "s.table.loadTable(caslib='dnfs',path='Arsenal_CSKAMoskow_2018_04_05_triplet_sample.sashdat', \n",
    "                 casout=dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', replace=1))\n",
    "s.alterTable(table='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', columns=[dict(name='uniqueid', rename='_id_')])\n",
    "img_dlpy_tbl=ImageTable.from_table(s.CASTable('Arsenal_CSKAMoskow_2018_04_05_triplet_sample', \n",
    "                                              where='_id_ > 56005500'),\n",
    "                                   image_col='_image_', label_col='_label_',path_col='_path_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; caslib</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASUSER(weshiz)</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; tableName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; rowsTransferred</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>0</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; shuffleWaitTime</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>0.0</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; minShuffleWaitTime</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>1e+300</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; maxShuffleWaitTime</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>0.0</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; averageShuffleWaitTime</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>0.0</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; casTable</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASTable('ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE', caslib='CASUSER(weshiz)')</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.441s</span> &#183; <span class=\"cas-user\">user 1s</span> &#183; <span class=\"cas-sys\">sys 1.81s</span> &#183; <span class=\"cas-memory\">mem 552MB</span></small></p>"
      ],
      "text/plain": [
       "[caslib]\n",
       "\n",
       " 'CASUSER(weshiz)'\n",
       "\n",
       "[tableName]\n",
       "\n",
       " 'ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE'\n",
       "\n",
       "[rowsTransferred]\n",
       "\n",
       " 0\n",
       "\n",
       "[shuffleWaitTime]\n",
       "\n",
       " 0.0\n",
       "\n",
       "[minShuffleWaitTime]\n",
       "\n",
       " 1e+300\n",
       "\n",
       "[maxShuffleWaitTime]\n",
       "\n",
       " 0.0\n",
       "\n",
       "[averageShuffleWaitTime]\n",
       "\n",
       " 0.0\n",
       "\n",
       "[casTable]\n",
       "\n",
       " CASTable('ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE', caslib='CASUSER(weshiz)')\n",
       "\n",
       "+ Elapsed: 0.441s, user: 1s, sys: 1.81s, mem: 552mb"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.partition(dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', \n",
    "            where='_label_ not in (\"keeper_CSKA\", \"keeper_Arsenal\")'), \n",
    "            casout=dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', replace=1))\n",
    "s.partition(dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', \n",
    "            where='_label1_ not in (\"keeper_CSKA\", \"keeper_Arsenal\")'), \n",
    "            casout=dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', replace=1))\n",
    "s.partition(dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', \n",
    "            where='_label2_ not in (\"keeper_CSKA\", \"keeper_Arsenal\")'), \n",
    "            casout=dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', replace=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_id_\">_id_</th>\n",
       "      <th title=\"_path_\">_path_</th>\n",
       "      <th title=\"_image_\">_image_</th>\n",
       "      <th title=\"_label_\">_label_</th>\n",
       "      <th title=\"isSelected\">isSelected</th>\n",
       "      <th title=\"_image1_\">_image1_</th>\n",
       "      <th title=\"_path1_\">_path1_</th>\n",
       "      <th title=\"_label1_\">_label1_</th>\n",
       "      <th title=\"_image2_\">_image2_</th>\n",
       "      <th title=\"_path2_\">_path2_</th>\n",
       "      <th title=\"_label2_\">_label2_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53002533.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>referee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53002534.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53002536.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54005623.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54005629.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54005636.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54005638.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54005648.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54005649.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>referee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>referee</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41003755.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41003760.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>referee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41003766.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41003769.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41003771.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41003777.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41003778.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23005467.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23005468.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23005483.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>referee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23005491.0</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>CSKA</td>\n",
       "      <td>b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...</td>\n",
       "      <td>/cas/DeepLearn/data/scisports_2019/team_classi...</td>\n",
       "      <td>referee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00974s</span> &#183; <span class=\"cas-user\">user 0.00905s</span> &#183; <span class=\"cas-sys\">sys 0.000652s</span> &#183; <span class=\"cas-memory\">mem 2.82MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table ARSENAL_CSKAMOSKOW_2018_04_05_TRIPLET_SAMPLE\n",
       " \n",
       "           _id_                                             _path_  \\\n",
       " 0   53002533.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 1   53002534.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 2   53002536.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 3   54005623.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 4   54005629.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 5   54005636.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 6   54005638.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 7   54005648.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 8   54005649.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 9   41003755.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 10  41003760.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 11  41003766.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 12  41003769.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 13  41003771.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 14  41003777.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 15  41003778.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 16  23005467.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 17  23005468.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 18  23005483.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " 19  23005491.0  /cas/DeepLearn/data/scisports_2019/team_classi...   \n",
       " \n",
       "                                               _image_  _label_  isSelected  \\\n",
       " 0   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 1   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 2   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 3   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 4   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 5   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 6   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 7   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 8   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  referee         1.0   \n",
       " 9   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 10  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 11  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 12  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 13  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 14  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 15  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 16  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 17  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...  Arsenal         1.0   \n",
       " 18  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " 19  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...     CSKA         1.0   \n",
       " \n",
       "                                              _image1_  \\\n",
       " 0   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 1   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 2   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 3   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 4   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 5   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 6   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 7   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 8   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 9   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 10  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 11  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 12  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 13  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 14  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 15  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 16  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 17  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 18  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 19  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " \n",
       "                                               _path1_ _label1_  \\\n",
       " 0   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 1   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 2   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 3   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 4   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 5   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 6   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 7   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 8   /cas/DeepLearn/data/scisports_2019/team_classi...  referee   \n",
       " 9   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 10  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 11  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 12  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 13  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 14  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 15  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 16  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 17  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal   \n",
       " 18  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " 19  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA   \n",
       " \n",
       "                                              _image2_  \\\n",
       " 0   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 1   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 2   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 3   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 4   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 5   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 6   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 7   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 8   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 9   b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 10  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 11  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 12  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 13  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 14  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 15  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 16  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 17  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 18  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " 19  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...   \n",
       " \n",
       "                                               _path2_ _label2_  \n",
       " 0   /cas/DeepLearn/data/scisports_2019/team_classi...  referee  \n",
       " 1   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 2   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 3   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal  \n",
       " 4   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 5   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal  \n",
       " 6   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 7   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 8   /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 9   /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal  \n",
       " 10  /cas/DeepLearn/data/scisports_2019/team_classi...  referee  \n",
       " 11  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal  \n",
       " 12  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 13  /cas/DeepLearn/data/scisports_2019/team_classi...  Arsenal  \n",
       " 14  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 15  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 16  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 17  /cas/DeepLearn/data/scisports_2019/team_classi...     CSKA  \n",
       " 18  /cas/DeepLearn/data/scisports_2019/team_classi...  referee  \n",
       " 19  /cas/DeepLearn/data/scisports_2019/team_classi...  referee  \n",
       "\n",
       "+ Elapsed: 0.00974s, user: 0.00905s, sys: 0.000652s, mem: 2.82mb"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fetch('Arsenal_CSKAMoskow_2018_04_05_triplet_sample', sastypes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; numrows</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>41</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00015s</span> &#183; <span class=\"cas-user\">user 0.00014s</span> &#183; <span class=\"cas-memory\">mem 0.409MB</span></small></p>"
      ],
      "text/plain": [
       "[numrows]\n",
       "\n",
       " 41\n",
       "\n",
       "+ Elapsed: 0.00015s, user: 0.00014s, mem: 0.409mb"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dlpy_tbl.numrows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Python Client to check forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = VanillaSolver(clip_grad_max=100, clip_grad_min=-100, learning_rate=0.0001,\n",
    "                       learning_rate_policy='step', gamma=0.1, step_size=30)\n",
    "optimizer = Optimizer(algorithm=solver, seed=13309, max_epochs=15, log_level=3, mini_batch_size=32, reg_l2=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Training from scratch.\n",
      "WARNING: Using dataSpecs settings. Additional input or target option settings will be ignored.\n",
      "NOTE:  Synchronous mode is enabled.\n",
      "NOTE:  The total number of parameters is 416112.\n",
      "NOTE:  The approximate memory cost is 3273.00 MB.\n",
      "NOTE:  Loading weights cost       0.00 (s).\n",
      "NOTE:  Initializing each layer cost       0.29 (s).\n",
      "NOTE:  The total number of threads on each worker is 8.\n",
      "NOTE:  The total mini-batch size per thread on each worker is 32.\n",
      "NOTE:  The maximum mini-batch size across all workers for the synchronous mode is 256.\n",
      "NOTE:  Target variable: isSelected\n",
      "NOTE:  Number of input variables:     3\n",
      "NOTE:  Number of numeric input variables:      3\n",
      "NOTE:  Number of FCMP layers in model: 1\n",
      "NOTE:  FCMP layer 'fcmplayer1' has input tensor size: width=48, height=1, depth=1\n",
      "NOTE:  FCMP layer 'fcmplayer1' has output tensor size: width=1, height=1, depth=1\n",
      "NOTE:  FCMP layer 'fcmplayer1' has 0 weights.\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.897     0.8289    0.08158     0.81\n",
      "NOTE:      1   256   0.0001            1.912     0.8583    0.08158     0.84\n",
      "NOTE:      2   256   0.0001            1.914     0.8607    0.08158     0.84\n",
      "NOTE:      3   256   0.0001            1.916     0.8632    0.08158     0.85\n",
      "NOTE:      4   256   0.0001            1.899      0.834    0.08158     0.83\n",
      "NOTE:      5   256   0.0001            1.908     0.8482    0.08158     0.82\n",
      "NOTE:      6   256   0.0001            1.897      0.828    0.08158     0.83\n",
      "NOTE:      7   256   0.0001            1.905     0.8445    0.08158     0.83\n",
      "NOTE:      8   256   0.0001            1.898     0.8282    0.08158     0.83\n",
      "NOTE:      9   256   0.0001            1.898     0.8303    0.08158     0.82\n",
      "NOTE:     10   256   0.0001            1.912     0.8507    0.08158     0.84\n",
      "NOTE:     11   256   0.0001            1.908      0.844    0.08158     0.84\n",
      "NOTE:     12   256   0.0001            1.919     0.8671    0.08158     0.82\n",
      "NOTE:     13   256   0.0001            1.912     0.8543    0.08158     0.83\n",
      "NOTE:     14   256   0.0001            1.885     0.8095    0.08158     0.88\n",
      "NOTE:     15   256   0.0001            1.894     0.8226    0.08158     0.82\n",
      "NOTE:     16   256   0.0001            1.898     0.8286    0.08158     0.83\n",
      "NOTE:     17   256   0.0001            1.894     0.8213    0.08158     0.90\n",
      "NOTE:     18   256   0.0001            1.898     0.8306    0.08158     0.86\n",
      "NOTE:     19   256   0.0001              1.9     0.8334    0.08158     0.82\n",
      "NOTE:     20   256   0.0001            1.894     0.8206    0.08158     0.84\n",
      "NOTE:     21   256   0.0001            1.895     0.8252    0.08158     0.84\n",
      "NOTE:     22   256   0.0001            1.907      0.847    0.08158     0.84\n",
      "NOTE:     23   256   0.0001            1.884     0.8085    0.08158     0.84\n",
      "NOTE:     24   256   0.0001            1.902     0.8393    0.08158     0.84\n",
      "NOTE:     25   256   0.0001            1.908     0.8456    0.08158     0.83\n",
      "NOTE:     26   256   0.0001            1.895     0.8253    0.08158     0.82\n",
      "NOTE:     27   256   0.0001            1.896     0.8232    0.08158     0.83\n",
      "NOTE:     28   256   0.0001            1.903      0.837    0.08158     0.85\n",
      "NOTE:     29   256   0.0001            1.894     0.8261    0.08158     0.84\n",
      "NOTE:     30   256   0.0001            1.895     0.8256    0.08158     0.83\n",
      "NOTE:     31   256   0.0001            1.901     0.8373    0.08158     0.84\n",
      "NOTE:     32   256   0.0001            1.903     0.8382    0.08158     0.84\n",
      "NOTE:     33   256   0.0001            1.904     0.8404    0.08158     0.85\n",
      "NOTE:     34   256   0.0001              1.9     0.8316    0.08158     0.86\n",
      "NOTE:     35   256   0.0001            1.904     0.8441    0.08158     0.83\n",
      "NOTE:     36   256   0.0001            1.902     0.8419    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.903     0.8384    0.08158     0.82\n",
      "NOTE:     38   256   0.0001            1.909     0.8524    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.912     0.8573    0.08158     0.82\n",
      "NOTE:     40   256   0.0001            1.904     0.8444    0.08158     0.82\n",
      "NOTE:     41   256   0.0001            1.898     0.8335    0.08158     0.81\n",
      "NOTE:     42   256   0.0001            1.915     0.8592    0.08158     0.81\n",
      "NOTE:     43   256   0.0001            1.895     0.8238    0.08158     0.88\n",
      "NOTE:     44   256   0.0001            1.899     0.8346    0.08158     0.83\n",
      "NOTE:     45   256   0.0001            1.916     0.8614    0.08158     0.91\n",
      "NOTE:     46   256   0.0001            1.904     0.8429    0.08158     0.83\n",
      "NOTE:     47   256   0.0001            1.903     0.8419    0.08158     0.84\n",
      "NOTE:     48   256   0.0001            1.899      0.828    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.905     0.8445    0.08158     0.84\n",
      "NOTE:     50   256   0.0001             1.89     0.8156    0.08158     0.83\n",
      "NOTE:     51   256   0.0001            1.903     0.8405    0.08158     0.83\n",
      "NOTE:     52   256   0.0001            1.904     0.8392    0.08158     0.83\n",
      "NOTE:     53   256   0.0001            1.909     0.8488    0.08158     0.83\n",
      "NOTE:     54   256   0.0001            1.902     0.8393    0.08158     0.82\n",
      "NOTE:     55   256   0.0001            1.918      0.866    0.08158     0.83\n",
      "NOTE:     56   256   0.0001            1.896     0.8262    0.08158     0.83\n",
      "NOTE:     57   256   0.0001            1.898      0.828    0.08158     0.83\n",
      "NOTE:     58   256   0.0001            1.901     0.8352    0.08158     0.82\n",
      "NOTE:     59   256   0.0001            1.902     0.8384    0.08158     0.82\n",
      "NOTE:     60   256   0.0001            1.912     0.8558    0.08158     0.87\n",
      "NOTE:     61   256   0.0001            1.939     0.9057    0.08158     0.82\n",
      "NOTE:     62   256   0.0001            1.926      0.885    0.08158     0.82\n",
      "NOTE:     63   256   0.0001            1.898     0.8296    0.08158     0.82\n",
      "NOTE:     64   256   0.0001            1.911     0.8555    0.08158     0.82\n",
      "NOTE:     65   256   0.0001            1.902     0.8373    0.08158     0.82\n",
      "NOTE:     66   256   0.0001            1.915     0.8621    0.08158     0.82\n",
      "NOTE:     67   256   0.0001            1.881     0.8004    0.08158     0.86\n",
      "NOTE:     68   256   0.0001            1.917     0.8633    0.08158     0.81\n",
      "NOTE:     69   256   0.0001            1.903     0.8422    0.08158     0.82\n",
      "NOTE:     70   256   0.0001            1.916      0.865    0.08158     0.83\n",
      "NOTE:     71   256   0.0001            1.903     0.8383    0.08158     0.83\n",
      "NOTE:     72   256   0.0001            1.899     0.8339    0.08158     0.82\n",
      "NOTE:     73   256   0.0001            1.905     0.8478    0.08158     0.83\n",
      "NOTE:     74   256   0.0001            1.893     0.8221    0.08158     0.83\n",
      "NOTE:     75   256   0.0001            1.897     0.8273    0.08158     0.82\n",
      "NOTE:     76   256   0.0001            1.918     0.8641    0.08158     0.83\n",
      "NOTE:     77   256   0.0001            1.896     0.8298    0.08158     0.83\n",
      "NOTE:     78   256   0.0001            1.902     0.8346    0.08158     0.82\n",
      "NOTE:     79   256   0.0001             1.89     0.8226    0.08158     0.82\n",
      "NOTE:     80   256   0.0001            1.907      0.843    0.08158     0.83\n",
      "NOTE:     81   256   0.0001            1.931     0.8933    0.08158     0.84\n",
      "NOTE:     82   256   0.0001            1.908     0.8482    0.08158     0.87\n",
      "NOTE:     83   256   0.0001            1.928     0.8841    0.08158     0.83\n",
      "NOTE:     84   256   0.0001            1.905     0.8445    0.08158     0.82\n",
      "NOTE:     85   256   0.0001            1.906     0.8437    0.08158     0.82\n",
      "NOTE:     86   256   0.0001            1.912      0.857    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.892     0.8196    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.901     0.8362    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.912     0.8538    0.08158     0.82\n",
      "NOTE:     90   256   0.0001            1.906     0.8463    0.08158     0.82\n",
      "NOTE:     91   256   0.0001            1.907     0.8473    0.08158     0.87\n",
      "NOTE:     92   256   0.0001            1.918     0.8705    0.08158     0.82\n",
      "NOTE:     93   256   0.0001            1.903     0.8391    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.915     0.8644    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.908     0.8533    0.08158     0.81\n",
      "NOTE:     96   256   0.0001            1.918     0.8654    0.08158     0.82\n",
      "NOTE:     97   256   0.0001            1.904     0.8429    0.08158     0.83\n",
      "NOTE:     98   256   0.0001            1.887     0.8084    0.08158     0.83\n",
      "NOTE:     99   256   0.0001            1.895     0.8285    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    100   256   0.0001            1.882     0.8002    0.08158     0.90\n",
      "NOTE:    101   256   0.0001            1.908     0.8477    0.08158     0.85\n",
      "NOTE:    102   256   0.0001            1.894     0.8247    0.08158     0.90\n",
      "NOTE:    103   256   0.0001            1.901     0.8363    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.893     0.8222    0.08158     0.84\n",
      "NOTE:    105   256   0.0001            1.911     0.8547    0.08158     0.83\n",
      "NOTE:    106   256   0.0001            1.882     0.8006    0.08158     0.82\n",
      "NOTE:    107   256   0.0001            1.909     0.8482    0.08158     0.82\n",
      "NOTE:    108   256   0.0001            1.872     0.7861    0.08158     0.82\n",
      "NOTE:    109   256   0.0001            1.894      0.827    0.08158     0.82\n",
      "NOTE:    110   256   0.0001            1.906      0.848    0.08158     0.82\n",
      "NOTE:    111   256   0.0001            1.892     0.8191    0.08158     0.89\n",
      "NOTE:    112   256   0.0001            1.914     0.8614    0.08158     0.83\n",
      "NOTE:    113   256   0.0001            1.891     0.8181    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.887     0.8114    0.08158     0.82\n",
      "NOTE:    115   256   0.0001            1.894     0.8249    0.08158     0.82\n",
      "NOTE:    116   256   0.0001            1.911     0.8544    0.08158     0.83\n",
      "NOTE:    117   256   0.0001            1.886     0.8147    0.08158     0.82\n",
      "NOTE:    118   256   0.0001            1.903     0.8375    0.08158     0.83\n",
      "NOTE:    119   256   0.0001              1.9     0.8392    0.08158     0.82\n",
      "NOTE:    120   256   0.0001            1.891     0.8171    0.08158     0.82\n",
      "NOTE:    121   256   0.0001            1.908     0.8505    0.08158     0.82\n",
      "NOTE:    122   256   0.0001            1.919     0.8706    0.08158     0.83\n",
      "NOTE:    123   256   0.0001             1.88     0.8037    0.08158     0.83\n",
      "NOTE:    124   256   0.0001            1.888     0.8126    0.08158     0.84\n",
      "NOTE:    125   256   0.0001            1.907     0.8457    0.08158     0.90\n",
      "NOTE:    126   256   0.0001            1.899     0.8351    0.08158     0.91\n",
      "NOTE:    127   256   0.0001            1.888     0.8203    0.08158     0.90\n",
      "NOTE:    128   256   0.0001            1.896     0.8251    0.08158     0.92\n",
      "NOTE:    129   256   0.0001            1.895     0.8262    0.08158     0.85\n",
      "NOTE:    130   256   0.0001             1.89     0.8188    0.08158     0.92\n",
      "NOTE:    131   256   0.0001            1.899      0.833    0.08158     0.84\n",
      "NOTE:    132   256   0.0001             1.89     0.8178    0.08158     0.84\n",
      "NOTE:    133   256   0.0001            1.891     0.8212    0.08158     0.85\n",
      "NOTE:    134   256   0.0001            1.914     0.8554    0.08158     0.84\n",
      "NOTE:    135   256   0.0001            1.896     0.8284    0.08158     0.85\n",
      "NOTE:    136   256   0.0001            1.903     0.8426    0.08158     0.87\n",
      "NOTE:    137   256   0.0001              1.9     0.8331    0.08158     0.89\n",
      "NOTE:    138   256   0.0001             1.89     0.8187    0.08158     0.86\n",
      "NOTE:    139   256   0.0001            1.894     0.8245    0.08158     0.82\n",
      "NOTE:    140   256   0.0001            1.896     0.8326    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.906     0.8518    0.08158     0.83\n",
      "NOTE:    142   256   0.0001            1.884     0.8064    0.08158     0.82\n",
      "NOTE:    143   256   0.0001            1.873     0.7825    0.08158     0.84\n",
      "NOTE:    144   256   0.0001            1.891     0.8201    0.08158     0.89\n",
      "NOTE:    145   256   0.0001            1.911     0.8568    0.08158     0.89\n",
      "NOTE:    146   256   0.0001            1.885       0.81    0.08158     0.87\n",
      "NOTE:    147   256   0.0001            1.916     0.8629    0.08158     0.83\n",
      "NOTE:    148   256   0.0001            1.927      0.884    0.08158     0.82\n",
      "NOTE:    149   256   0.0001            1.891     0.8189    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.898     0.8331    0.08158     0.82\n",
      "NOTE:    151   256   0.0001            1.887     0.8152    0.08158     0.83\n",
      "NOTE:    152   256   0.0001            1.892     0.8199    0.08158     0.90\n",
      "NOTE:    153   256   0.0001            1.892     0.8161    0.08158     0.89\n",
      "NOTE:    154   256   0.0001            1.876     0.7997    0.08158     0.90\n",
      "NOTE:    155   256   0.0001            1.905     0.8444    0.08158     0.90\n",
      "NOTE:    156   256   0.0001            1.896     0.8296    0.08158     0.88\n",
      "NOTE:    157   256   0.0001            1.891     0.8175    0.08158     0.84\n",
      "NOTE:    158   256   0.0001             1.89     0.8172    0.08158     0.84\n",
      "NOTE:    159   256   0.0001            1.896     0.8336    0.08158     0.84\n",
      "NOTE:    160   256   0.0001            1.907     0.8492    0.08158     0.83\n",
      "NOTE:    161   256   0.0001            1.892     0.8232    0.08158     0.83\n",
      "NOTE:    162   256   0.0001            1.897     0.8305    0.08158     0.84\n",
      "NOTE:    163   256   0.0001            1.911     0.8584    0.08158     0.87\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  0        0.0001           1.901     0.8371   137.71\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.906     0.8459    0.08158     0.87\n",
      "NOTE:      1   256   0.0001             1.89     0.8214    0.08158     0.85\n",
      "NOTE:      2   256   0.0001            1.898     0.8315    0.08158     0.84\n",
      "NOTE:      3   256   0.0001            1.894     0.8237    0.08158     0.84\n",
      "NOTE:      4   256   0.0001            1.901     0.8423    0.08158     0.84\n",
      "NOTE:      5   256   0.0001             1.89     0.8199    0.08158     0.84\n",
      "NOTE:      6   256   0.0001            1.906     0.8451    0.08158     0.90\n",
      "NOTE:      7   256   0.0001            1.884     0.8068    0.08158     0.86\n",
      "NOTE:      8   256   0.0001            1.918     0.8663    0.08158     0.82\n",
      "NOTE:      9   256   0.0001            1.886     0.8111    0.08158     0.82\n",
      "NOTE:     10   256   0.0001            1.894     0.8226    0.08158     0.90\n",
      "NOTE:     11   256   0.0001             1.89     0.8176    0.08158     0.89\n",
      "NOTE:     12   256   0.0001            1.897     0.8276    0.08158     0.83\n",
      "NOTE:     13   256   0.0001            1.873     0.7852    0.08158     0.83\n",
      "NOTE:     14   256   0.0001            1.889     0.8165    0.08158     0.90\n",
      "NOTE:     15   256   0.0001            1.909     0.8537    0.08158     0.87\n",
      "NOTE:     16   256   0.0001            1.908     0.8506    0.08158     0.82\n",
      "NOTE:     17   256   0.0001            1.908     0.8497    0.08158     0.84\n",
      "NOTE:     18   256   0.0001            1.915     0.8629    0.08158     0.85\n",
      "NOTE:     19   256   0.0001            1.889     0.8174    0.08158     0.82\n",
      "NOTE:     20   256   0.0001            1.906     0.8537    0.08158     0.84\n",
      "NOTE:     21   256   0.0001            1.896     0.8307    0.08158     0.90\n",
      "NOTE:     22   256   0.0001             1.89     0.8174    0.08158     0.87\n",
      "NOTE:     23   256   0.0001            1.901     0.8341    0.08158     0.82\n",
      "NOTE:     24   256   0.0001            1.889      0.812    0.08158     0.84\n",
      "NOTE:     25   256   0.0001            1.885     0.8122    0.08158     0.92\n",
      "NOTE:     26   256   0.0001             1.88     0.8005    0.08158     0.88\n",
      "NOTE:     27   256   0.0001            1.901     0.8409    0.08158     0.87\n",
      "NOTE:     28   256   0.0001            1.909     0.8529    0.08158     0.88\n",
      "NOTE:     29   256   0.0001            1.891     0.8191    0.08158     0.83\n",
      "NOTE:     30   256   0.0001              1.9     0.8342    0.08158     0.82\n",
      "NOTE:     31   256   0.0001             1.88      0.798    0.08158     0.89\n",
      "NOTE:     32   256   0.0001            1.888     0.8146    0.08158     0.82\n",
      "NOTE:     33   256   0.0001            1.902      0.839    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.893     0.8188    0.08158     0.82\n",
      "NOTE:     35   256   0.0001            1.886     0.8095    0.08158     0.82\n",
      "NOTE:     36   256   0.0001            1.912     0.8563    0.08158     0.82\n",
      "NOTE:     37   256   0.0001             1.89     0.8196    0.08158     0.82\n",
      "NOTE:     38   256   0.0001            1.898     0.8351    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.882     0.8041    0.08158     0.82\n",
      "NOTE:     40   256   0.0001            1.886     0.8138    0.08158     0.82\n",
      "NOTE:     41   256   0.0001            1.897     0.8284    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     42   256   0.0001            1.901     0.8431    0.08158     0.83\n",
      "NOTE:     43   256   0.0001            1.887     0.8117    0.08158     0.83\n",
      "NOTE:     44   256   0.0001            1.909     0.8602    0.08158     0.82\n",
      "NOTE:     45   256   0.0001            1.904     0.8472    0.08158     0.83\n",
      "NOTE:     46   256   0.0001            1.902     0.8407    0.08158     0.88\n",
      "NOTE:     47   256   0.0001            1.884     0.8058    0.08158     0.83\n",
      "NOTE:     48   256   0.0001            1.893      0.823    0.08158     0.89\n",
      "NOTE:     49   256   0.0001              1.9     0.8384    0.08158     0.89\n",
      "NOTE:     50   256   0.0001             1.89     0.8154    0.08158     0.94\n",
      "NOTE:     51   256   0.0001            1.886     0.8179    0.08158     0.88\n",
      "NOTE:     52   256   0.0001            1.889     0.8193    0.08158     0.84\n",
      "NOTE:     53   256   0.0001            1.879     0.7995    0.08158     0.91\n",
      "NOTE:     54   256   0.0001            1.896      0.826    0.08158     0.85\n",
      "NOTE:     55   256   0.0001            1.898     0.8356    0.08158     0.84\n",
      "NOTE:     56   256   0.0001            1.908     0.8524    0.08158     0.84\n",
      "NOTE:     57   256   0.0001            1.897     0.8307    0.08158     0.85\n",
      "NOTE:     58   256   0.0001            1.889     0.8236    0.08158     0.86\n",
      "NOTE:     59   256   0.0001            1.906     0.8468    0.08158     0.84\n",
      "NOTE:     60   256   0.0001            1.906     0.8461    0.08158     0.84\n",
      "NOTE:     61   256   0.0001            1.891     0.8191    0.08158     0.86\n",
      "NOTE:     62   256   0.0001            1.878     0.7977    0.08158     0.85\n",
      "NOTE:     63   256   0.0001            1.881     0.8048    0.08158     0.84\n",
      "NOTE:     64   256   0.0001            1.905     0.8437    0.08158     0.85\n",
      "NOTE:     65   256   0.0001            1.906     0.8463    0.08158     0.85\n",
      "NOTE:     66   256   0.0001            1.906     0.8462    0.08158     0.85\n",
      "NOTE:     67   256   0.0001            1.868     0.7786    0.08158     0.86\n",
      "NOTE:     68   256   0.0001            1.907     0.8511    0.08158     0.85\n",
      "NOTE:     69   256   0.0001            1.923     0.8739    0.08158     0.85\n",
      "NOTE:     70   256   0.0001            1.879     0.7953    0.08158     0.84\n",
      "NOTE:     71   256   0.0001            1.898     0.8328    0.08158     0.85\n",
      "NOTE:     72   256   0.0001            1.912     0.8599    0.08158     0.85\n",
      "NOTE:     73   256   0.0001            1.882     0.8028    0.08158     0.85\n",
      "NOTE:     74   256   0.0001            1.889     0.8139    0.08158     0.84\n",
      "NOTE:     75   256   0.0001            1.894     0.8285    0.08158     0.85\n",
      "NOTE:     76   256   0.0001             1.89     0.8157    0.08158     0.85\n",
      "NOTE:     77   256   0.0001            1.895     0.8285    0.08158     0.85\n",
      "NOTE:     78   256   0.0001            1.904     0.8426    0.08158     0.84\n",
      "NOTE:     79   256   0.0001            1.902     0.8367    0.08158     0.85\n",
      "NOTE:     80   256   0.0001            1.908     0.8514    0.08158     0.86\n",
      "NOTE:     81   256   0.0001            1.906     0.8485    0.08158     0.86\n",
      "NOTE:     82   256   0.0001             1.93     0.8931    0.08158     0.87\n",
      "NOTE:     83   256   0.0001            1.903     0.8454    0.08158     0.84\n",
      "NOTE:     84   256   0.0001            1.889     0.8168    0.08158     0.83\n",
      "NOTE:     85   256   0.0001            1.892     0.8173    0.08158     0.83\n",
      "NOTE:     86   256   0.0001            1.902     0.8455    0.08158     0.84\n",
      "NOTE:     87   256   0.0001            1.898      0.834    0.08158     0.83\n",
      "NOTE:     88   256   0.0001            1.888     0.8174    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.915     0.8658    0.08158     0.85\n",
      "NOTE:     90   256   0.0001            1.887     0.8143    0.08158     0.85\n",
      "NOTE:     91   256   0.0001              1.9     0.8377    0.08158     0.83\n",
      "NOTE:     92   256   0.0001            1.895     0.8296    0.08158     0.83\n",
      "NOTE:     93   256   0.0001            1.905      0.849    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.899     0.8357    0.08158     0.83\n",
      "NOTE:     95   256   0.0001            1.879     0.7975    0.08158     0.82\n",
      "NOTE:     96   256   0.0001            1.897     0.8342    0.08158     0.83\n",
      "NOTE:     97   256   0.0001            1.894     0.8227    0.08158     0.83\n",
      "NOTE:     98   256   0.0001            1.884     0.8081    0.08158     0.84\n",
      "NOTE:     99   256   0.0001            1.887     0.8136    0.08158     0.82\n",
      "NOTE:    100   256   0.0001            1.887     0.8111    0.08158     0.82\n",
      "NOTE:    101   256   0.0001            1.902     0.8422    0.08158     0.82\n",
      "NOTE:    102   256   0.0001            1.884     0.8067    0.08158     0.81\n",
      "NOTE:    103   256   0.0001            1.886     0.8105    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.876     0.7937    0.08158     0.83\n",
      "NOTE:    105   256   0.0001            1.899     0.8328    0.08158     0.85\n",
      "NOTE:    106   256   0.0001            1.878     0.7979    0.08158     0.85\n",
      "NOTE:    107   256   0.0001            1.916     0.8669    0.08158     0.81\n",
      "NOTE:    108   256   0.0001            1.891     0.8185    0.08158     0.82\n",
      "NOTE:    109   256   0.0001            1.891     0.8199    0.08158     0.82\n",
      "NOTE:    110   256   0.0001            1.909     0.8529    0.08158     0.82\n",
      "NOTE:    111   256   0.0001            1.883     0.8152    0.08158     0.82\n",
      "NOTE:    112   256   0.0001            1.889     0.8179    0.08158     0.81\n",
      "NOTE:    113   256   0.0001            1.899     0.8395    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.895     0.8316    0.08158     0.82\n",
      "NOTE:    115   256   0.0001            1.887     0.8122    0.08158     0.81\n",
      "NOTE:    116   256   0.0001            1.897     0.8329    0.08158     0.82\n",
      "NOTE:    117   256   0.0001            1.882     0.8064    0.08158     0.82\n",
      "NOTE:    118   256   0.0001            1.873     0.7909    0.08158     0.82\n",
      "NOTE:    119   256   0.0001             1.87      0.781    0.08158     0.81\n",
      "NOTE:    120   256   0.0001            1.885     0.8073    0.08158     0.83\n",
      "NOTE:    121   256   0.0001            1.898     0.8331    0.08158     0.82\n",
      "NOTE:    122   256   0.0001             1.87     0.7892    0.08158     0.81\n",
      "NOTE:    123   256   0.0001            1.865      0.775    0.08158     0.89\n",
      "NOTE:    124   256   0.0001            1.889      0.815    0.08158     0.83\n",
      "NOTE:    125   256   0.0001            1.889     0.8171    0.08158     0.82\n",
      "NOTE:    126   256   0.0001            1.904      0.845    0.08158     0.82\n",
      "NOTE:    127   256   0.0001            1.908     0.8551    0.08158     0.82\n",
      "NOTE:    128   256   0.0001            1.906     0.8507    0.08158     0.82\n",
      "NOTE:    129   256   0.0001            1.877     0.7957    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.896     0.8323    0.08158     0.88\n",
      "NOTE:    131   256   0.0001             1.88     0.8044    0.08158     0.83\n",
      "NOTE:    132   256   0.0001            1.882      0.799    0.08158     0.82\n",
      "NOTE:    133   256   0.0001            1.888     0.8153    0.08158     0.82\n",
      "NOTE:    134   256   0.0001            1.887     0.8132    0.08158     0.83\n",
      "NOTE:    135   256   0.0001            1.888     0.8153    0.08158     0.83\n",
      "NOTE:    136   256   0.0001            1.878     0.7944    0.08158     0.82\n",
      "NOTE:    137   256   0.0001              1.9     0.8361    0.08158     0.83\n",
      "NOTE:    138   256   0.0001            1.881     0.8032    0.08158     0.82\n",
      "NOTE:    139   256   0.0001            1.905     0.8473    0.08158     0.87\n",
      "NOTE:    140   256   0.0001            1.877     0.7967    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.874     0.7895    0.08158     0.90\n",
      "NOTE:    142   256   0.0001            1.875     0.7902    0.08158     0.90\n",
      "NOTE:    143   256   0.0001            1.884      0.811    0.08158     0.87\n",
      "NOTE:    144   256   0.0001            1.878     0.7982    0.08158     0.83\n",
      "NOTE:    145   256   0.0001             1.88      0.801    0.08158     0.82\n",
      "NOTE:    146   256   0.0001            1.886     0.8132    0.08158     0.83\n",
      "NOTE:    147   256   0.0001            1.893     0.8248    0.08158     0.82\n",
      "NOTE:    148   256   0.0001            1.875     0.7934    0.08158     0.83\n",
      "NOTE:    149   256   0.0001            1.899     0.8382    0.08158     0.90\n",
      "NOTE:    150   256   0.0001            1.881      0.805    0.08158     0.88\n",
      "NOTE:    151   256   0.0001            1.877     0.7984    0.08158     0.83\n",
      "NOTE:    152   256   0.0001            1.882     0.8108    0.08158     0.82\n",
      "NOTE:    153   256   0.0001            1.867     0.7783    0.08158     0.83\n",
      "NOTE:    154   256   0.0001            1.886     0.8167    0.08158     0.82\n",
      "NOTE:    155   256   0.0001            1.881     0.8048    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    156   256   0.0001             1.89     0.8221    0.08158     0.90\n",
      "NOTE:    157   256   0.0001             1.89     0.8212    0.08158     0.87\n",
      "NOTE:    158   256   0.0001            1.871     0.7854    0.08158     0.82\n",
      "NOTE:    159   256   0.0001            1.896     0.8285    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.886     0.8139    0.08158     0.83\n",
      "NOTE:    161   256   0.0001            1.876     0.7969    0.08158     0.82\n",
      "NOTE:    162   256   0.0001            1.902     0.8385    0.08158     0.83\n",
      "NOTE:    163   256   0.0001            1.887     0.8123    0.08158     0.90\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  1        0.0001           1.892     0.8235   138.18\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.884     0.8103    0.08158     0.87\n",
      "NOTE:      1   256   0.0001            1.886     0.8121    0.08158     0.82\n",
      "NOTE:      2   256   0.0001            1.889     0.8216    0.08158     0.83\n",
      "NOTE:      3   256   0.0001            1.885     0.8141    0.08158     0.82\n",
      "NOTE:      4   256   0.0001            1.881     0.7993    0.08158     0.87\n",
      "NOTE:      5   256   0.0001            1.882      0.809    0.08158     0.82\n",
      "NOTE:      6   256   0.0001            1.879     0.7971    0.08158     0.83\n",
      "NOTE:      7   256   0.0001            1.891     0.8223    0.08158     0.84\n",
      "NOTE:      8   256   0.0001            1.885     0.8091    0.08158     0.83\n",
      "NOTE:      9   256   0.0001            1.889     0.8168    0.08158     0.84\n",
      "NOTE:     10   256   0.0001            1.885     0.8152    0.08158     0.89\n",
      "NOTE:     11   256   0.0001            1.867     0.7779    0.08158     0.87\n",
      "NOTE:     12   256   0.0001            1.887     0.8086    0.08158     0.83\n",
      "NOTE:     13   256   0.0001            1.893     0.8284    0.08158     0.83\n",
      "NOTE:     14   256   0.0001            1.905     0.8481    0.08158     0.84\n",
      "NOTE:     15   256   0.0001            1.893     0.8258    0.08158     0.83\n",
      "NOTE:     16   256   0.0001            1.896     0.8362    0.08158     0.83\n",
      "NOTE:     17   256   0.0001            1.891      0.825    0.08158     0.83\n",
      "NOTE:     18   256   0.0001            1.884     0.8124    0.08158     0.82\n",
      "NOTE:     19   256   0.0001            1.871     0.7905    0.08158     0.82\n",
      "NOTE:     20   256   0.0001            1.895     0.8299    0.08158     0.83\n",
      "NOTE:     21   256   0.0001            1.885     0.8149    0.08158     0.83\n",
      "NOTE:     22   256   0.0001            1.865      0.778    0.08158     0.83\n",
      "NOTE:     23   256   0.0001            1.886     0.8135    0.08158     0.88\n",
      "NOTE:     24   256   0.0001            1.885     0.8112    0.08158     0.84\n",
      "NOTE:     25   256   0.0001            1.898     0.8389    0.08158     0.83\n",
      "NOTE:     26   256   0.0001            1.872     0.7907    0.08158     0.83\n",
      "NOTE:     27   256   0.0001            1.887      0.814    0.08158     0.82\n",
      "NOTE:     28   256   0.0001            1.886      0.815    0.08158     0.82\n",
      "NOTE:     29   256   0.0001            1.898     0.8335    0.08158     0.82\n",
      "NOTE:     30   256   0.0001            1.898     0.8403    0.08158     0.82\n",
      "NOTE:     31   256   0.0001            1.862      0.769    0.08158     0.82\n",
      "NOTE:     32   256   0.0001            1.893     0.8282    0.08158     0.86\n",
      "NOTE:     33   256   0.0001            1.878     0.7994    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.887     0.8171    0.08158     0.82\n",
      "NOTE:     35   256   0.0001            1.873      0.792    0.08158     0.82\n",
      "NOTE:     36   256   0.0001            1.871     0.7898    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.872     0.7921    0.08158     0.83\n",
      "NOTE:     38   256   0.0001            1.888     0.8183    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.876     0.7962    0.08158     0.82\n",
      "NOTE:     40   256   0.0001             1.89     0.8188    0.08158     0.83\n",
      "NOTE:     41   256   0.0001            1.906     0.8518    0.08158     0.82\n",
      "NOTE:     42   256   0.0001            1.908     0.8554    0.08158     0.82\n",
      "NOTE:     43   256   0.0001            1.876     0.7938    0.08158     0.82\n",
      "NOTE:     44   256   0.0001            1.875     0.7979    0.08158     0.83\n",
      "NOTE:     45   256   0.0001            1.884     0.8097    0.08158     0.83\n",
      "NOTE:     46   256   0.0001             1.89     0.8209    0.08158     0.82\n",
      "NOTE:     47   256   0.0001            1.865     0.7759    0.08158     0.83\n",
      "NOTE:     48   256   0.0001            1.902     0.8439    0.08158     0.82\n",
      "NOTE:     49   256   0.0001            1.897     0.8355    0.08158     0.82\n",
      "NOTE:     50   256   0.0001            1.883     0.8069    0.08158     0.84\n",
      "NOTE:     51   256   0.0001            1.878     0.8016    0.08158     0.82\n",
      "NOTE:     52   256   0.0001            1.877     0.7999    0.08158     0.82\n",
      "NOTE:     53   256   0.0001            1.864     0.7783    0.08158     0.82\n",
      "NOTE:     54   256   0.0001            1.901     0.8433    0.08158     0.83\n",
      "NOTE:     55   256   0.0001            1.859     0.7671    0.08158     0.82\n",
      "NOTE:     56   256   0.0001             1.89     0.8238    0.08158     0.82\n",
      "NOTE:     57   256   0.0001            1.887     0.8222    0.08158     0.84\n",
      "NOTE:     58   256   0.0001            1.886     0.8163    0.08158     0.83\n",
      "NOTE:     59   256   0.0001             1.89     0.8256    0.08158     0.84\n",
      "NOTE:     60   256   0.0001            1.884     0.8074    0.08158     0.83\n",
      "NOTE:     61   256   0.0001            1.882     0.8077    0.08158     0.83\n",
      "NOTE:     62   256   0.0001            1.873      0.792    0.08158     0.83\n",
      "NOTE:     63   256   0.0001            1.882     0.8062    0.08158     0.83\n",
      "NOTE:     64   256   0.0001            1.896     0.8344    0.08158     0.83\n",
      "NOTE:     65   256   0.0001            1.877     0.7945    0.08158     0.84\n",
      "NOTE:     66   256   0.0001            1.886     0.8107    0.08158     0.83\n",
      "NOTE:     67   256   0.0001            1.874     0.7952    0.08158     0.83\n",
      "NOTE:     68   256   0.0001            1.883     0.8108    0.08158     0.83\n",
      "NOTE:     69   256   0.0001            1.872     0.7921    0.08158     0.83\n",
      "NOTE:     70   256   0.0001            1.883     0.8108    0.08158     0.82\n",
      "NOTE:     71   256   0.0001            1.901     0.8443    0.08158     0.83\n",
      "NOTE:     72   256   0.0001            1.893     0.8275    0.08158     0.83\n",
      "NOTE:     73   256   0.0001            1.897     0.8369    0.08158     0.83\n",
      "NOTE:     74   256   0.0001            1.879     0.7988    0.08158     0.82\n",
      "NOTE:     75   256   0.0001            1.891      0.823    0.08158     0.83\n",
      "NOTE:     76   256   0.0001            1.884     0.8118    0.08158     0.83\n",
      "NOTE:     77   256   0.0001              1.9     0.8409    0.08158     0.82\n",
      "NOTE:     78   256   0.0001            1.869      0.782    0.08158     0.82\n",
      "NOTE:     79   256   0.0001            1.888     0.8213    0.08158     0.83\n",
      "NOTE:     80   256   0.0001            1.879      0.803    0.08158     0.82\n",
      "NOTE:     81   256   0.0001             1.87     0.7857    0.08158     0.83\n",
      "NOTE:     82   256   0.0001            1.888     0.8164    0.08158     0.82\n",
      "NOTE:     83   256   0.0001            1.886      0.815    0.08158     0.82\n",
      "NOTE:     84   256   0.0001            1.887     0.8133    0.08158     0.83\n",
      "NOTE:     85   256   0.0001            1.879     0.8015    0.08158     0.84\n",
      "NOTE:     86   256   0.0001            1.872     0.7911    0.08158     0.83\n",
      "NOTE:     87   256   0.0001            1.885      0.816    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.885     0.8116    0.08158     0.83\n",
      "NOTE:     89   256   0.0001            1.866     0.7801    0.08158     0.83\n",
      "NOTE:     90   256   0.0001            1.898     0.8425    0.08158     0.82\n",
      "NOTE:     91   256   0.0001            1.872     0.7941    0.08158     0.82\n",
      "NOTE:     92   256   0.0001            1.886      0.814    0.08158     0.82\n",
      "NOTE:     93   256   0.0001            1.867     0.7838    0.08158     0.83\n",
      "NOTE:     94   256   0.0001            1.883     0.8139    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.894     0.8378    0.08158     0.83\n",
      "NOTE:     96   256   0.0001             1.88     0.8097    0.08158     0.83\n",
      "NOTE:     97   256   0.0001            1.884     0.8081    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     98   256   0.0001            1.897     0.8396    0.08158     0.87\n",
      "NOTE:     99   256   0.0001            1.859     0.7648    0.08158     0.82\n",
      "NOTE:    100   256   0.0001            1.875     0.7964    0.08158     0.81\n",
      "NOTE:    101   256   0.0001            1.874      0.796    0.08158     0.90\n",
      "NOTE:    102   256   0.0001             1.86     0.7722    0.08158     0.82\n",
      "NOTE:    103   256   0.0001             1.89     0.8228    0.08158     0.82\n",
      "NOTE:    104   256   0.0001            1.873      0.796    0.08158     0.88\n",
      "NOTE:    105   256   0.0001            1.893     0.8287    0.08158     0.83\n",
      "NOTE:    106   256   0.0001            1.869     0.7885    0.08158     0.83\n",
      "NOTE:    107   256   0.0001            1.893     0.8283    0.08158     0.84\n",
      "NOTE:    108   256   0.0001            1.884     0.8127    0.08158     0.83\n",
      "NOTE:    109   256   0.0001            1.892     0.8287    0.08158     0.84\n",
      "NOTE:    110   256   0.0001            1.893     0.8278    0.08158     0.84\n",
      "NOTE:    111   256   0.0001            1.891      0.821    0.08158     0.88\n",
      "NOTE:    112   256   0.0001            1.863     0.7752    0.08158     0.82\n",
      "NOTE:    113   256   0.0001            1.876     0.7959    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.891     0.8274    0.08158     0.84\n",
      "NOTE:    115   256   0.0001            1.894     0.8327    0.08158     0.83\n",
      "NOTE:    116   256   0.0001            1.874     0.7922    0.08158     0.84\n",
      "NOTE:    117   256   0.0001            1.857     0.7611    0.08158     0.91\n",
      "NOTE:    118   256   0.0001            1.898     0.8426    0.08158     0.86\n",
      "NOTE:    119   256   0.0001            1.878     0.8024    0.08158     0.81\n",
      "NOTE:    120   256   0.0001            1.878     0.8001    0.08158     0.82\n",
      "NOTE:    121   256   0.0001            1.868     0.7825    0.08158     0.82\n",
      "NOTE:    122   256   0.0001            1.873     0.7974    0.08158     0.81\n",
      "NOTE:    123   256   0.0001             1.87     0.7917    0.08158     0.82\n",
      "NOTE:    124   256   0.0001            1.882     0.8115    0.08158     0.82\n",
      "NOTE:    125   256   0.0001            1.885     0.8178    0.08158     0.83\n",
      "NOTE:    126   256   0.0001            1.883      0.817    0.08158     0.83\n",
      "NOTE:    127   256   0.0001            1.886     0.8114    0.08158     0.83\n",
      "NOTE:    128   256   0.0001            1.874     0.7937    0.08158     0.83\n",
      "NOTE:    129   256   0.0001            1.876     0.7994    0.08158     0.82\n",
      "NOTE:    130   256   0.0001             1.89     0.8179    0.08158     0.84\n",
      "NOTE:    131   256   0.0001            1.873     0.7936    0.08158     0.84\n",
      "NOTE:    132   256   0.0001            1.869     0.7879    0.08158     0.83\n",
      "NOTE:    133   256   0.0001            1.871     0.7911    0.08158     0.83\n",
      "NOTE:    134   256   0.0001            1.887     0.8191    0.08158     0.83\n",
      "NOTE:    135   256   0.0001            1.873     0.7949    0.08158     0.83\n",
      "NOTE:    136   256   0.0001            1.868      0.778    0.08158     0.82\n",
      "NOTE:    137   256   0.0001            1.873     0.7937    0.08158     0.83\n",
      "NOTE:    138   256   0.0001            1.881     0.8083    0.08158     0.83\n",
      "NOTE:    139   256   0.0001            1.879     0.8034    0.08158     0.82\n",
      "NOTE:    140   256   0.0001             1.89     0.8231    0.08158     0.82\n",
      "NOTE:    141   256   0.0001            1.881     0.8014    0.08158     0.83\n",
      "NOTE:    142   256   0.0001            1.859     0.7674    0.08158     0.82\n",
      "NOTE:    143   256   0.0001            1.879     0.8051    0.08158     0.82\n",
      "NOTE:    144   256   0.0001            1.874     0.7919    0.08158     0.82\n",
      "NOTE:    145   256   0.0001            1.868     0.7853    0.08158     0.83\n",
      "NOTE:    146   256   0.0001            1.884     0.8158    0.08158     0.83\n",
      "NOTE:    147   256   0.0001            1.873     0.7951    0.08158     0.82\n",
      "NOTE:    148   256   0.0001            1.876     0.8029    0.08158     0.83\n",
      "NOTE:    149   256   0.0001            1.857     0.7624    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.855     0.7616    0.08158     0.82\n",
      "NOTE:    151   256   0.0001            1.877     0.8042    0.08158     0.83\n",
      "NOTE:    152   256   0.0001             1.89     0.8234    0.08158     0.82\n",
      "NOTE:    153   256   0.0001            1.874     0.7914    0.08158     0.82\n",
      "NOTE:    154   256   0.0001            1.876     0.7986    0.08158     0.82\n",
      "NOTE:    155   256   0.0001            1.869     0.7847    0.08158     0.83\n",
      "NOTE:    156   256   0.0001            1.878      0.811    0.08158     0.83\n",
      "NOTE:    157   256   0.0001            1.896     0.8301    0.08158     0.82\n",
      "NOTE:    158   256   0.0001            1.873     0.7962    0.08158     0.82\n",
      "NOTE:    159   256   0.0001             1.86     0.7734    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.876     0.8021    0.08158     0.82\n",
      "NOTE:    161   256   0.0001            1.891     0.8232    0.08158     0.83\n",
      "NOTE:    162   256   0.0001            1.881     0.8065    0.08158     0.83\n",
      "NOTE:    163   256   0.0001            1.864     0.7805    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  2        0.0001           1.881     0.8075   136.16\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.874     0.7915    0.08158     0.82\n",
      "NOTE:      1   256   0.0001            1.881     0.8052    0.08158     0.83\n",
      "NOTE:      2   256   0.0001            1.877     0.8039    0.08158     0.82\n",
      "NOTE:      3   256   0.0001            1.875     0.7925    0.08158     0.82\n",
      "NOTE:      4   256   0.0001            1.871     0.7906    0.08158     0.82\n",
      "NOTE:      5   256   0.0001            1.878     0.7974    0.08158     0.82\n",
      "NOTE:      6   256   0.0001            1.876     0.7988    0.08158     0.82\n",
      "NOTE:      7   256   0.0001            1.886     0.8147    0.08158     0.83\n",
      "NOTE:      8   256   0.0001            1.874      0.797    0.08158     0.82\n",
      "NOTE:      9   256   0.0001            1.878     0.8051    0.08158     0.82\n",
      "NOTE:     10   256   0.0001            1.878     0.8021    0.08158     0.82\n",
      "NOTE:     11   256   0.0001            1.884     0.8099    0.08158     0.82\n",
      "NOTE:     12   256   0.0001            1.873      0.798    0.08158     0.83\n",
      "NOTE:     13   256   0.0001            1.855     0.7604    0.08158     0.82\n",
      "NOTE:     14   256   0.0001            1.864     0.7731    0.08158     0.83\n",
      "NOTE:     15   256   0.0001            1.882     0.8111    0.08158     0.82\n",
      "NOTE:     16   256   0.0001            1.879      0.799    0.08158     0.82\n",
      "NOTE:     17   256   0.0001            1.868     0.7832    0.08158     0.83\n",
      "NOTE:     18   256   0.0001            1.875     0.7988    0.08158     0.83\n",
      "NOTE:     19   256   0.0001            1.865     0.7788    0.08158     0.82\n",
      "NOTE:     20   256   0.0001            1.898     0.8433    0.08158     0.82\n",
      "NOTE:     21   256   0.0001            1.869     0.7813    0.08158     0.82\n",
      "NOTE:     22   256   0.0001            1.895     0.8333    0.08158     0.82\n",
      "NOTE:     23   256   0.0001            1.877     0.8017    0.08158     0.82\n",
      "NOTE:     24   256   0.0001            1.874     0.7937    0.08158     0.82\n",
      "NOTE:     25   256   0.0001            1.865     0.7802    0.08158     0.82\n",
      "NOTE:     26   256   0.0001            1.892     0.8264    0.08158     0.82\n",
      "NOTE:     27   256   0.0001            1.865     0.7809    0.08158     0.83\n",
      "NOTE:     28   256   0.0001            1.872     0.7921    0.08158     0.82\n",
      "NOTE:     29   256   0.0001            1.844     0.7473    0.08158     0.83\n",
      "NOTE:     30   256   0.0001            1.869      0.784    0.08158     0.82\n",
      "NOTE:     31   256   0.0001            1.874     0.7993    0.08158     0.83\n",
      "NOTE:     32   256   0.0001            1.871     0.7898    0.08158     0.82\n",
      "NOTE:     33   256   0.0001            1.858     0.7647    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.878     0.8035    0.08158     0.83\n",
      "NOTE:     35   256   0.0001            1.876     0.7931    0.08158     0.83\n",
      "NOTE:     36   256   0.0001            1.864     0.7763    0.08158     0.82\n",
      "NOTE:     37   256   0.0001            1.889     0.8226    0.08158     0.82\n",
      "NOTE:     38   256   0.0001            1.847     0.7546    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.872     0.7893    0.08158     0.83\n",
      "NOTE:     40   256   0.0001            1.873     0.7884    0.08158     0.82\n",
      "NOTE:     41   256   0.0001            1.882     0.8099    0.08158     0.83\n",
      "NOTE:     42   256   0.0001            1.874     0.7918    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     43   256   0.0001            1.865     0.7828    0.08158     0.82\n",
      "NOTE:     44   256   0.0001            1.867     0.7841    0.08158     0.83\n",
      "NOTE:     45   256   0.0001            1.899     0.8441    0.08158     0.82\n",
      "NOTE:     46   256   0.0001             1.87     0.7917    0.08158     0.82\n",
      "NOTE:     47   256   0.0001            1.883     0.8095    0.08158     0.82\n",
      "NOTE:     48   256   0.0001            1.854     0.7608    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.865     0.7791    0.08158     0.83\n",
      "NOTE:     50   256   0.0001             1.87     0.7845    0.08158     0.82\n",
      "NOTE:     51   256   0.0001            1.879      0.808    0.08158     0.82\n",
      "NOTE:     52   256   0.0001            1.863     0.7764    0.08158     0.82\n",
      "NOTE:     53   256   0.0001            1.882     0.8166    0.08158     0.82\n",
      "NOTE:     54   256   0.0001            1.863     0.7787    0.08158     0.82\n",
      "NOTE:     55   256   0.0001            1.885     0.8153    0.08158     0.82\n",
      "NOTE:     56   256   0.0001            1.862     0.7739    0.08158     0.82\n",
      "NOTE:     57   256   0.0001            1.883     0.8102    0.08158     0.82\n",
      "NOTE:     58   256   0.0001            1.861     0.7745    0.08158     0.83\n",
      "NOTE:     59   256   0.0001            1.893      0.835    0.08158     0.88\n",
      "NOTE:     60   256   0.0001            1.893     0.8317    0.08158     0.82\n",
      "NOTE:     61   256   0.0001            1.872     0.7919    0.08158     0.87\n",
      "NOTE:     62   256   0.0001            1.861     0.7703    0.08158     0.83\n",
      "NOTE:     63   256   0.0001            1.851     0.7565    0.08158     0.82\n",
      "NOTE:     64   256   0.0001            1.891     0.8295    0.08158     0.81\n",
      "NOTE:     65   256   0.0001            1.879     0.8036    0.08158     0.82\n",
      "NOTE:     66   256   0.0001            1.866     0.7806    0.08158     0.82\n",
      "NOTE:     67   256   0.0001            1.878     0.8037    0.08158     0.82\n",
      "NOTE:     68   256   0.0001            1.877     0.7959    0.08158     0.88\n",
      "NOTE:     69   256   0.0001            1.855     0.7681    0.08158     0.83\n",
      "NOTE:     70   256   0.0001            1.863     0.7789    0.08158     0.82\n",
      "NOTE:     71   256   0.0001             1.86     0.7724    0.08158     0.82\n",
      "NOTE:     72   256   0.0001            1.859      0.774    0.08158     0.84\n",
      "NOTE:     73   256   0.0001            1.879     0.8068    0.08158     0.82\n",
      "NOTE:     74   256   0.0001             1.87     0.7947    0.08158     0.82\n",
      "NOTE:     75   256   0.0001            1.872     0.7893    0.08158     0.82\n",
      "NOTE:     76   256   0.0001            1.887      0.817    0.08158     0.82\n",
      "NOTE:     77   256   0.0001            1.876     0.7961    0.08158     0.88\n",
      "NOTE:     78   256   0.0001            1.869     0.7872    0.08158     0.83\n",
      "NOTE:     79   256   0.0001            1.868     0.7849    0.08158     0.83\n",
      "NOTE:     80   256   0.0001            1.877     0.8004    0.08158     0.83\n",
      "NOTE:     81   256   0.0001            1.862     0.7757    0.08158     0.82\n",
      "NOTE:     82   256   0.0001            1.848      0.764    0.08158     0.82\n",
      "NOTE:     83   256   0.0001            1.872      0.788    0.08158     0.83\n",
      "NOTE:     84   256   0.0001            1.869     0.7846    0.08158     0.82\n",
      "NOTE:     85   256   0.0001            1.888     0.8227    0.08158     0.82\n",
      "NOTE:     86   256   0.0001            1.876     0.7978    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.849     0.7533    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.876     0.8039    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.866     0.7847    0.08158     0.82\n",
      "NOTE:     90   256   0.0001            1.858     0.7692    0.08158     0.83\n",
      "NOTE:     91   256   0.0001            1.866     0.7809    0.08158     0.82\n",
      "NOTE:     92   256   0.0001            1.862     0.7764    0.08158     0.82\n",
      "NOTE:     93   256   0.0001            1.874     0.7958    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.869     0.7879    0.08158     0.86\n",
      "NOTE:     95   256   0.0001            1.874     0.8012    0.08158     0.82\n",
      "NOTE:     96   256   0.0001            1.873     0.7928    0.08158     0.84\n",
      "NOTE:     97   256   0.0001            1.854     0.7579    0.08158     0.83\n",
      "NOTE:     98   256   0.0001            1.875     0.7997    0.08158     0.82\n",
      "NOTE:     99   256   0.0001            1.848     0.7547    0.08158     0.85\n",
      "NOTE:    100   256   0.0001             1.88     0.8134    0.08158     0.91\n",
      "NOTE:    101   256   0.0001             1.89      0.828    0.08158     0.87\n",
      "NOTE:    102   256   0.0001            1.897     0.8377    0.08158     0.80\n",
      "NOTE:    103   256   0.0001            1.858      0.768    0.08158     0.82\n",
      "NOTE:    104   256   0.0001            1.869     0.7903    0.08158     0.83\n",
      "NOTE:    105   256   0.0001            1.863     0.7797    0.08158     0.83\n",
      "NOTE:    106   256   0.0001            1.858     0.7662    0.08158     0.83\n",
      "NOTE:    107   256   0.0001            1.865     0.7831    0.08158     0.83\n",
      "NOTE:    108   256   0.0001            1.861     0.7743    0.08158     0.83\n",
      "NOTE:    109   256   0.0001             1.87     0.7884    0.08158     0.82\n",
      "NOTE:    110   256   0.0001            1.866     0.7825    0.08158     0.83\n",
      "NOTE:    111   256   0.0001            1.856     0.7713    0.08158     0.82\n",
      "NOTE:    112   256   0.0001            1.882     0.8134    0.08158     0.82\n",
      "NOTE:    113   256   0.0001            1.855     0.7722    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.868     0.7898    0.08158     0.90\n",
      "NOTE:    115   256   0.0001            1.858     0.7706    0.08158     0.90\n",
      "NOTE:    116   256   0.0001            1.874     0.7944    0.08158     0.88\n",
      "NOTE:    117   256   0.0001            1.862     0.7773    0.08158     0.83\n",
      "NOTE:    118   256   0.0001            1.856     0.7668    0.08158     0.82\n",
      "NOTE:    119   256   0.0001            1.865      0.787    0.08158     0.81\n",
      "NOTE:    120   256   0.0001            1.862     0.7769    0.08158     0.85\n",
      "NOTE:    121   256   0.0001            1.848     0.7577    0.08158     0.82\n",
      "NOTE:    122   256   0.0001            1.862     0.7787    0.08158     0.83\n",
      "NOTE:    123   256   0.0001            1.877     0.8028    0.08158     0.82\n",
      "NOTE:    124   256   0.0001            1.874     0.7979    0.08158     0.89\n",
      "NOTE:    125   256   0.0001            1.878     0.8098    0.08158     0.87\n",
      "NOTE:    126   256   0.0001            1.871     0.8049    0.08158     0.85\n",
      "NOTE:    127   256   0.0001            1.862     0.7794    0.08158     0.83\n",
      "NOTE:    128   256   0.0001            1.886     0.8171    0.08158     0.83\n",
      "NOTE:    129   256   0.0001             1.87     0.7882    0.08158     0.85\n",
      "NOTE:    130   256   0.0001            1.865     0.7808    0.08158     0.83\n",
      "NOTE:    131   256   0.0001            1.866     0.7806    0.08158     0.84\n",
      "NOTE:    132   256   0.0001            1.878     0.7994    0.08158     0.88\n",
      "NOTE:    133   256   0.0001            1.873     0.7938    0.08158     0.83\n",
      "NOTE:    134   256   0.0001             1.85     0.7545    0.08158     0.88\n",
      "NOTE:    135   256   0.0001            1.844     0.7486    0.08158     0.84\n",
      "NOTE:    136   256   0.0001            1.858     0.7699    0.08158     0.84\n",
      "NOTE:    137   256   0.0001            1.874     0.7987    0.08158     0.82\n",
      "NOTE:    138   256   0.0001            1.874     0.7954    0.08158     0.83\n",
      "NOTE:    139   256   0.0001             1.88     0.8056    0.08158     0.82\n",
      "NOTE:    140   256   0.0001            1.867      0.789    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.878     0.8066    0.08158     0.82\n",
      "NOTE:    142   256   0.0001            1.865     0.7803    0.08158     0.83\n",
      "NOTE:    143   256   0.0001            1.878     0.8049    0.08158     0.83\n",
      "NOTE:    144   256   0.0001            1.873      0.793    0.08158     0.82\n",
      "NOTE:    145   256   0.0001            1.881     0.8091    0.08158     0.83\n",
      "NOTE:    146   256   0.0001            1.875     0.7923    0.08158     0.87\n",
      "NOTE:    147   256   0.0001            1.858     0.7719    0.08158     0.90\n",
      "NOTE:    148   256   0.0001            1.873     0.7954    0.08158     0.87\n",
      "NOTE:    149   256   0.0001            1.872     0.7992    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.885     0.8152    0.08158     0.83\n",
      "NOTE:    151   256   0.0001            1.865       0.78    0.08158     0.83\n",
      "NOTE:    152   256   0.0001             1.87     0.7897    0.08158     0.83\n",
      "NOTE:    153   256   0.0001            1.852     0.7575    0.08158     0.84\n",
      "NOTE:    154   256   0.0001            1.851     0.7601    0.08158     0.84\n",
      "NOTE:    155   256   0.0001            1.862      0.775    0.08158     0.83\n",
      "NOTE:    156   256   0.0001            1.856     0.7687    0.08158     0.83\n",
      "NOTE:    157   256   0.0001            1.851     0.7549    0.08158     0.90\n",
      "NOTE:    158   256   0.0001            1.866     0.7842    0.08158     0.88\n",
      "NOTE:    159   256   0.0001             1.88      0.809    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.858     0.7727    0.08158     0.82\n",
      "NOTE:    161   256   0.0001            1.866     0.7826    0.08158     0.82\n",
      "NOTE:    162   256   0.0001            1.875     0.8028    0.08158     0.81\n",
      "NOTE:    163   256   0.0001            1.863      0.779    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  3        0.0001            1.87     0.7901   136.42\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.878     0.8084    0.08158     0.82\n",
      "NOTE:      1   256   0.0001            1.862      0.779    0.08158     0.82\n",
      "NOTE:      2   256   0.0001            1.871     0.7924    0.08158     0.82\n",
      "NOTE:      3   256   0.0001            1.852     0.7583    0.08158     0.82\n",
      "NOTE:      4   256   0.0001            1.857     0.7694    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:      5   256   0.0001            1.847     0.7524    0.08158     0.82\n",
      "NOTE:      6   256   0.0001            1.868     0.7891    0.08158     0.83\n",
      "NOTE:      7   256   0.0001            1.876     0.8061    0.08158     0.82\n",
      "NOTE:      8   256   0.0001            1.882     0.8091    0.08158     0.83\n",
      "NOTE:      9   256   0.0001            1.848     0.7521    0.08158     0.83\n",
      "NOTE:     10   256   0.0001            1.842     0.7461    0.08158     0.83\n",
      "NOTE:     11   256   0.0001            1.861      0.779    0.08158     0.88\n",
      "NOTE:     12   256   0.0001            1.866     0.7841    0.08158     0.88\n",
      "NOTE:     13   256   0.0001            1.867     0.7865    0.08158     0.83\n",
      "NOTE:     14   256   0.0001            1.855     0.7641    0.08158     0.84\n",
      "NOTE:     15   256   0.0001            1.853     0.7623    0.08158     0.88\n",
      "NOTE:     16   256   0.0001            1.837     0.7382    0.08158     0.84\n",
      "NOTE:     17   256   0.0001            1.868     0.7849    0.08158     0.83\n",
      "NOTE:     18   256   0.0001            1.883     0.8227    0.08158     0.83\n",
      "NOTE:     19   256   0.0001            1.862      0.775    0.08158     0.83\n",
      "NOTE:     20   256   0.0001            1.846     0.7525    0.08158     0.83\n",
      "NOTE:     21   256   0.0001            1.857     0.7742    0.08158     0.83\n",
      "NOTE:     22   256   0.0001            1.882     0.8171    0.08158     0.83\n",
      "NOTE:     23   256   0.0001            1.852     0.7607    0.08158     0.86\n",
      "NOTE:     24   256   0.0001            1.868     0.7987    0.08158     0.89\n",
      "NOTE:     25   256   0.0001            1.869       0.79    0.08158     0.83\n",
      "NOTE:     26   256   0.0001            1.852     0.7623    0.08158     0.83\n",
      "NOTE:     27   256   0.0001            1.864     0.7848    0.08158     0.84\n",
      "NOTE:     28   256   0.0001            1.887     0.8172    0.08158     0.82\n",
      "NOTE:     29   256   0.0001            1.859     0.7727    0.08158     0.82\n",
      "NOTE:     30   256   0.0001            1.865     0.7859    0.08158     0.81\n",
      "NOTE:     31   256   0.0001            1.881     0.8051    0.08158     0.83\n",
      "NOTE:     32   256   0.0001            1.857     0.7717    0.08158     0.83\n",
      "NOTE:     33   256   0.0001            1.876     0.8016    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.875     0.8004    0.08158     0.83\n",
      "NOTE:     35   256   0.0001            1.873     0.7936    0.08158     0.85\n",
      "NOTE:     36   256   0.0001            1.877     0.8076    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.844     0.7514    0.08158     0.86\n",
      "NOTE:     38   256   0.0001            1.844     0.7438    0.08158     0.83\n",
      "NOTE:     39   256   0.0001            1.852     0.7587    0.08158     0.83\n",
      "NOTE:     40   256   0.0001            1.841      0.746    0.08158     0.81\n",
      "NOTE:     41   256   0.0001            1.868      0.787    0.08158     0.83\n",
      "NOTE:     42   256   0.0001            1.868     0.7849    0.08158     0.90\n",
      "NOTE:     43   256   0.0001             1.86     0.7753    0.08158     0.87\n",
      "NOTE:     44   256   0.0001             1.85     0.7616    0.08158     0.82\n",
      "NOTE:     45   256   0.0001            1.867     0.7897    0.08158     0.83\n",
      "NOTE:     46   256   0.0001            1.854     0.7605    0.08158     0.90\n",
      "NOTE:     47   256   0.0001            1.847     0.7485    0.08158     0.87\n",
      "NOTE:     48   256   0.0001            1.863     0.7826    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.849     0.7636    0.08158     0.83\n",
      "NOTE:     50   256   0.0001            1.868     0.7912    0.08158     0.83\n",
      "NOTE:     51   256   0.0001            1.856     0.7718    0.08158     0.86\n",
      "NOTE:     52   256   0.0001             1.86     0.7731    0.08158     0.82\n",
      "NOTE:     53   256   0.0001             1.85     0.7582    0.08158     0.85\n",
      "NOTE:     54   256   0.0001            1.865      0.781    0.08158     0.88\n",
      "NOTE:     55   256   0.0001            1.813     0.6926    0.08158     0.85\n",
      "NOTE:     56   256   0.0001            1.865     0.7844    0.08158     0.83\n",
      "NOTE:     57   256   0.0001            1.881     0.8128    0.08158     0.87\n",
      "NOTE:     58   256   0.0001            1.851      0.761    0.08158     0.82\n",
      "NOTE:     59   256   0.0001            1.852     0.7638    0.08158     0.82\n",
      "NOTE:     60   256   0.0001             1.84     0.7399    0.08158     0.90\n",
      "NOTE:     61   256   0.0001             1.86     0.7786    0.08158     0.90\n",
      "NOTE:     62   256   0.0001            1.865      0.782    0.08158     0.87\n",
      "NOTE:     63   256   0.0001            1.866     0.7897    0.08158     0.83\n",
      "NOTE:     64   256   0.0001            1.867     0.7879    0.08158     0.88\n",
      "NOTE:     65   256   0.0001            1.843     0.7435    0.08158     0.87\n",
      "NOTE:     66   256   0.0001            1.844     0.7418    0.08158     0.83\n",
      "NOTE:     67   256   0.0001            1.867     0.7872    0.08158     0.82\n",
      "NOTE:     68   256   0.0001            1.872     0.8029    0.08158     0.84\n",
      "NOTE:     69   256   0.0001            1.844     0.7498    0.08158     0.83\n",
      "NOTE:     70   256   0.0001            1.864     0.7896    0.08158     0.84\n",
      "NOTE:     71   256   0.0001            1.838     0.7372    0.08158     0.83\n",
      "NOTE:     72   256   0.0001            1.865     0.7782    0.08158     0.83\n",
      "NOTE:     73   256   0.0001            1.857     0.7715    0.08158     0.83\n",
      "NOTE:     74   256   0.0001            1.844     0.7483    0.08158     0.83\n",
      "NOTE:     75   256   0.0001             1.86     0.7788    0.08158     0.83\n",
      "NOTE:     76   256   0.0001            1.856     0.7659    0.08158     0.82\n",
      "NOTE:     77   256   0.0001             1.86     0.7717    0.08158     0.82\n",
      "NOTE:     78   256   0.0001            1.849     0.7531    0.08158     0.88\n",
      "NOTE:     79   256   0.0001             1.84     0.7502    0.08158     0.88\n",
      "NOTE:     80   256   0.0001            1.866     0.7896    0.08158     0.83\n",
      "NOTE:     81   256   0.0001            1.859     0.7724    0.08158     0.84\n",
      "NOTE:     82   256   0.0001            1.853     0.7607    0.08158     0.85\n",
      "NOTE:     83   256   0.0001             1.85     0.7591    0.08158     0.83\n",
      "NOTE:     84   256   0.0001            1.863      0.781    0.08158     0.84\n",
      "NOTE:     85   256   0.0001            1.854     0.7635    0.08158     0.83\n",
      "NOTE:     86   256   0.0001            1.824      0.708    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.873     0.8011    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.845     0.7509    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.835     0.7331    0.08158     0.83\n",
      "NOTE:     90   256   0.0001            1.884     0.8171    0.08158     0.82\n",
      "NOTE:     91   256   0.0001            1.845     0.7478    0.08158     0.83\n",
      "NOTE:     92   256   0.0001            1.852      0.759    0.08158     0.83\n",
      "NOTE:     93   256   0.0001            1.848     0.7497    0.08158     0.83\n",
      "NOTE:     94   256   0.0001            1.836     0.7324    0.08158     0.83\n",
      "NOTE:     95   256   0.0001             1.86     0.7854    0.08158     0.83\n",
      "NOTE:     96   256   0.0001            1.847     0.7547    0.08158     0.83\n",
      "NOTE:     97   256   0.0001            1.851     0.7575    0.08158     0.82\n",
      "NOTE:     98   256   0.0001            1.867      0.785    0.08158     0.82\n",
      "NOTE:     99   256   0.0001            1.836     0.7348    0.08158     0.82\n",
      "NOTE:    100   256   0.0001            1.875     0.8022    0.08158     0.85\n",
      "NOTE:    101   256   0.0001            1.852     0.7645    0.08158     0.83\n",
      "NOTE:    102   256   0.0001            1.841     0.7423    0.08158     0.82\n",
      "NOTE:    103   256   0.0001            1.858     0.7734    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.853     0.7667    0.08158     0.82\n",
      "NOTE:    105   256   0.0001            1.851     0.7588    0.08158     0.83\n",
      "NOTE:    106   256   0.0001            1.856     0.7661    0.08158     0.86\n",
      "NOTE:    107   256   0.0001             1.86     0.7784    0.08158     0.90\n",
      "NOTE:    108   256   0.0001             1.85     0.7557    0.08158     0.87\n",
      "NOTE:    109   256   0.0001            1.852     0.7607    0.08158     0.86\n",
      "NOTE:    110   256   0.0001            1.841     0.7478    0.08158     0.84\n",
      "NOTE:    111   256   0.0001            1.864     0.7825    0.08158     0.81\n",
      "NOTE:    112   256   0.0001            1.832     0.7292    0.08158     0.91\n",
      "NOTE:    113   256   0.0001            1.865     0.7822    0.08158     0.89\n",
      "NOTE:    114   256   0.0001            1.868     0.7823    0.08158     0.82\n",
      "NOTE:    115   256   0.0001            1.875      0.797    0.08158     0.82\n",
      "NOTE:    116   256   0.0001            1.833     0.7288    0.08158     0.82\n",
      "NOTE:    117   256   0.0001            1.836     0.7327    0.08158     0.83\n",
      "NOTE:    118   256   0.0001            1.876     0.8009    0.08158     0.84\n",
      "NOTE:    119   256   0.0001            1.876     0.8041    0.08158     0.83\n",
      "NOTE:    120   256   0.0001            1.853     0.7597    0.08158     0.84\n",
      "NOTE:    121   256   0.0001            1.834     0.7296    0.08158     0.84\n",
      "NOTE:    122   256   0.0001            1.856     0.7706    0.08158     0.83\n",
      "NOTE:    123   256   0.0001             1.86     0.7756    0.08158     0.83\n",
      "NOTE:    124   256   0.0001            1.856     0.7783    0.08158     0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    125   256   0.0001            1.843     0.7507    0.08158     0.83\n",
      "NOTE:    126   256   0.0001             1.85     0.7594    0.08158     0.83\n",
      "NOTE:    127   256   0.0001            1.843     0.7478    0.08158     0.83\n",
      "NOTE:    128   256   0.0001            1.839     0.7476    0.08158     0.82\n",
      "NOTE:    129   256   0.0001            1.856     0.7704    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.868      0.788    0.08158     0.83\n",
      "NOTE:    131   256   0.0001            1.845     0.7506    0.08158     0.90\n",
      "NOTE:    132   256   0.0001            1.844     0.7453    0.08158     0.90\n",
      "NOTE:    133   256   0.0001             1.85     0.7664    0.08158     0.91\n",
      "NOTE:    134   256   0.0001            1.863     0.7832    0.08158     0.94\n",
      "NOTE:    135   256   0.0001            1.838     0.7326    0.08158     0.91\n",
      "NOTE:    136   256   0.0001            1.836     0.7366    0.08158     0.87\n",
      "NOTE:    137   256   0.0001            1.836     0.7394    0.08158     0.85\n",
      "NOTE:    138   256   0.0001            1.841     0.7431    0.08158     0.82\n",
      "NOTE:    139   256   0.0001            1.849     0.7565    0.08158     0.83\n",
      "NOTE:    140   256   0.0001            1.855     0.7668    0.08158     0.87\n",
      "NOTE:    141   256   0.0001            1.856     0.7716    0.08158     0.82\n",
      "NOTE:    142   256   0.0001            1.843     0.7473    0.08158     0.82\n",
      "NOTE:    143   256   0.0001            1.842     0.7443    0.08158     0.88\n",
      "NOTE:    144   256   0.0001            1.864     0.7866    0.08158     0.83\n",
      "NOTE:    145   256   0.0001            1.863     0.7768    0.08158     0.84\n",
      "NOTE:    146   256   0.0001            1.875     0.8001    0.08158     0.84\n",
      "NOTE:    147   256   0.0001            1.868     0.7907    0.08158     0.82\n",
      "NOTE:    148   256   0.0001            1.863     0.7821    0.08158     0.83\n",
      "NOTE:    149   256   0.0001            1.855     0.7683    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.853     0.7631    0.08158     0.83\n",
      "NOTE:    151   256   0.0001            1.865     0.7843    0.08158     0.86\n",
      "NOTE:    152   256   0.0001            1.858     0.7702    0.08158     0.83\n",
      "NOTE:    153   256   0.0001            1.851     0.7595    0.08158     0.82\n",
      "NOTE:    154   256   0.0001            1.842     0.7448    0.08158     0.82\n",
      "NOTE:    155   256   0.0001            1.855      0.763    0.08158     0.82\n",
      "NOTE:    156   256   0.0001            1.864     0.7828    0.08158     0.83\n",
      "NOTE:    157   256   0.0001            1.854      0.763    0.08158     0.87\n",
      "NOTE:    158   256   0.0001            1.847     0.7524    0.08158     0.82\n",
      "NOTE:    159   256   0.0001            1.831     0.7268    0.08158     0.83\n",
      "NOTE:    160   256   0.0001            1.869     0.7922    0.08158     0.85\n",
      "NOTE:    161   256   0.0001            1.866     0.7952    0.08158     0.82\n",
      "NOTE:    162   256   0.0001            1.854     0.7731    0.08158     0.86\n",
      "NOTE:    163   256   0.0001            1.842     0.7473    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  4        0.0001           1.856     0.7691   137.89\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.847      0.752    0.08158     0.83\n",
      "NOTE:      1   256   0.0001            1.837     0.7445    0.08158     0.82\n",
      "NOTE:      2   256   0.0001            1.842     0.7448    0.08158     0.83\n",
      "NOTE:      3   256   0.0001            1.863      0.785    0.08158     0.84\n",
      "NOTE:      4   256   0.0001            1.848     0.7614    0.08158     0.82\n",
      "NOTE:      5   256   0.0001            1.848     0.7572    0.08158     0.83\n",
      "NOTE:      6   256   0.0001            1.851     0.7587    0.08158     0.83\n",
      "NOTE:      7   256   0.0001            1.855     0.7679    0.08158     0.82\n",
      "NOTE:      8   256   0.0001            1.853     0.7656    0.08158     0.81\n",
      "NOTE:      9   256   0.0001            1.841     0.7496    0.08158     0.83\n",
      "NOTE:     10   256   0.0001            1.864     0.7847    0.08158     0.83\n",
      "NOTE:     11   256   0.0001            1.851       0.76    0.08158     0.82\n",
      "NOTE:     12   256   0.0001            1.861      0.774    0.08158     0.90\n",
      "NOTE:     13   256   0.0001            1.833     0.7303    0.08158     0.83\n",
      "NOTE:     14   256   0.0001             1.86      0.781    0.08158     0.82\n",
      "NOTE:     15   256   0.0001            1.832     0.7302    0.08157     0.83\n",
      "NOTE:     16   256   0.0001            1.857     0.7681    0.08157     0.84\n",
      "NOTE:     17   256   0.0001             1.83     0.7197    0.08157     0.83\n",
      "NOTE:     18   256   0.0001            1.844     0.7499    0.08157     0.83\n",
      "NOTE:     19   256   0.0001            1.869     0.7933    0.08157     0.83\n",
      "NOTE:     20   256   0.0001            1.822     0.7124    0.08157     0.82\n",
      "NOTE:     21   256   0.0001            1.868     0.7926    0.08157     0.82\n",
      "NOTE:     22   256   0.0001            1.835     0.7313    0.08157     0.82\n",
      "NOTE:     23   256   0.0001            1.852     0.7647    0.08157     0.82\n",
      "NOTE:     24   256   0.0001            1.832     0.7366    0.08157     0.82\n",
      "NOTE:     25   256   0.0001            1.842     0.7416    0.08157     0.82\n",
      "NOTE:     26   256   0.0001            1.852     0.7634    0.08157     0.82\n",
      "NOTE:     27   256   0.0001            1.832     0.7237    0.08157     0.82\n",
      "NOTE:     28   256   0.0001            1.863     0.7848    0.08157     0.83\n",
      "NOTE:     29   256   0.0001            1.872     0.8011    0.08157     0.83\n",
      "NOTE:     30   256   0.0001            1.841      0.744    0.08157     0.83\n",
      "NOTE:     31   256   0.0001            1.857     0.7764    0.08157     0.82\n",
      "NOTE:     32   256   0.0001            1.859     0.7778    0.08157     0.82\n",
      "NOTE:     33   256   0.0001            1.834     0.7281    0.08157     0.83\n",
      "NOTE:     34   256   0.0001            1.869     0.8005    0.08157     0.83\n",
      "NOTE:     35   256   0.0001            1.853     0.7604    0.08157     0.82\n",
      "NOTE:     36   256   0.0001            1.837     0.7406    0.08157     0.82\n",
      "NOTE:     37   256   0.0001            1.855     0.7717    0.08157     0.82\n",
      "NOTE:     38   256   0.0001            1.835      0.737    0.08157     0.82\n",
      "NOTE:     39   256   0.0001            1.848     0.7571    0.08157     0.82\n",
      "NOTE:     40   256   0.0001            1.836     0.7411    0.08157     0.83\n",
      "NOTE:     41   256   0.0001            1.849      0.763    0.08157     0.83\n",
      "NOTE:     42   256   0.0001             1.84     0.7429    0.08157     0.82\n",
      "NOTE:     43   256   0.0001            1.846     0.7603    0.08157     0.83\n",
      "NOTE:     44   256   0.0001             1.85     0.7599    0.08157     0.82\n",
      "NOTE:     45   256   0.0001            1.834      0.735    0.08157     0.83\n",
      "NOTE:     46   256   0.0001            1.826     0.7192    0.08157     0.82\n",
      "NOTE:     47   256   0.0001            1.856     0.7734    0.08157     0.82\n",
      "NOTE:     48   256   0.0001            1.854     0.7725    0.08157     0.82\n",
      "NOTE:     49   256   0.0001            1.863     0.7796    0.08157     0.83\n",
      "NOTE:     50   256   0.0001            1.864     0.7821    0.08157     0.82\n",
      "NOTE:     51   256   0.0001            1.853     0.7587    0.08157     0.82\n",
      "NOTE:     52   256   0.0001             1.82     0.7133    0.08157     0.82\n",
      "NOTE:     53   256   0.0001            1.835     0.7386    0.08157     0.82\n",
      "NOTE:     54   256   0.0001            1.874     0.8069    0.08157     0.82\n",
      "NOTE:     55   256   0.0001            1.843     0.7429    0.08157     0.82\n",
      "NOTE:     56   256   0.0001            1.847     0.7529    0.08157     0.82\n",
      "NOTE:     57   256   0.0001            1.835     0.7349    0.08157     0.82\n",
      "NOTE:     58   256   0.0001            1.844     0.7553    0.08157     0.82\n",
      "NOTE:     59   256   0.0001            1.849     0.7689    0.08157     0.82\n",
      "NOTE:     60   256   0.0001            1.834     0.7399    0.08157     0.82\n",
      "NOTE:     61   256   0.0001            1.842     0.7469    0.08157     0.82\n",
      "NOTE:     62   256   0.0001            1.844     0.7497    0.08157     0.82\n",
      "NOTE:     63   256   0.0001            1.862     0.7776    0.08157     0.82\n",
      "NOTE:     64   256   0.0001            1.832     0.7293    0.08157     0.82\n",
      "NOTE:     65   256   0.0001            1.835     0.7335    0.08157     0.82\n",
      "NOTE:     66   256   0.0001            1.833     0.7343    0.08157     0.82\n",
      "NOTE:     67   256   0.0001            1.858     0.7739    0.08157     0.82\n",
      "NOTE:     68   256   0.0001             1.85     0.7679    0.08157     0.82\n",
      "NOTE:     69   256   0.0001            1.847     0.7574    0.08157     0.82\n",
      "NOTE:     70   256   0.0001            1.849     0.7643    0.08157     0.82\n",
      "NOTE:     71   256   0.0001            1.847     0.7566    0.08157     0.82\n",
      "NOTE:     72   256   0.0001            1.833     0.7334    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     73   256   0.0001            1.829     0.7279    0.08157     0.82\n",
      "NOTE:     74   256   0.0001            1.855     0.7656    0.08157     0.82\n",
      "NOTE:     75   256   0.0001            1.848     0.7561    0.08157     0.82\n",
      "NOTE:     76   256   0.0001             1.84     0.7473    0.08157     0.82\n",
      "NOTE:     77   256   0.0001            1.834     0.7339    0.08157     0.82\n",
      "NOTE:     78   256   0.0001            1.868     0.7979    0.08157     0.82\n",
      "NOTE:     79   256   0.0001            1.838     0.7412    0.08157     0.82\n",
      "NOTE:     80   256   0.0001            1.869     0.7956    0.08157     0.82\n",
      "NOTE:     81   256   0.0001            1.851     0.7697    0.08157     0.82\n",
      "NOTE:     82   256   0.0001            1.851     0.7629    0.08157     0.82\n",
      "NOTE:     83   256   0.0001            1.855     0.7702    0.08157     0.82\n",
      "NOTE:     84   256   0.0001            1.837     0.7435    0.08157     0.82\n",
      "NOTE:     85   256   0.0001            1.822     0.7118    0.08157     0.82\n",
      "NOTE:     86   256   0.0001            1.861     0.7817    0.08157     0.82\n",
      "NOTE:     87   256   0.0001            1.845     0.7593    0.08157     0.82\n",
      "NOTE:     88   256   0.0001            1.834     0.7404    0.08157     0.82\n",
      "NOTE:     89   256   0.0001            1.836       0.74    0.08157     0.82\n",
      "NOTE:     90   256   0.0001            1.843     0.7546    0.08157     0.82\n",
      "NOTE:     91   256   0.0001            1.811     0.6994    0.08157     0.82\n",
      "NOTE:     92   256   0.0001            1.833     0.7315    0.08157     0.82\n",
      "NOTE:     93   256   0.0001            1.826     0.7255    0.08157     0.82\n",
      "NOTE:     94   256   0.0001             1.84     0.7493    0.08157     0.82\n",
      "NOTE:     95   256   0.0001            1.825     0.7192    0.08157     0.83\n",
      "NOTE:     96   256   0.0001            1.842     0.7464    0.08157     0.82\n",
      "NOTE:     97   256   0.0001             1.83     0.7351    0.08157     0.82\n",
      "NOTE:     98   256   0.0001            1.831     0.7331    0.08157     0.82\n",
      "NOTE:     99   256   0.0001            1.847     0.7649    0.08157     0.82\n",
      "NOTE:    100   256   0.0001            1.855     0.7733    0.08157     0.82\n",
      "NOTE:    101   256   0.0001            1.852     0.7701    0.08157     0.82\n",
      "NOTE:    102   256   0.0001             1.86      0.781    0.08157     0.83\n",
      "NOTE:    103   256   0.0001            1.811     0.6984    0.08157     0.82\n",
      "NOTE:    104   256   0.0001            1.858     0.7777    0.08157     0.82\n",
      "NOTE:    105   256   0.0001            1.834     0.7416    0.08157     0.82\n",
      "NOTE:    106   256   0.0001            1.839      0.746    0.08157     0.82\n",
      "NOTE:    107   256   0.0001            1.851     0.7675    0.08157     0.82\n",
      "NOTE:    108   256   0.0001            1.828     0.7376    0.08157     0.83\n",
      "NOTE:    109   256   0.0001            1.827     0.7209    0.08157     0.82\n",
      "NOTE:    110   256   0.0001            1.837     0.7414    0.08157     0.82\n",
      "NOTE:    111   256   0.0001             1.84     0.7481    0.08157     0.82\n",
      "NOTE:    112   256   0.0001            1.857     0.7788    0.08157     0.82\n",
      "NOTE:    113   256   0.0001            1.838     0.7481    0.08157     0.82\n",
      "NOTE:    114   256   0.0001            1.833     0.7293    0.08157     0.82\n",
      "NOTE:    115   256   0.0001            1.819     0.7083    0.08157     0.82\n",
      "NOTE:    116   256   0.0001            1.837     0.7544    0.08157     0.82\n",
      "NOTE:    117   256   0.0001            1.829     0.7356    0.08157     0.82\n",
      "NOTE:    118   256   0.0001            1.832     0.7313    0.08157     0.82\n",
      "NOTE:    119   256   0.0001            1.841     0.7498    0.08157     0.82\n",
      "NOTE:    120   256   0.0001            1.836     0.7409    0.08157     0.82\n",
      "NOTE:    121   256   0.0001             1.85     0.7662    0.08157     0.82\n",
      "NOTE:    122   256   0.0001            1.817     0.7153    0.08157     0.83\n",
      "NOTE:    123   256   0.0001            1.822      0.714    0.08157     0.81\n",
      "NOTE:    124   256   0.0001              1.8     0.6885    0.08157     0.82\n",
      "NOTE:    125   256   0.0001            1.811     0.6939    0.08157     0.82\n",
      "NOTE:    126   256   0.0001            1.842     0.7527    0.08157     0.82\n",
      "NOTE:    127   256   0.0001            1.822     0.7162    0.08157     0.82\n",
      "NOTE:    128   256   0.0001            1.834     0.7358    0.08157     0.82\n",
      "NOTE:    129   256   0.0001            1.843     0.7509    0.08157     0.82\n",
      "NOTE:    130   256   0.0001            1.844     0.7533    0.08157     0.82\n",
      "NOTE:    131   256   0.0001            1.818      0.712    0.08157     0.82\n",
      "NOTE:    132   256   0.0001            1.821     0.7183    0.08157     0.82\n",
      "NOTE:    133   256   0.0001            1.852     0.7723    0.08157     0.82\n",
      "NOTE:    134   256   0.0001            1.831     0.7414    0.08157     0.82\n",
      "NOTE:    135   256   0.0001            1.852     0.7668    0.08157     0.82\n",
      "NOTE:    136   256   0.0001            1.822     0.7214    0.08157     0.82\n",
      "NOTE:    137   256   0.0001             1.83      0.736    0.08157     0.82\n",
      "NOTE:    138   256   0.0001            1.846     0.7577    0.08157     0.83\n",
      "NOTE:    139   256   0.0001            1.832     0.7358    0.08157     0.83\n",
      "NOTE:    140   256   0.0001            1.805     0.6911    0.08157     0.82\n",
      "NOTE:    141   256   0.0001             1.82     0.7176    0.08157     0.82\n",
      "NOTE:    142   256   0.0001             1.85     0.7673    0.08157     0.82\n",
      "NOTE:    143   256   0.0001            1.828     0.7294    0.08157     0.82\n",
      "NOTE:    144   256   0.0001            1.844     0.7538    0.08157     0.83\n",
      "NOTE:    145   256   0.0001            1.841     0.7555    0.08157     0.83\n",
      "NOTE:    146   256   0.0001            1.817     0.7119    0.08157     0.82\n",
      "NOTE:    147   256   0.0001            1.817     0.7121    0.08157     0.83\n",
      "NOTE:    148   256   0.0001            1.854     0.7708    0.08157     0.82\n",
      "NOTE:    149   256   0.0001            1.834     0.7449    0.08157     0.82\n",
      "NOTE:    150   256   0.0001            1.806     0.6885    0.08157     0.82\n",
      "NOTE:    151   256   0.0001            1.824     0.7239    0.08157     0.83\n",
      "NOTE:    152   256   0.0001            1.851     0.7704    0.08157     0.82\n",
      "NOTE:    153   256   0.0001            1.851     0.7643    0.08157     0.82\n",
      "NOTE:    154   256   0.0001            1.827     0.7321    0.08157     0.82\n",
      "NOTE:    155   256   0.0001            1.841     0.7485    0.08157     0.82\n",
      "NOTE:    156   256   0.0001            1.813     0.7102    0.08157     0.82\n",
      "NOTE:    157   256   0.0001              1.8     0.6897    0.08157     0.82\n",
      "NOTE:    158   256   0.0001            1.835     0.7497    0.08157     0.82\n",
      "NOTE:    159   256   0.0001            1.832     0.7334    0.08157     0.83\n",
      "NOTE:    160   256   0.0001            1.857     0.7839    0.08157     0.82\n",
      "NOTE:    161   256   0.0001            1.835     0.7424    0.08157     0.82\n",
      "NOTE:    162   256   0.0001            1.827     0.7329    0.08157     0.83\n",
      "NOTE:    163   256   0.0001            1.826     0.7259    0.08157     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  5        0.0001           1.841      0.748   135.05\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.834     0.7439    0.08157     0.82\n",
      "NOTE:      1   256   0.0001            1.811     0.7027    0.08157     0.83\n",
      "NOTE:      2   256   0.0001            1.843      0.753    0.08157     0.82\n",
      "NOTE:      3   256   0.0001            1.822     0.7199    0.08157     0.82\n",
      "NOTE:      4   256   0.0001             1.85     0.7746    0.08157     0.82\n",
      "NOTE:      5   256   0.0001            1.819     0.7139    0.08157     0.82\n",
      "NOTE:      6   256   0.0001            1.837     0.7454    0.08157     0.82\n",
      "NOTE:      7   256   0.0001            1.832     0.7384    0.08157     0.83\n",
      "NOTE:      8   256   0.0001            1.842     0.7458    0.08157     0.82\n",
      "NOTE:      9   256   0.0001            1.834     0.7373    0.08157     0.82\n",
      "NOTE:     10   256   0.0001            1.829     0.7294    0.08157     0.82\n",
      "NOTE:     11   256   0.0001            1.835     0.7404    0.08157     0.82\n",
      "NOTE:     12   256   0.0001            1.802     0.6983    0.08157     0.82\n",
      "NOTE:     13   256   0.0001            1.827     0.7315    0.08157     0.82\n",
      "NOTE:     14   256   0.0001            1.832     0.7374    0.08157     0.82\n",
      "NOTE:     15   256   0.0001            1.844     0.7584    0.08157     0.82\n",
      "NOTE:     16   256   0.0001            1.829     0.7343    0.08157     0.82\n",
      "NOTE:     17   256   0.0001            1.826     0.7286    0.08157     0.82\n",
      "NOTE:     18   256   0.0001            1.856     0.7847    0.08157     0.82\n",
      "NOTE:     19   256   0.0001            1.822     0.7206    0.08157     0.82\n",
      "NOTE:     20   256   0.0001            1.834     0.7409    0.08157     0.82\n",
      "NOTE:     21   256   0.0001            1.834     0.7479    0.08157     0.82\n",
      "NOTE:     22   256   0.0001            1.834     0.7356    0.08157     0.83\n",
      "NOTE:     23   256   0.0001            1.838     0.7493    0.08157     0.82\n",
      "NOTE:     24   256   0.0001            1.846     0.7587    0.08157     0.82\n",
      "NOTE:     25   256   0.0001            1.816     0.7089    0.08157     0.82\n",
      "NOTE:     26   256   0.0001            1.834     0.7435    0.08157     0.82\n",
      "NOTE:     27   256   0.0001            1.831      0.733    0.08157     0.82\n",
      "NOTE:     28   256   0.0001             1.79     0.6727    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     29   256   0.0001            1.834     0.7498    0.08157     0.82\n",
      "NOTE:     30   256   0.0001            1.856     0.7778    0.08157     0.82\n",
      "NOTE:     31   256   0.0001            1.837     0.7461    0.08157     0.82\n",
      "NOTE:     32   256   0.0001            1.798     0.6819    0.08157     0.82\n",
      "NOTE:     33   256   0.0001            1.813     0.7065    0.08157     0.82\n",
      "NOTE:     34   256   0.0001            1.827     0.7228    0.08157     0.83\n",
      "NOTE:     35   256   0.0001            1.829     0.7357    0.08157     0.82\n",
      "NOTE:     36   256   0.0001            1.806     0.6981    0.08157     0.82\n",
      "NOTE:     37   256   0.0001            1.819     0.7167    0.08157     0.82\n",
      "NOTE:     38   256   0.0001            1.825     0.7274    0.08157     0.82\n",
      "NOTE:     39   256   0.0001            1.833     0.7428    0.08157     0.82\n",
      "NOTE:     40   256   0.0001            1.809     0.7015    0.08157     0.82\n",
      "NOTE:     41   256   0.0001            1.818     0.7116    0.08157     0.82\n",
      "NOTE:     42   256   0.0001            1.835     0.7445    0.08157     0.82\n",
      "NOTE:     43   256   0.0001            1.838     0.7534    0.08157     0.81\n",
      "NOTE:     44   256   0.0001            1.837     0.7555    0.08157     0.83\n",
      "NOTE:     45   256   0.0001            1.828     0.7494    0.08157     0.82\n",
      "NOTE:     46   256   0.0001            1.796     0.6736    0.08157     0.82\n",
      "NOTE:     47   256   0.0001            1.828     0.7404    0.08157     0.82\n",
      "NOTE:     48   256   0.0001            1.819     0.7161    0.08157     0.82\n",
      "NOTE:     49   256   0.0001            1.816     0.7099    0.08157     0.82\n",
      "NOTE:     50   256   0.0001            1.823     0.7149    0.08157     0.82\n",
      "NOTE:     51   256   0.0001            1.836     0.7418    0.08157     0.82\n",
      "NOTE:     52   256   0.0001            1.812     0.7012    0.08157     0.83\n",
      "NOTE:     53   256   0.0001            1.826     0.7346    0.08157     0.82\n",
      "NOTE:     54   256   0.0001            1.818     0.7205    0.08157     0.82\n",
      "NOTE:     55   256   0.0001             1.82     0.7186    0.08157     0.82\n",
      "NOTE:     56   256   0.0001            1.809     0.6955    0.08157     0.82\n",
      "NOTE:     57   256   0.0001            1.815     0.7104    0.08157     0.83\n",
      "NOTE:     58   256   0.0001            1.849     0.7818    0.08157     0.82\n",
      "NOTE:     59   256   0.0001            1.806     0.6853    0.08157     0.82\n",
      "NOTE:     60   256   0.0001            1.817     0.7096    0.08157     0.82\n",
      "NOTE:     61   256   0.0001             1.83     0.7454    0.08157     0.82\n",
      "NOTE:     62   256   0.0001            1.822     0.7277    0.08157     0.82\n",
      "NOTE:     63   256   0.0001            1.811     0.7076    0.08157     0.81\n",
      "NOTE:     64   256   0.0001             1.83     0.7409    0.08157     0.82\n",
      "NOTE:     65   256   0.0001            1.829      0.732    0.08157     0.82\n",
      "NOTE:     66   256   0.0001            1.833     0.7358    0.08157     0.82\n",
      "NOTE:     67   256   0.0001            1.853     0.7766    0.08157     0.82\n",
      "NOTE:     68   256   0.0001            1.823     0.7218    0.08157     0.82\n",
      "NOTE:     69   256   0.0001            1.829     0.7353    0.08157     0.82\n",
      "NOTE:     70   256   0.0001            1.827     0.7367    0.08157     0.82\n",
      "NOTE:     71   256   0.0001            1.805     0.7027    0.08157     0.82\n",
      "NOTE:     72   256   0.0001            1.809     0.7114    0.08157     0.83\n",
      "NOTE:     73   256   0.0001            1.814     0.7083    0.08157     0.83\n",
      "NOTE:     74   256   0.0001            1.815     0.7201    0.08157     0.83\n",
      "NOTE:     75   256   0.0001            1.826     0.7377    0.08157     0.82\n",
      "NOTE:     76   256   0.0001             1.83      0.739    0.08157     0.82\n",
      "NOTE:     77   256   0.0001            1.828     0.7317    0.08157     0.82\n",
      "NOTE:     78   256   0.0001              1.8     0.6925    0.08157     0.82\n",
      "NOTE:     79   256   0.0001            1.814     0.7106    0.08157     0.82\n",
      "NOTE:     80   256   0.0001            1.816     0.7167    0.08157     0.81\n",
      "NOTE:     81   256   0.0001            1.805       0.69    0.08157     0.82\n",
      "NOTE:     82   256   0.0001              1.8     0.7003    0.08157     0.82\n",
      "NOTE:     83   256   0.0001            1.831     0.7428    0.08157     0.82\n",
      "NOTE:     84   256   0.0001            1.825     0.7276    0.08157     0.82\n",
      "NOTE:     85   256   0.0001            1.827     0.7375    0.08157     0.82\n",
      "NOTE:     86   256   0.0001            1.835     0.7489    0.08157     0.82\n",
      "NOTE:     87   256   0.0001            1.841      0.761    0.08157     0.82\n",
      "NOTE:     88   256   0.0001            1.817     0.7233    0.08157     0.82\n",
      "NOTE:     89   256   0.0001            1.821     0.7246    0.08157     0.83\n",
      "NOTE:     90   256   0.0001            1.822     0.7262    0.08157     0.82\n",
      "NOTE:     91   256   0.0001            1.814     0.7145    0.08157     0.82\n",
      "NOTE:     92   256   0.0001             1.83     0.7355    0.08157     0.82\n",
      "NOTE:     93   256   0.0001            1.814     0.7122    0.08157     0.82\n",
      "NOTE:     94   256   0.0001             1.82     0.7256    0.08157     0.82\n",
      "NOTE:     95   256   0.0001            1.791     0.6726    0.08157     0.82\n",
      "NOTE:     96   256   0.0001             1.81      0.707    0.08157     0.82\n",
      "NOTE:     97   256   0.0001              1.8     0.6929    0.08157     0.82\n",
      "NOTE:     98   256   0.0001            1.827      0.731    0.08157     0.82\n",
      "NOTE:     99   256   0.0001            1.793     0.6783    0.08157     0.82\n",
      "NOTE:    100   256   0.0001            1.823      0.724    0.08157     0.82\n",
      "NOTE:    101   256   0.0001             1.83     0.7433    0.08157     0.83\n",
      "NOTE:    102   256   0.0001            1.843     0.7701    0.08157     0.82\n",
      "NOTE:    103   256   0.0001            1.826     0.7388    0.08157     0.82\n",
      "NOTE:    104   256   0.0001            1.823     0.7279    0.08157     0.82\n",
      "NOTE:    105   256   0.0001            1.817     0.7144    0.08157     0.82\n",
      "NOTE:    106   256   0.0001            1.805     0.7005    0.08157     0.82\n",
      "NOTE:    107   256   0.0001            1.811     0.7089    0.08157     0.82\n",
      "NOTE:    108   256   0.0001            1.805     0.6935    0.08157     0.82\n",
      "NOTE:    109   256   0.0001            1.834      0.749    0.08157     0.83\n",
      "NOTE:    110   256   0.0001            1.801      0.689    0.08157     0.82\n",
      "NOTE:    111   256   0.0001            1.825     0.7348    0.08157     0.82\n",
      "NOTE:    112   256   0.0001            1.829     0.7405    0.08157     0.82\n",
      "NOTE:    113   256   0.0001            1.809     0.7003    0.08157     0.82\n",
      "NOTE:    114   256   0.0001            1.821      0.727    0.08157     0.83\n",
      "NOTE:    115   256   0.0001            1.817     0.7123    0.08157     0.82\n",
      "NOTE:    116   256   0.0001            1.822     0.7225    0.08157     0.82\n",
      "NOTE:    117   256   0.0001            1.818     0.7138    0.08157     0.82\n",
      "NOTE:    118   256   0.0001            1.813      0.709    0.08157     0.83\n",
      "NOTE:    119   256   0.0001            1.799     0.6908    0.08157     0.82\n",
      "NOTE:    120   256   0.0001            1.814     0.7115    0.08157     0.81\n",
      "NOTE:    121   256   0.0001            1.821     0.7261    0.08157     0.82\n",
      "NOTE:    122   256   0.0001            1.811     0.7075    0.08157     0.83\n",
      "NOTE:    123   256   0.0001            1.823     0.7192    0.08157     0.82\n",
      "NOTE:    124   256   0.0001            1.803     0.6862    0.08157     0.82\n",
      "NOTE:    125   256   0.0001            1.808     0.7039    0.08157     0.82\n",
      "NOTE:    126   256   0.0001            1.819     0.7313    0.08157     0.83\n",
      "NOTE:    127   256   0.0001            1.819     0.7285    0.08157     0.81\n",
      "NOTE:    128   256   0.0001            1.796     0.6881    0.08157     0.82\n",
      "NOTE:    129   256   0.0001            1.818     0.7196    0.08157     0.82\n",
      "NOTE:    130   256   0.0001            1.824     0.7297    0.08157     0.82\n",
      "NOTE:    131   256   0.0001            1.816     0.7162    0.08157     0.82\n",
      "NOTE:    132   256   0.0001             1.82     0.7237    0.08157     0.82\n",
      "NOTE:    133   256   0.0001            1.816     0.7115    0.08157     0.82\n",
      "NOTE:    134   256   0.0001            1.807     0.6965    0.08157     0.82\n",
      "NOTE:    135   256   0.0001             1.81     0.6985    0.08157     0.82\n",
      "NOTE:    136   256   0.0001            1.809     0.7084    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    137   256   0.0001            1.817     0.7242    0.08157     0.82\n",
      "NOTE:    138   256   0.0001            1.806     0.7041    0.08157     0.82\n",
      "NOTE:    139   256   0.0001            1.824     0.7267    0.08157     0.82\n",
      "NOTE:    140   256   0.0001            1.823     0.7315    0.08157     0.82\n",
      "NOTE:    141   256   0.0001            1.823     0.7344    0.08157     0.82\n",
      "NOTE:    142   256   0.0001            1.819     0.7152    0.08157     0.82\n",
      "NOTE:    143   256   0.0001            1.808     0.7066    0.08157     0.84\n",
      "NOTE:    144   256   0.0001            1.842     0.7588    0.08157     0.82\n",
      "NOTE:    145   256   0.0001            1.813      0.718    0.08157     0.82\n",
      "NOTE:    146   256   0.0001            1.808     0.7006    0.08157     0.82\n",
      "NOTE:    147   256   0.0001            1.801      0.688    0.08157     0.82\n",
      "NOTE:    148   256   0.0001             1.79     0.6756    0.08157     0.82\n",
      "NOTE:    149   256   0.0001            1.788     0.6781    0.08157     0.82\n",
      "NOTE:    150   256   0.0001            1.814     0.7148    0.08157     0.82\n",
      "NOTE:    151   256   0.0001            1.805     0.7143    0.08157     0.82\n",
      "NOTE:    152   256   0.0001            1.824     0.7296    0.08157     0.82\n",
      "NOTE:    153   256   0.0001            1.808     0.7042    0.08157     0.82\n",
      "NOTE:    154   256   0.0001            1.827     0.7441    0.08157     0.82\n",
      "NOTE:    155   256   0.0001            1.816      0.719    0.08157     0.82\n",
      "NOTE:    156   256   0.0001            1.813     0.7168    0.08157     0.82\n",
      "NOTE:    157   256   0.0001            1.812     0.7172    0.08157     0.82\n",
      "NOTE:    158   256   0.0001            1.827     0.7392    0.08157     0.82\n",
      "NOTE:    159   256   0.0001            1.791     0.6786    0.08157     0.82\n",
      "NOTE:    160   256   0.0001            1.826     0.7371    0.08157     0.82\n",
      "NOTE:    161   256   0.0001            1.831     0.7414    0.08157     0.82\n",
      "NOTE:    162   256   0.0001            1.815     0.7295    0.08157     0.82\n",
      "NOTE:    163   256   0.0001            1.801     0.6984    0.08157     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  6        0.0001            1.82     0.7229   134.73\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001             1.83     0.7362    0.08157     0.82\n",
      "NOTE:      1   256   0.0001            1.842     0.7528    0.08157     0.82\n",
      "NOTE:      2   256   0.0001            1.832     0.7524    0.08157     0.82\n",
      "NOTE:      3   256   0.0001            1.797     0.6905    0.08157     0.82\n",
      "NOTE:      4   256   0.0001            1.814     0.7126    0.08157     0.82\n",
      "NOTE:      5   256   0.0001            1.797     0.6877    0.08157     0.82\n",
      "NOTE:      6   256   0.0001            1.786     0.6681    0.08157     0.82\n",
      "NOTE:      7   256   0.0001            1.807      0.712    0.08157     0.82\n",
      "NOTE:      8   256   0.0001            1.834     0.7491    0.08157     0.83\n",
      "NOTE:      9   256   0.0001              1.8     0.6923    0.08157     0.82\n",
      "NOTE:     10   256   0.0001            1.801     0.6979    0.08157     0.82\n",
      "NOTE:     11   256   0.0001            1.791     0.6776    0.08157     0.82\n",
      "NOTE:     12   256   0.0001            1.829     0.7488    0.08157     0.82\n",
      "NOTE:     13   256   0.0001            1.799     0.6869    0.08157     0.82\n",
      "NOTE:     14   256   0.0001            1.826      0.731    0.08157     0.84\n",
      "NOTE:     15   256   0.0001            1.788     0.6735    0.08157     0.82\n",
      "NOTE:     16   256   0.0001            1.799      0.685    0.08157     0.83\n",
      "NOTE:     17   256   0.0001            1.795     0.6819    0.08157     0.82\n",
      "NOTE:     18   256   0.0001             1.79     0.6851    0.08157     0.82\n",
      "NOTE:     19   256   0.0001            1.811     0.7066    0.08157     0.82\n",
      "NOTE:     20   256   0.0001            1.798     0.6949    0.08157     0.82\n",
      "NOTE:     21   256   0.0001            1.792     0.6811    0.08157     0.82\n",
      "NOTE:     22   256   0.0001            1.789     0.6864    0.08157     0.82\n",
      "NOTE:     23   256   0.0001            1.803     0.6997    0.08157     0.82\n",
      "NOTE:     24   256   0.0001            1.829     0.7541    0.08157     0.82\n",
      "NOTE:     25   256   0.0001            1.814     0.7249    0.08157     0.82\n",
      "NOTE:     26   256   0.0001            1.807     0.7185    0.08157     0.82\n",
      "NOTE:     27   256   0.0001            1.798     0.6835    0.08157     0.82\n",
      "NOTE:     28   256   0.0001            1.794     0.6844    0.08157     0.82\n",
      "NOTE:     29   256   0.0001            1.823     0.7349    0.08157     0.82\n",
      "NOTE:     30   256   0.0001            1.831     0.7539    0.08157     0.82\n",
      "NOTE:     31   256   0.0001            1.818      0.734    0.08157     0.82\n",
      "NOTE:     32   256   0.0001            1.807     0.7048    0.08157     0.82\n",
      "NOTE:     33   256   0.0001            1.799     0.6859    0.08157     0.82\n",
      "NOTE:     34   256   0.0001            1.822     0.7274    0.08157     0.82\n",
      "NOTE:     35   256   0.0001            1.773     0.6616    0.08157     0.83\n",
      "NOTE:     36   256   0.0001            1.802     0.6962    0.08157     0.87\n",
      "NOTE:     37   256   0.0001            1.809     0.7106    0.08157     0.82\n",
      "NOTE:     38   256   0.0001            1.793     0.6814    0.08157     0.82\n",
      "NOTE:     39   256   0.0001            1.793     0.6839    0.08157     0.82\n",
      "NOTE:     40   256   0.0001            1.806     0.7122    0.08157     0.82\n",
      "NOTE:     41   256   0.0001              1.8     0.7098    0.08157     0.82\n",
      "NOTE:     42   256   0.0001            1.794     0.6862    0.08157     0.82\n",
      "NOTE:     43   256   0.0001            1.812     0.7157    0.08157     0.82\n",
      "NOTE:     44   256   0.0001            1.774     0.6481    0.08157     0.82\n",
      "NOTE:     45   256   0.0001            1.797     0.6986    0.08157     0.82\n",
      "NOTE:     46   256   0.0001            1.786     0.6697    0.08157     0.82\n",
      "NOTE:     47   256   0.0001            1.813     0.7269    0.08157     0.82\n",
      "NOTE:     48   256   0.0001             1.79     0.6764    0.08157     0.82\n",
      "NOTE:     49   256   0.0001            1.829     0.7428    0.08157     0.82\n",
      "NOTE:     50   256   0.0001            1.816     0.7296    0.08157     0.82\n",
      "NOTE:     51   256   0.0001            1.783     0.6721    0.08157     0.82\n",
      "NOTE:     52   256   0.0001            1.805     0.7087    0.08157     0.82\n",
      "NOTE:     53   256   0.0001            1.784     0.6748    0.08157     0.82\n",
      "NOTE:     54   256   0.0001            1.772     0.6475    0.08157     0.82\n",
      "NOTE:     55   256   0.0001            1.794      0.687    0.08157     0.82\n",
      "NOTE:     56   256   0.0001            1.826     0.7472    0.08157     0.82\n",
      "NOTE:     57   256   0.0001            1.806     0.7044    0.08157     0.87\n",
      "NOTE:     58   256   0.0001            1.805     0.7226    0.08157     0.82\n",
      "NOTE:     59   256   0.0001              1.8     0.7065    0.08157     0.82\n",
      "NOTE:     60   256   0.0001            1.807     0.6981    0.08157     0.85\n",
      "NOTE:     61   256   0.0001             1.79     0.6754    0.08157     0.82\n",
      "NOTE:     62   256   0.0001             1.81     0.7066    0.08157     0.82\n",
      "NOTE:     63   256   0.0001            1.801     0.7037    0.08157     0.82\n",
      "NOTE:     64   256   0.0001            1.802     0.7012    0.08157     0.82\n",
      "NOTE:     65   256   0.0001            1.795     0.6876    0.08157     0.83\n",
      "NOTE:     66   256   0.0001            1.765     0.6448    0.08157     0.82\n",
      "NOTE:     67   256   0.0001             1.82     0.7238    0.08157     0.82\n",
      "NOTE:     68   256   0.0001            1.825     0.7442    0.08157     0.82\n",
      "NOTE:     69   256   0.0001            1.793     0.6861    0.08157     0.85\n",
      "NOTE:     70   256   0.0001            1.795     0.7049    0.08157     0.89\n",
      "NOTE:     71   256   0.0001            1.806     0.7044    0.08157     0.87\n",
      "NOTE:     72   256   0.0001            1.797      0.694    0.08157     0.83\n",
      "NOTE:     73   256   0.0001            1.778     0.6646    0.08157     0.83\n",
      "NOTE:     74   256   0.0001            1.793     0.6882    0.08157     0.84\n",
      "NOTE:     75   256   0.0001            1.812     0.7257    0.08157     0.83\n",
      "NOTE:     76   256   0.0001            1.796     0.6951    0.08157     0.83\n",
      "NOTE:     77   256   0.0001            1.777     0.6616    0.08157     0.90\n",
      "NOTE:     78   256   0.0001            1.784     0.6714    0.08157     0.90\n",
      "NOTE:     79   256   0.0001            1.775     0.6494    0.08157     0.83\n",
      "NOTE:     80   256   0.0001            1.799     0.7005    0.08157     0.83\n",
      "NOTE:     81   256   0.0001            1.814     0.7381    0.08157     0.89\n",
      "NOTE:     82   256   0.0001            1.772      0.654    0.08157     0.82\n",
      "NOTE:     83   256   0.0001            1.774     0.6537    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     84   256   0.0001            1.785     0.6722    0.08157     0.83\n",
      "NOTE:     85   256   0.0001            1.786     0.6769    0.08157     0.89\n",
      "NOTE:     86   256   0.0001            1.784      0.685    0.08157     0.83\n",
      "NOTE:     87   256   0.0001            1.796     0.6832    0.08157     0.84\n",
      "NOTE:     88   256   0.0001            1.791     0.6801    0.08157     0.90\n",
      "NOTE:     89   256   0.0001            1.782     0.6719    0.08157     0.84\n",
      "NOTE:     90   256   0.0001            1.803     0.6997    0.08157     0.83\n",
      "NOTE:     91   256   0.0001            1.813     0.7164    0.08157     0.83\n",
      "NOTE:     92   256   0.0001             1.81     0.7177    0.08157     0.88\n",
      "NOTE:     93   256   0.0001            1.754     0.6219    0.08157     0.82\n",
      "NOTE:     94   256   0.0001            1.777     0.6524    0.08157     0.83\n",
      "NOTE:     95   256   0.0001            1.801     0.6975    0.08157     0.83\n",
      "NOTE:     96   256   0.0001            1.815     0.7323    0.08157     0.89\n",
      "NOTE:     97   256   0.0001            1.773     0.6604    0.08157     0.83\n",
      "NOTE:     98   256   0.0001            1.801     0.7041    0.08157     0.85\n",
      "NOTE:     99   256   0.0001            1.807     0.7084    0.08157     0.83\n",
      "NOTE:    100   256   0.0001            1.758     0.6281    0.08157     0.84\n",
      "NOTE:    101   256   0.0001            1.769     0.6451    0.08157     0.83\n",
      "NOTE:    102   256   0.0001            1.773     0.6507    0.08157     0.84\n",
      "NOTE:    103   256   0.0001            1.764     0.6496    0.08157     0.84\n",
      "NOTE:    104   256   0.0001            1.783     0.6725    0.08157     0.88\n",
      "NOTE:    105   256   0.0001            1.793     0.6848    0.08157     0.84\n",
      "NOTE:    106   256   0.0001            1.796     0.6994    0.08157     0.85\n",
      "NOTE:    107   256   0.0001            1.787     0.6825    0.08157     0.83\n",
      "NOTE:    108   256   0.0001            1.807     0.7152    0.08157     0.87\n",
      "NOTE:    109   256   0.0001            1.785     0.6758    0.08157     0.85\n",
      "NOTE:    110   256   0.0001            1.812     0.7281    0.08157     0.83\n",
      "NOTE:    111   256   0.0001            1.798      0.704    0.08157     0.82\n",
      "NOTE:    112   256   0.0001            1.779     0.6679    0.08157     0.88\n",
      "NOTE:    113   256   0.0001            1.765     0.6451    0.08157     0.88\n",
      "NOTE:    114   256   0.0001            1.813     0.7228    0.08157     0.86\n",
      "NOTE:    115   256   0.0001            1.803     0.7173    0.08157     0.83\n",
      "NOTE:    116   256   0.0001            1.779     0.6708    0.08157     0.84\n",
      "NOTE:    117   256   0.0001            1.802     0.6975    0.08157     0.84\n",
      "NOTE:    118   256   0.0001            1.785     0.6806    0.08157     0.83\n",
      "NOTE:    119   256   0.0001            1.781     0.6664    0.08157     0.83\n",
      "NOTE:    120   256   0.0001            1.792     0.7087    0.08157     0.87\n",
      "NOTE:    121   256   0.0001            1.789     0.6912    0.08157     0.84\n",
      "NOTE:    122   256   0.0001            1.808     0.7135    0.08157     0.82\n",
      "NOTE:    123   256   0.0001            1.813     0.7305    0.08157     0.84\n",
      "NOTE:    124   256   0.0001            1.783     0.6847    0.08157     0.88\n",
      "NOTE:    125   256   0.0001            1.792     0.6996    0.08157     0.88\n",
      "NOTE:    126   256   0.0001            1.813     0.7209    0.08157     0.83\n",
      "NOTE:    127   256   0.0001            1.771     0.6734    0.08157     0.84\n",
      "NOTE:    128   256   0.0001            1.801     0.7145    0.08157     0.88\n",
      "NOTE:    129   256   0.0001            1.763     0.6385    0.08157     0.87\n",
      "NOTE:    130   256   0.0001            1.792     0.6971    0.08157     0.84\n",
      "NOTE:    131   256   0.0001            1.792     0.6992    0.08157     0.83\n",
      "NOTE:    132   256   0.0001            1.792     0.6955    0.08157     0.83\n",
      "NOTE:    133   256   0.0001            1.772      0.649    0.08157     0.83\n",
      "NOTE:    134   256   0.0001              1.8     0.7118    0.08157     0.83\n",
      "NOTE:    135   256   0.0001            1.793     0.6926    0.08157     0.83\n",
      "NOTE:    136   256   0.0001            1.785     0.6891    0.08157     0.83\n",
      "NOTE:    137   256   0.0001            1.792     0.6976    0.08157     0.83\n",
      "NOTE:    138   256   0.0001            1.782     0.6811    0.08157     0.83\n",
      "NOTE:    139   256   0.0001            1.758     0.6378    0.08157     0.85\n",
      "NOTE:    140   256   0.0001             1.78      0.676    0.08157     0.83\n",
      "NOTE:    141   256   0.0001            1.768     0.6581    0.08157     0.83\n",
      "NOTE:    142   256   0.0001            1.786     0.6881    0.08157     0.83\n",
      "NOTE:    143   256   0.0001            1.756     0.6367    0.08157     0.88\n",
      "NOTE:    144   256   0.0001            1.788     0.6831    0.08157     0.82\n",
      "NOTE:    145   256   0.0001             1.79     0.6796    0.08157     0.82\n",
      "NOTE:    146   256   0.0001            1.786     0.6888    0.08157     0.82\n",
      "NOTE:    147   256   0.0001            1.817     0.7323    0.08157     0.82\n",
      "NOTE:    148   256   0.0001            1.787     0.6899    0.08157     0.83\n",
      "NOTE:    149   256   0.0001            1.764     0.6413    0.08157     0.83\n",
      "NOTE:    150   256   0.0001            1.806     0.7277    0.08157     0.82\n",
      "NOTE:    151   256   0.0001            1.782     0.6899    0.08157     0.83\n",
      "NOTE:    152   256   0.0001            1.759     0.6445    0.08157     0.83\n",
      "NOTE:    153   256   0.0001            1.788     0.6847    0.08157     0.83\n",
      "NOTE:    154   256   0.0001            1.783     0.6807    0.08157     0.83\n",
      "NOTE:    155   256   0.0001             1.75     0.6505    0.08157     0.84\n",
      "NOTE:    156   256   0.0001             1.77     0.6519    0.08157     0.83\n",
      "NOTE:    157   256   0.0001            1.762     0.6525    0.08157     0.82\n",
      "NOTE:    158   256   0.0001            1.786     0.6948    0.08157     0.83\n",
      "NOTE:    159   256   0.0001            1.764      0.641    0.08157     0.83\n",
      "NOTE:    160   256   0.0001            1.776     0.6766    0.08157     0.83\n",
      "NOTE:    161   256   0.0001            1.772     0.6598    0.08157     0.83\n",
      "NOTE:    162   256   0.0001            1.773     0.6619    0.08157     0.83\n",
      "NOTE:    163   256   0.0001            1.753     0.6418    0.08157     0.83\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  7        0.0001           1.794     0.6911   136.80\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.805     0.7219    0.08157     0.82\n",
      "NOTE:      1   256   0.0001            1.768     0.6525    0.08157     0.83\n",
      "NOTE:      2   256   0.0001            1.762     0.6447    0.08157     0.83\n",
      "NOTE:      3   256   0.0001            1.787     0.6882    0.08157     0.83\n",
      "NOTE:      4   256   0.0001             1.79     0.6866    0.08157     0.83\n",
      "NOTE:      5   256   0.0001            1.765     0.6678    0.08157     0.83\n",
      "NOTE:      6   256   0.0001            1.797      0.697    0.08157     0.83\n",
      "NOTE:      7   256   0.0001            1.774     0.6651    0.08157     0.82\n",
      "NOTE:      8   256   0.0001            1.791     0.6973    0.08157     0.83\n",
      "NOTE:      9   256   0.0001            1.768      0.665    0.08157     0.83\n",
      "NOTE:     10   256   0.0001            1.773     0.6626    0.08157     0.85\n",
      "NOTE:     11   256   0.0001            1.782     0.6832    0.08157     0.82\n",
      "NOTE:     12   256   0.0001            1.794     0.7052    0.08157     0.83\n",
      "NOTE:     13   256   0.0001            1.802      0.719    0.08157     0.83\n",
      "NOTE:     14   256   0.0001            1.794     0.7049    0.08157     0.83\n",
      "NOTE:     15   256   0.0001            1.785     0.6917    0.08157     0.83\n",
      "NOTE:     16   256   0.0001            1.773     0.6555    0.08157     0.83\n",
      "NOTE:     17   256   0.0001            1.785     0.6881    0.08157     0.82\n",
      "NOTE:     18   256   0.0001            1.782     0.6752    0.08157     0.82\n",
      "NOTE:     19   256   0.0001            1.763     0.6512    0.08157     0.82\n",
      "NOTE:     20   256   0.0001            1.777     0.6855    0.08157     0.83\n",
      "NOTE:     21   256   0.0001            1.763     0.6527    0.08157     0.82\n",
      "NOTE:     22   256   0.0001            1.772      0.661    0.08157     0.83\n",
      "NOTE:     23   256   0.0001            1.785      0.691    0.08157     0.82\n",
      "NOTE:     24   256   0.0001            1.745     0.6168    0.08157     0.82\n",
      "NOTE:     25   256   0.0001            1.754     0.6392    0.08157     0.83\n",
      "NOTE:     26   256   0.0001            1.778     0.6833    0.08157     0.83\n",
      "NOTE:     27   256   0.0001            1.772     0.6769    0.08157     0.83\n",
      "NOTE:     28   256   0.0001            1.785     0.6874    0.08157     0.82\n",
      "NOTE:     29   256   0.0001            1.791     0.6912    0.08157     0.83\n",
      "NOTE:     30   256   0.0001            1.761     0.6565    0.08157     0.83\n",
      "NOTE:     31   256   0.0001            1.751     0.6411    0.08157     0.82\n",
      "NOTE:     32   256   0.0001            1.764     0.6377    0.08157     0.83\n",
      "NOTE:     33   256   0.0001             1.79     0.7028    0.08157     0.82\n",
      "NOTE:     34   256   0.0001             1.76     0.6501    0.08157     0.82\n",
      "NOTE:     35   256   0.0001            1.803     0.7062    0.08157     0.82\n",
      "NOTE:     36   256   0.0001             1.76     0.6619    0.08157     0.82\n",
      "NOTE:     37   256   0.0001            1.803     0.7278    0.08157     0.83\n",
      "NOTE:     38   256   0.0001            1.788     0.7057    0.08157     0.86\n",
      "NOTE:     39   256   0.0001            1.766     0.6495    0.08157     0.83\n",
      "NOTE:     40   256   0.0001            1.788     0.6939    0.08157     0.82\n",
      "NOTE:     41   256   0.0001            1.788     0.6986    0.08157     0.82\n",
      "NOTE:     42   256   0.0001            1.764     0.6471    0.08157     0.82\n",
      "NOTE:     43   256   0.0001            1.789     0.7008    0.08157     0.83\n",
      "NOTE:     44   256   0.0001            1.813     0.7498    0.08157     0.83\n",
      "NOTE:     45   256   0.0001            1.775     0.6738    0.08157     0.82\n",
      "NOTE:     46   256   0.0001            1.788     0.6965    0.08157     0.82\n",
      "NOTE:     47   256   0.0001            1.762     0.6528    0.08157     0.83\n",
      "NOTE:     48   256   0.0001            1.782      0.694    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     49   256   0.0001            1.754      0.627    0.08157     0.83\n",
      "NOTE:     50   256   0.0001            1.794     0.6865    0.08157     0.83\n",
      "NOTE:     51   256   0.0001             1.78     0.6757    0.08157     0.83\n",
      "NOTE:     52   256   0.0001            1.807     0.7262    0.08157     0.82\n",
      "NOTE:     53   256   0.0001             1.78     0.6875    0.08157     0.82\n",
      "NOTE:     54   256   0.0001            1.755     0.6412    0.08157     0.83\n",
      "NOTE:     55   256   0.0001            1.767     0.6496    0.08157     0.82\n",
      "NOTE:     56   256   0.0001            1.771     0.6763    0.08157     0.82\n",
      "NOTE:     57   256   0.0001            1.764     0.6539    0.08157     0.83\n",
      "NOTE:     58   256   0.0001             1.76     0.6512    0.08157     0.82\n",
      "NOTE:     59   256   0.0001             1.78     0.6895    0.08157     0.82\n",
      "NOTE:     60   256   0.0001            1.758     0.6521    0.08157     0.83\n",
      "NOTE:     61   256   0.0001            1.757     0.6411    0.08157     0.82\n",
      "NOTE:     62   256   0.0001            1.786     0.6954    0.08157     0.82\n",
      "NOTE:     63   256   0.0001            1.762     0.6546    0.08157     0.83\n",
      "NOTE:     64   256   0.0001            1.778     0.6862    0.08157     0.83\n",
      "NOTE:     65   256   0.0001            1.766     0.6665    0.08157     0.82\n",
      "NOTE:     66   256   0.0001            1.794     0.7214    0.08157     0.82\n",
      "NOTE:     67   256   0.0001            1.749     0.6342    0.08157     0.82\n",
      "NOTE:     68   256   0.0001            1.768     0.6674    0.08157     0.82\n",
      "NOTE:     69   256   0.0001            1.767     0.6703    0.08157     0.82\n",
      "NOTE:     70   256   0.0001            1.755     0.6405    0.08157     0.82\n",
      "NOTE:     71   256   0.0001            1.764     0.6529    0.08157     0.82\n",
      "NOTE:     72   256   0.0001            1.755     0.6377    0.08157     0.82\n",
      "NOTE:     73   256   0.0001            1.759     0.6514    0.08157     0.83\n",
      "NOTE:     74   256   0.0001             1.78     0.6842    0.08157     0.83\n",
      "NOTE:     75   256   0.0001            1.762     0.6619    0.08157     0.82\n",
      "NOTE:     76   256   0.0001            1.759      0.638    0.08157     0.83\n",
      "NOTE:     77   256   0.0001            1.748     0.6292    0.08157     0.83\n",
      "NOTE:     78   256   0.0001            1.742     0.6172    0.08157     0.82\n",
      "NOTE:     79   256   0.0001             1.79     0.6978    0.08157     0.82\n",
      "NOTE:     80   256   0.0001             1.76     0.6593    0.08157     0.83\n",
      "NOTE:     81   256   0.0001             1.76     0.6597    0.08157     0.83\n",
      "NOTE:     82   256   0.0001            1.782     0.6951    0.08157     0.82\n",
      "NOTE:     83   256   0.0001            1.787      0.686    0.08157     0.83\n",
      "NOTE:     84   256   0.0001            1.787     0.6939    0.08157     0.83\n",
      "NOTE:     85   256   0.0001            1.791     0.7082    0.08157     0.82\n",
      "NOTE:     86   256   0.0001            1.774     0.6707    0.08157     0.82\n",
      "NOTE:     87   256   0.0001            1.803     0.7079    0.08157     0.83\n",
      "NOTE:     88   256   0.0001             1.75     0.6496    0.08157     0.83\n",
      "NOTE:     89   256   0.0001            1.747     0.6342    0.08157     0.82\n",
      "NOTE:     90   256   0.0001            1.752     0.6393    0.08157     0.83\n",
      "NOTE:     91   256   0.0001            1.776     0.6684    0.08157     0.82\n",
      "NOTE:     92   256   0.0001            1.779     0.6879    0.08157     0.82\n",
      "NOTE:     93   256   0.0001            1.778      0.696    0.08157     0.82\n",
      "NOTE:     94   256   0.0001            1.757     0.6397    0.08157     0.82\n",
      "NOTE:     95   256   0.0001            1.754     0.6428    0.08157     0.83\n",
      "NOTE:     96   256   0.0001            1.769     0.6688    0.08157     0.83\n",
      "NOTE:     97   256   0.0001             1.75     0.6356    0.08157     0.83\n",
      "NOTE:     98   256   0.0001            1.776      0.679    0.08157     0.82\n",
      "NOTE:     99   256   0.0001            1.776     0.6867    0.08157     0.82\n",
      "NOTE:    100   256   0.0001            1.739     0.6208    0.08157     0.83\n",
      "NOTE:    101   256   0.0001            1.792     0.7076    0.08157     0.82\n",
      "NOTE:    102   256   0.0001            1.759     0.6644    0.08157     0.82\n",
      "NOTE:    103   256   0.0001            1.735     0.6081    0.08157     0.82\n",
      "NOTE:    104   256   0.0001            1.762     0.6551    0.08157     0.82\n",
      "NOTE:    105   256   0.0001            1.767     0.6627    0.08157     0.83\n",
      "NOTE:    106   256   0.0001            1.758     0.6478    0.08157     0.82\n",
      "NOTE:    107   256   0.0001            1.751     0.6394    0.08157     0.83\n",
      "NOTE:    108   256   0.0001            1.775     0.6856    0.08157     0.82\n",
      "NOTE:    109   256   0.0001            1.819     0.7449    0.08157     0.82\n",
      "NOTE:    110   256   0.0001             1.79     0.7059    0.08157     0.83\n",
      "NOTE:    111   256   0.0001            1.742     0.6277    0.08157     0.82\n",
      "NOTE:    112   256   0.0001             1.72     0.5928    0.08157     0.82\n",
      "NOTE:    113   256   0.0001            1.743     0.6271    0.08157     0.82\n",
      "NOTE:    114   256   0.0001            1.762     0.6583    0.08157     0.83\n",
      "NOTE:    115   256   0.0001            1.764     0.6742    0.08157     0.83\n",
      "NOTE:    116   256   0.0001            1.771     0.6778    0.08157     0.82\n",
      "NOTE:    117   256   0.0001            1.795     0.7076    0.08157     0.83\n",
      "NOTE:    118   256   0.0001            1.768     0.6805    0.08157     0.82\n",
      "NOTE:    119   256   0.0001            1.747     0.6257    0.08157     0.82\n",
      "NOTE:    120   256   0.0001            1.738     0.6328    0.08157     0.82\n",
      "NOTE:    121   256   0.0001            1.786     0.7045    0.08157     0.83\n",
      "NOTE:    122   256   0.0001            1.757     0.6675    0.08157     0.83\n",
      "NOTE:    123   256   0.0001            1.764     0.6624    0.08157     0.82\n",
      "NOTE:    124   256   0.0001             1.74     0.6269    0.08157     0.83\n",
      "NOTE:    125   256   0.0001            1.748     0.6572    0.08157     0.83\n",
      "NOTE:    126   256   0.0001            1.778     0.6812    0.08157     0.82\n",
      "NOTE:    127   256   0.0001            1.761     0.6591    0.08157     0.82\n",
      "NOTE:    128   256   0.0001             1.74       0.64    0.08157     0.82\n",
      "NOTE:    129   256   0.0001            1.728     0.6049    0.08157     0.82\n",
      "NOTE:    130   256   0.0001            1.733      0.624    0.08157     0.82\n",
      "NOTE:    131   256   0.0001            1.735     0.6284    0.08157     0.83\n",
      "NOTE:    132   256   0.0001            1.735      0.625    0.08157     0.83\n",
      "NOTE:    133   256   0.0001            1.744     0.6391    0.08157     0.82\n",
      "NOTE:    134   256   0.0001            1.771     0.6797    0.08157     0.83\n",
      "NOTE:    135   256   0.0001             1.75      0.644    0.08157     0.82\n",
      "NOTE:    136   256   0.0001            1.787     0.6948    0.08157     0.82\n",
      "NOTE:    137   256   0.0001            1.757     0.6552    0.08157     0.82\n",
      "NOTE:    138   256   0.0001             1.72     0.5924    0.08157     0.82\n",
      "NOTE:    139   256   0.0001            1.732     0.6259    0.08157     0.83\n",
      "NOTE:    140   256   0.0001            1.752     0.6524    0.08157     0.82\n",
      "NOTE:    141   256   0.0001             1.75     0.6514    0.08157     0.83\n",
      "NOTE:    142   256   0.0001            1.731     0.6278    0.08157     0.82\n",
      "NOTE:    143   256   0.0001             1.75     0.6315    0.08157     0.82\n",
      "NOTE:    144   256   0.0001            1.746     0.6487    0.08157     0.82\n",
      "NOTE:    145   256   0.0001            1.769     0.6685    0.08157     0.82\n",
      "NOTE:    146   256   0.0001            1.753     0.6638    0.08157     0.83\n",
      "NOTE:    147   256   0.0001            1.737     0.6386    0.08157     0.82\n",
      "NOTE:    148   256   0.0001             1.77     0.6809    0.08157     0.82\n",
      "NOTE:    149   256   0.0001            1.738     0.6298    0.08157     0.83\n",
      "NOTE:    150   256   0.0001            1.763     0.6697    0.08157     0.82\n",
      "NOTE:    151   256   0.0001            1.727     0.6226    0.08157     0.82\n",
      "NOTE:    152   256   0.0001            1.783      0.704    0.08157     0.82\n",
      "NOTE:    153   256   0.0001            1.771     0.6648    0.08157     0.82\n",
      "NOTE:    154   256   0.0001            1.751      0.642    0.08157     0.83\n",
      "NOTE:    155   256   0.0001            1.725     0.6032    0.08157     0.83\n",
      "NOTE:    156   256   0.0001            1.732     0.6216    0.08157     0.83\n",
      "NOTE:    157   256   0.0001            1.741     0.6461    0.08157     0.82\n",
      "NOTE:    158   256   0.0001            1.729     0.6132    0.08157     0.83\n",
      "NOTE:    159   256   0.0001            1.747     0.6486    0.08157     0.82\n",
      "NOTE:    160   256   0.0001             1.79     0.7234    0.08157     0.82\n",
      "NOTE:    161   256   0.0001            1.738     0.6321    0.08157     0.83\n",
      "NOTE:    162   256   0.0001            1.749     0.6518    0.08157     0.83\n",
      "NOTE:    163   256   0.0001            1.738     0.6365    0.08157     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  8        0.0001           1.766     0.6644   135.36\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001             1.74     0.6315    0.08157     0.82\n",
      "NOTE:      1   256   0.0001            1.729     0.6075    0.08157     0.83\n",
      "NOTE:      2   256   0.0001            1.734     0.6481    0.08157     0.82\n",
      "NOTE:      3   256   0.0001            1.722     0.6062    0.08157     0.82\n",
      "NOTE:      4   256   0.0001            1.743     0.6315    0.08157     0.83\n",
      "NOTE:      5   256   0.0001            1.724     0.6152    0.08157     0.82\n",
      "NOTE:      6   256   0.0001            1.747     0.6414    0.08157     0.83\n",
      "NOTE:      7   256   0.0001            1.731     0.6102    0.08157     0.82\n",
      "NOTE:      8   256   0.0001             1.77     0.6817    0.08157     0.83\n",
      "NOTE:      9   256   0.0001            1.734     0.6344    0.08157     0.83\n",
      "NOTE:     10   256   0.0001            1.751     0.6516    0.08157     0.82\n",
      "NOTE:     11   256   0.0001            1.737     0.6143    0.08157     0.83\n",
      "NOTE:     12   256   0.0001            1.728     0.6154    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     13   256   0.0001            1.748     0.6588    0.08157     0.82\n",
      "NOTE:     14   256   0.0001            1.706     0.5673    0.08157     0.83\n",
      "NOTE:     15   256   0.0001             1.76     0.6627    0.08157     0.83\n",
      "NOTE:     16   256   0.0001            1.714     0.5932    0.08157     0.82\n",
      "NOTE:     17   256   0.0001            1.757     0.6523    0.08157     0.82\n",
      "NOTE:     18   256   0.0001            1.717      0.584    0.08157     0.83\n",
      "NOTE:     19   256   0.0001             1.72     0.6035    0.08157     0.83\n",
      "NOTE:     20   256   0.0001             1.73     0.6366    0.08157     0.82\n",
      "NOTE:     21   256   0.0001            1.739     0.6486    0.08157     0.82\n",
      "NOTE:     22   256   0.0001            1.752     0.6549    0.08157     0.82\n",
      "NOTE:     23   256   0.0001            1.722     0.6169    0.08157     0.83\n",
      "NOTE:     24   256   0.0001            1.727     0.6203    0.08157     0.82\n",
      "NOTE:     25   256   0.0001            1.746     0.6361    0.08157     0.82\n",
      "NOTE:     26   256   0.0001            1.747     0.6707    0.08157     0.82\n",
      "NOTE:     27   256   0.0001            1.748     0.6459    0.08157     0.82\n",
      "NOTE:     28   256   0.0001            1.753     0.6661    0.08157     0.82\n",
      "NOTE:     29   256   0.0001            1.747     0.6505    0.08157     0.83\n",
      "NOTE:     30   256   0.0001             1.72     0.6142    0.08157     0.82\n",
      "NOTE:     31   256   0.0001            1.735     0.6344    0.08157     0.83\n",
      "NOTE:     32   256   0.0001            1.746       0.64    0.08157     0.82\n",
      "NOTE:     33   256   0.0001            1.763     0.6818    0.08157     0.82\n",
      "NOTE:     34   256   0.0001            1.747     0.6549    0.08157     0.82\n",
      "NOTE:     35   256   0.0001            1.752      0.666    0.08157     0.83\n",
      "NOTE:     36   256   0.0001            1.721     0.6107    0.08157     0.82\n",
      "NOTE:     37   256   0.0001             1.73     0.6402    0.08157     0.82\n",
      "NOTE:     38   256   0.0001             1.74     0.6257    0.08157     0.83\n",
      "NOTE:     39   256   0.0001            1.742     0.6448    0.08157     0.82\n",
      "NOTE:     40   256   0.0001            1.716     0.6238    0.08157     0.82\n",
      "NOTE:     41   256   0.0001            1.762     0.6746    0.08157     0.82\n",
      "NOTE:     42   256   0.0001             1.72     0.6013    0.08157     0.83\n",
      "NOTE:     43   256   0.0001            1.746     0.6433    0.08157     0.83\n",
      "NOTE:     44   256   0.0001            1.738     0.6218    0.08157     0.82\n",
      "NOTE:     45   256   0.0001             1.73     0.6403    0.08157     0.83\n",
      "NOTE:     46   256   0.0001            1.722     0.6202    0.08157     0.83\n",
      "NOTE:     47   256   0.0001            1.723     0.6092    0.08157     0.83\n",
      "NOTE:     48   256   0.0001            1.716     0.6069    0.08157     0.85\n",
      "NOTE:     49   256   0.0001            1.748     0.6509    0.08157     0.83\n",
      "NOTE:     50   256   0.0001            1.744     0.6349    0.08157     0.84\n",
      "NOTE:     51   256   0.0001            1.744      0.652    0.08157     0.83\n",
      "NOTE:     52   256   0.0001            1.738      0.648    0.08157     0.83\n",
      "NOTE:     53   256   0.0001            1.723     0.6217    0.08157     0.83\n",
      "NOTE:     54   256   0.0001            1.745     0.6512    0.08157     0.82\n",
      "NOTE:     55   256   0.0001            1.725     0.6277    0.08157     0.83\n",
      "NOTE:     56   256   0.0001            1.726      0.622    0.08157     0.82\n",
      "NOTE:     57   256   0.0001             1.72     0.6065    0.08157     0.82\n",
      "NOTE:     58   256   0.0001            1.737     0.6341    0.08157     0.82\n",
      "NOTE:     59   256   0.0001            1.754     0.6644    0.08157     0.83\n",
      "NOTE:     60   256   0.0001            1.733     0.6373    0.08157     0.82\n",
      "NOTE:     61   256   0.0001            1.702     0.5919    0.08157     0.82\n",
      "NOTE:     62   256   0.0001            1.739     0.6304    0.08157     0.83\n",
      "NOTE:     63   256   0.0001            1.718     0.6105    0.08157     0.83\n",
      "NOTE:     64   256   0.0001            1.723     0.6183    0.08157     0.82\n",
      "NOTE:     65   256   0.0001            1.712     0.5894    0.08157     0.83\n",
      "NOTE:     66   256   0.0001            1.725     0.6263    0.08157     0.82\n",
      "NOTE:     67   256   0.0001            1.747      0.654    0.08157     0.82\n",
      "NOTE:     68   256   0.0001            1.756     0.6698    0.08157     0.82\n",
      "NOTE:     69   256   0.0001            1.737     0.6508    0.08157     0.83\n",
      "NOTE:     70   256   0.0001            1.715     0.6015    0.08157     0.83\n",
      "NOTE:     71   256   0.0001            1.739     0.6334    0.08157     0.82\n",
      "NOTE:     72   256   0.0001            1.724      0.613    0.08157     0.84\n",
      "NOTE:     73   256   0.0001            1.752     0.6538    0.08157     0.83\n",
      "NOTE:     74   256   0.0001            1.741     0.6461    0.08157     0.83\n",
      "NOTE:     75   256   0.0001            1.713     0.5953    0.08157     0.82\n",
      "NOTE:     76   256   0.0001             1.76      0.684    0.08157     0.83\n",
      "NOTE:     77   256   0.0001            1.752     0.6649    0.08157     0.83\n",
      "NOTE:     78   256   0.0001            1.699     0.5719    0.08157     0.82\n",
      "NOTE:     79   256   0.0001            1.768     0.6938    0.08157     0.83\n",
      "NOTE:     80   256   0.0001            1.777     0.7049    0.08157     0.83\n",
      "NOTE:     81   256   0.0001            1.758     0.6654    0.08157     0.82\n",
      "NOTE:     82   256   0.0001            1.737      0.625    0.08157     0.83\n",
      "NOTE:     83   256   0.0001            1.754     0.6612    0.08157     0.83\n",
      "NOTE:     84   256   0.0001            1.723     0.5988    0.08157     0.83\n",
      "NOTE:     85   256   0.0001            1.735     0.6321    0.08157     0.82\n",
      "NOTE:     86   256   0.0001            1.741     0.6438    0.08157     0.83\n",
      "NOTE:     87   256   0.0001            1.733     0.6334    0.08157     0.82\n",
      "NOTE:     88   256   0.0001            1.718     0.6192    0.08157     0.83\n",
      "NOTE:     89   256   0.0001            1.745     0.6449    0.08157     0.87\n",
      "NOTE:     90   256   0.0001            1.735      0.647    0.08157     0.83\n",
      "NOTE:     91   256   0.0001            1.718     0.6073    0.08157     0.82\n",
      "NOTE:     92   256   0.0001            1.734       0.63    0.08157     0.82\n",
      "NOTE:     93   256   0.0001            1.672     0.5377    0.08157     0.82\n",
      "NOTE:     94   256   0.0001            1.726     0.6185    0.08157     0.82\n",
      "NOTE:     95   256   0.0001             1.72     0.6076    0.08157     0.82\n",
      "NOTE:     96   256   0.0001            1.734     0.6328    0.08157     0.82\n",
      "NOTE:     97   256   0.0001            1.737     0.6446    0.08157     0.83\n",
      "NOTE:     98   256   0.0001            1.759     0.6836    0.08157     0.82\n",
      "NOTE:     99   256   0.0001            1.684     0.5725    0.08157     0.82\n",
      "NOTE:    100   256   0.0001            1.738      0.656    0.08157     0.83\n",
      "NOTE:    101   256   0.0001            1.677     0.5437    0.08157     0.82\n",
      "NOTE:    102   256   0.0001            1.731     0.6302    0.08157     0.82\n",
      "NOTE:    103   256   0.0001            1.752     0.6741    0.08157     0.83\n",
      "NOTE:    104   256   0.0001            1.721     0.6125    0.08157     0.83\n",
      "NOTE:    105   256   0.0001            1.747     0.6379    0.08157     0.82\n",
      "NOTE:    106   256   0.0001            1.722     0.6284    0.08157     0.83\n",
      "NOTE:    107   256   0.0001            1.725     0.6262    0.08157     0.82\n",
      "NOTE:    108   256   0.0001            1.748     0.6542    0.08157     0.82\n",
      "NOTE:    109   256   0.0001            1.717     0.6041    0.08157     0.82\n",
      "NOTE:    110   256   0.0001            1.738     0.6389    0.08157     0.83\n",
      "NOTE:    111   256   0.0001            1.735     0.6286    0.08157     0.83\n",
      "NOTE:    112   256   0.0001            1.751     0.6532    0.08157     0.83\n",
      "NOTE:    113   256   0.0001            1.739     0.6512    0.08157     0.83\n",
      "NOTE:    114   256   0.0001            1.702      0.597    0.08157     0.83\n",
      "NOTE:    115   256   0.0001            1.726     0.6317    0.08157     0.82\n",
      "NOTE:    116   256   0.0001            1.766     0.6895    0.08157     0.82\n",
      "NOTE:    117   256   0.0001            1.733     0.6305    0.08157     0.83\n",
      "NOTE:    118   256   0.0001            1.712     0.5926    0.08157     0.82\n",
      "NOTE:    119   256   0.0001            1.714     0.6139    0.08157     0.82\n",
      "NOTE:    120   256   0.0001            1.725     0.6276    0.08157     0.83\n",
      "NOTE:    121   256   0.0001            1.727     0.6254    0.08157     0.82\n",
      "NOTE:    122   256   0.0001            1.703     0.6054    0.08157     0.82\n",
      "NOTE:    123   256   0.0001            1.729     0.6238    0.08157     0.82\n",
      "NOTE:    124   256   0.0001            1.762     0.6893    0.08157     0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    125   256   0.0001            1.694     0.5795    0.08157     0.83\n",
      "NOTE:    126   256   0.0001            1.707     0.6058    0.08157     0.82\n",
      "NOTE:    127   256   0.0001            1.731     0.6288    0.08157     0.83\n",
      "NOTE:    128   256   0.0001            1.732     0.6349    0.08157     0.82\n",
      "NOTE:    129   256   0.0001             1.73     0.6455    0.08157     0.83\n",
      "NOTE:    130   256   0.0001            1.763     0.7072    0.08157     0.83\n",
      "NOTE:    131   256   0.0001            1.706     0.5934    0.08157     0.83\n",
      "NOTE:    132   256   0.0001            1.703     0.5968    0.08157     0.83\n",
      "NOTE:    133   256   0.0001             1.75     0.6624    0.08157     0.83\n",
      "NOTE:    134   256   0.0001            1.741     0.6478    0.08157     0.82\n",
      "NOTE:    135   256   0.0001            1.742     0.6503    0.08157     0.83\n",
      "NOTE:    136   256   0.0001            1.721     0.6298    0.08157     0.82\n",
      "NOTE:    137   256   0.0001            1.719       0.62    0.08157     0.83\n",
      "NOTE:    138   256   0.0001              1.7     0.5876    0.08157     0.82\n",
      "NOTE:    139   256   0.0001            1.681     0.5656    0.08157     0.82\n",
      "NOTE:    140   256   0.0001            1.732     0.6477    0.08157     0.82\n",
      "NOTE:    141   256   0.0001            1.695     0.5864    0.08157     0.83\n",
      "NOTE:    142   256   0.0001            1.698     0.5908    0.08157     0.82\n",
      "NOTE:    143   256   0.0001            1.727     0.6399    0.08157     0.82\n",
      "NOTE:    144   256   0.0001            1.709     0.5967    0.08157     0.82\n",
      "NOTE:    145   256   0.0001            1.703     0.5865    0.08157     0.83\n",
      "NOTE:    146   256   0.0001             1.72     0.6259    0.08157     0.82\n",
      "NOTE:    147   256   0.0001            1.722     0.6283    0.08157     0.82\n",
      "NOTE:    148   256   0.0001            1.716     0.6127    0.08157     0.83\n",
      "NOTE:    149   256   0.0001            1.691      0.609    0.08157     0.82\n",
      "NOTE:    150   256   0.0001            1.695     0.5705    0.08157     0.82\n",
      "NOTE:    151   256   0.0001            1.729     0.6421    0.08157     0.82\n",
      "NOTE:    152   256   0.0001            1.717     0.6319    0.08157     0.82\n",
      "NOTE:    153   256   0.0001            1.748     0.6824    0.08157     0.82\n",
      "NOTE:    154   256   0.0001            1.745     0.6579    0.08157     0.82\n",
      "NOTE:    155   256   0.0001            1.719     0.6278    0.08157     0.83\n",
      "NOTE:    156   256   0.0001            1.705      0.594    0.08157     0.82\n",
      "NOTE:    157   256   0.0001            1.739     0.6554    0.08157     0.82\n",
      "NOTE:    158   256   0.0001            1.729     0.6285    0.08157     0.83\n",
      "NOTE:    159   256   0.0001            1.746      0.658    0.08157     0.82\n",
      "NOTE:    160   256   0.0001            1.721     0.6339    0.08157     0.82\n",
      "NOTE:    161   256   0.0001            1.733     0.6387    0.08157     0.83\n",
      "NOTE:    162   256   0.0001             1.72     0.6321    0.08157     0.83\n",
      "NOTE:    163   256   0.0001            1.709     0.6219    0.08157     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  9        0.0001           1.731     0.6304   135.35\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001             1.71     0.6112    0.08157     0.83\n",
      "NOTE:      1   256   0.0001            1.741     0.6608    0.08157     0.83\n",
      "NOTE:      2   256   0.0001             1.71     0.5983    0.08157     0.82\n",
      "NOTE:      3   256   0.0001            1.717      0.645    0.08157     0.82\n",
      "NOTE:      4   256   0.0001            1.704     0.5938    0.08157     0.82\n",
      "NOTE:      5   256   0.0001            1.708     0.5883    0.08157     0.83\n",
      "NOTE:      6   256   0.0001            1.744     0.6546    0.08157     0.82\n",
      "NOTE:      7   256   0.0001            1.735     0.6697    0.08157     0.83\n",
      "NOTE:      8   256   0.0001            1.743     0.6611    0.08157     0.82\n",
      "NOTE:      9   256   0.0001            1.763     0.6979    0.08157     0.82\n",
      "NOTE:     10   256   0.0001            1.747     0.6721    0.08157     0.82\n",
      "NOTE:     11   256   0.0001            1.709      0.624    0.08157     0.83\n",
      "NOTE:     12   256   0.0001             1.71      0.592    0.08157     0.83\n",
      "NOTE:     13   256   0.0001            1.724     0.6232    0.08157     0.82\n",
      "NOTE:     14   256   0.0001            1.709     0.6187    0.08157     0.83\n",
      "NOTE:     15   256   0.0001            1.735     0.6384    0.08157     0.83\n",
      "NOTE:     16   256   0.0001            1.743     0.6648    0.08157     0.82\n",
      "NOTE:     17   256   0.0001            1.713     0.6076    0.08157     0.83\n",
      "NOTE:     18   256   0.0001            1.687     0.5758    0.08157     0.82\n",
      "NOTE:     19   256   0.0001            1.715     0.6307    0.08157     0.82\n",
      "NOTE:     20   256   0.0001             1.73     0.6299    0.08157     0.82\n",
      "NOTE:     21   256   0.0001            1.732     0.6503    0.08157     0.83\n",
      "NOTE:     22   256   0.0001            1.707     0.6049    0.08157     0.83\n",
      "NOTE:     23   256   0.0001            1.688     0.5666    0.08157     0.82\n",
      "NOTE:     24   256   0.0001             1.69     0.5913    0.08157     0.83\n",
      "NOTE:     25   256   0.0001            1.699     0.5995    0.08157     0.82\n",
      "NOTE:     26   256   0.0001            1.707     0.6081    0.08157     0.82\n",
      "NOTE:     27   256   0.0001             1.71     0.6221    0.08157     0.83\n",
      "NOTE:     28   256   0.0001            1.717     0.6381    0.08157     0.83\n",
      "NOTE:     29   256   0.0001            1.718     0.6344    0.08157     0.82\n",
      "NOTE:     30   256   0.0001            1.693     0.5946    0.08157     0.82\n",
      "NOTE:     31   256   0.0001            1.713      0.619    0.08157     0.82\n",
      "NOTE:     32   256   0.0001             1.68     0.5823    0.08157     0.82\n",
      "NOTE:     33   256   0.0001            1.677     0.5758    0.08157     0.82\n",
      "NOTE:     34   256   0.0001            1.736      0.658    0.08157     0.83\n",
      "NOTE:     35   256   0.0001            1.715     0.6075    0.08157     0.83\n",
      "NOTE:     36   256   0.0001            1.694     0.5835    0.08157     0.82\n",
      "NOTE:     37   256   0.0001            1.697     0.5815    0.08157     0.83\n",
      "NOTE:     38   256   0.0001            1.684     0.5692    0.08157     0.83\n",
      "NOTE:     39   256   0.0001            1.711     0.6239    0.08157     0.82\n",
      "NOTE:     40   256   0.0001            1.668     0.5563    0.08157     0.82\n",
      "NOTE:     41   256   0.0001            1.724     0.6344    0.08157     0.83\n",
      "NOTE:     42   256   0.0001            1.721     0.6392    0.08157     0.83\n",
      "NOTE:     43   256   0.0001            1.711     0.6021    0.08157     0.82\n",
      "NOTE:     44   256   0.0001            1.667     0.5564    0.08157     0.83\n",
      "NOTE:     45   256   0.0001            1.694     0.5924    0.08157     0.83\n",
      "NOTE:     46   256   0.0001            1.684     0.5851    0.08157     0.83\n",
      "NOTE:     47   256   0.0001            1.713     0.6228    0.08157     0.82\n",
      "NOTE:     48   256   0.0001            1.713     0.6227    0.08157     0.82\n",
      "NOTE:     49   256   0.0001            1.686     0.5718    0.08157     0.83\n",
      "NOTE:     50   256   0.0001            1.706     0.6157    0.08157     0.82\n",
      "NOTE:     51   256   0.0001            1.674     0.5738    0.08157     0.83\n",
      "NOTE:     52   256   0.0001            1.695      0.595    0.08157     0.83\n",
      "NOTE:     53   256   0.0001            1.703     0.6204    0.08157     0.83\n",
      "NOTE:     54   256   0.0001            1.678     0.5692    0.08157     0.84\n",
      "NOTE:     55   256   0.0001            1.696     0.6231    0.08157     0.83\n",
      "NOTE:     56   256   0.0001            1.667     0.5537    0.08157     0.83\n",
      "NOTE:     57   256   0.0001             1.66     0.5436    0.08157     0.82\n",
      "NOTE:     58   256   0.0001            1.706     0.6124    0.08157     0.83\n",
      "NOTE:     59   256   0.0001            1.733     0.6596    0.08157     0.90\n",
      "NOTE:     60   256   0.0001            1.703     0.6086    0.08157     0.86\n",
      "NOTE:     61   256   0.0001            1.696      0.591    0.08157     0.82\n",
      "NOTE:     62   256   0.0001            1.672     0.5694    0.08157     0.82\n",
      "NOTE:     63   256   0.0001            1.715     0.6149    0.08157     0.83\n",
      "NOTE:     64   256   0.0001              1.7     0.6196    0.08157     0.82\n",
      "NOTE:     65   256   0.0001            1.699     0.6205    0.08157     0.82\n",
      "NOTE:     66   256   0.0001            1.726      0.649    0.08157     0.87\n",
      "NOTE:     67   256   0.0001             1.71     0.6285    0.08157     0.82\n",
      "NOTE:     68   256   0.0001            1.696     0.5899    0.08157     0.82\n",
      "NOTE:     69   256   0.0001             1.68     0.5976    0.08157     0.83\n",
      "NOTE:     70   256   0.0001            1.686     0.5902    0.08157     0.82\n",
      "NOTE:     71   256   0.0001            1.692     0.5945    0.08157     0.82\n",
      "NOTE:     72   256   0.0001            1.662     0.5852    0.08157     0.83\n",
      "NOTE:     73   256   0.0001            1.713     0.6235    0.08157     0.82\n",
      "NOTE:     74   256   0.0001            1.654     0.5504    0.08157     0.81\n",
      "NOTE:     75   256   0.0001            1.665     0.5422    0.08157     0.83\n",
      "NOTE:     76   256   0.0001            1.709     0.6353    0.08157     0.83\n",
      "NOTE:     77   256   0.0001            1.699     0.6122    0.08157     0.82\n",
      "NOTE:     78   256   0.0001            1.674     0.5591    0.08157     0.82\n",
      "NOTE:     79   256   0.0001            1.715     0.6584    0.08157     0.83\n",
      "NOTE:     80   256   0.0001            1.725     0.6727    0.08157     0.82\n",
      "NOTE:     81   256   0.0001            1.733     0.6892    0.08157     0.82\n",
      "NOTE:     82   256   0.0001            1.666     0.5818    0.08157     0.83\n",
      "NOTE:     83   256   0.0001            1.687     0.6013    0.08157     0.83\n",
      "NOTE:     84   256   0.0001            1.683     0.5916    0.08158     0.82\n",
      "NOTE:     85   256   0.0001            1.679     0.5803    0.08157     0.82\n",
      "NOTE:     86   256   0.0001            1.692     0.6208    0.08157     0.83\n",
      "NOTE:     87   256   0.0001            1.708     0.6535    0.08157     0.83\n",
      "NOTE:     88   256   0.0001            1.706      0.626    0.08157     0.82\n",
      "NOTE:     89   256   0.0001            1.684     0.5914    0.08157     0.83\n",
      "NOTE:     90   256   0.0001            1.716     0.6387    0.08157     0.83\n",
      "NOTE:     91   256   0.0001            1.667     0.5597    0.08157     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     92   256   0.0001            1.669     0.5447    0.08157     0.83\n",
      "NOTE:     93   256   0.0001            1.671      0.611    0.08158     0.83\n",
      "NOTE:     94   256   0.0001            1.697     0.6062    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.728     0.6539    0.08158     0.83\n",
      "NOTE:     96   256   0.0001            1.708     0.6443    0.08158     0.83\n",
      "NOTE:     97   256   0.0001            1.711      0.623    0.08158     0.82\n",
      "NOTE:     98   256   0.0001              1.7     0.6085    0.08158     0.82\n",
      "NOTE:     99   256   0.0001            1.686     0.6184    0.08157     0.83\n",
      "NOTE:    100   256   0.0001            1.671     0.5704    0.08157     0.83\n",
      "NOTE:    101   256   0.0001            1.723     0.6622    0.08158     0.82\n",
      "NOTE:    102   256   0.0001            1.662     0.5987    0.08158     0.82\n",
      "NOTE:    103   256   0.0001            1.718     0.6565    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.685     0.5899    0.08158     0.82\n",
      "NOTE:    105   256   0.0001            1.632     0.5072    0.08158     0.82\n",
      "NOTE:    106   256   0.0001            1.659     0.5481    0.08158     0.83\n",
      "NOTE:    107   256   0.0001             1.68     0.5776    0.08158     0.82\n",
      "NOTE:    108   256   0.0001            1.714     0.6415    0.08158     0.82\n",
      "NOTE:    109   256   0.0001            1.666     0.5612    0.08158     0.82\n",
      "NOTE:    110   256   0.0001            1.653     0.5609    0.08158     0.82\n",
      "NOTE:    111   256   0.0001             1.68     0.5834    0.08158     0.83\n",
      "NOTE:    112   256   0.0001            1.727     0.6916    0.08158     0.83\n",
      "NOTE:    113   256   0.0001            1.684     0.6096    0.08158     0.83\n",
      "NOTE:    114   256   0.0001            1.712     0.6416    0.08158     0.82\n",
      "NOTE:    115   256   0.0001            1.695     0.6029    0.08158     0.82\n",
      "NOTE:    116   256   0.0001            1.719     0.6683    0.08158     0.83\n",
      "NOTE:    117   256   0.0001             1.71     0.6598    0.08158     0.82\n",
      "NOTE:    118   256   0.0001             1.63     0.5237    0.08158     0.82\n",
      "NOTE:    119   256   0.0001            1.679     0.6031    0.08158     0.83\n",
      "NOTE:    120   256   0.0001            1.683     0.6191    0.08158     0.82\n",
      "NOTE:    121   256   0.0001            1.731     0.6795    0.08158     0.82\n",
      "NOTE:    122   256   0.0001            1.641     0.5333    0.08158     0.82\n",
      "NOTE:    123   256   0.0001            1.713     0.6575    0.08158     0.83\n",
      "NOTE:    124   256   0.0001            1.684     0.6128    0.08158     0.83\n",
      "NOTE:    125   256   0.0001            1.665     0.5689    0.08158     0.82\n",
      "NOTE:    126   256   0.0001            1.679     0.5955    0.08158     0.83\n",
      "NOTE:    127   256   0.0001            1.698      0.615    0.08158     0.83\n",
      "NOTE:    128   256   0.0001            1.692     0.6053    0.08158     0.82\n",
      "NOTE:    129   256   0.0001            1.713     0.6446    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.732     0.6781    0.08158     0.83\n",
      "NOTE:    131   256   0.0001            1.681     0.5962    0.08158     0.83\n",
      "NOTE:    132   256   0.0001             1.65     0.5203    0.08158     0.82\n",
      "NOTE:    133   256   0.0001            1.669     0.5818    0.08158     0.83\n",
      "NOTE:    134   256   0.0001            1.705     0.6186    0.08158     0.83\n",
      "NOTE:    135   256   0.0001            1.686     0.6067    0.08158     0.82\n",
      "NOTE:    136   256   0.0001            1.713     0.6625    0.08158     0.83\n",
      "NOTE:    137   256   0.0001            1.673     0.6275    0.08158     0.83\n",
      "NOTE:    138   256   0.0001            1.682     0.6125    0.08158     0.83\n",
      "NOTE:    139   256   0.0001            1.702     0.6284    0.08158     0.82\n",
      "NOTE:    140   256   0.0001            1.689     0.6089    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.702     0.6378    0.08158     0.83\n",
      "NOTE:    142   256   0.0001            1.638     0.5382    0.08158     0.82\n",
      "NOTE:    143   256   0.0001            1.639     0.5308    0.08158     0.82\n",
      "NOTE:    144   256   0.0001            1.651     0.5534    0.08158     0.82\n",
      "NOTE:    145   256   0.0001            1.694     0.6216    0.08158     0.82\n",
      "NOTE:    146   256   0.0001            1.673     0.5929    0.08158     0.82\n",
      "NOTE:    147   256   0.0001            1.656     0.5742    0.08158     0.82\n",
      "NOTE:    148   256   0.0001            1.661     0.5878    0.08158     0.83\n",
      "NOTE:    149   256   0.0001            1.709     0.6705    0.08158     0.82\n",
      "NOTE:    150   256   0.0001            1.694      0.604    0.08158     0.82\n",
      "NOTE:    151   256   0.0001            1.701     0.6389    0.08158     0.82\n",
      "NOTE:    152   256   0.0001            1.675     0.6235    0.08158     0.82\n",
      "NOTE:    153   256   0.0001            1.677     0.6053    0.08158     0.83\n",
      "NOTE:    154   256   0.0001            1.686     0.5982    0.08158     0.82\n",
      "NOTE:    155   256   0.0001            1.685     0.6063    0.08158     0.82\n",
      "NOTE:    156   256   0.0001             1.69     0.6206    0.08158     0.82\n",
      "NOTE:    157   256   0.0001            1.686       0.62    0.08158     0.83\n",
      "NOTE:    158   256   0.0001            1.627     0.5253    0.08158     0.83\n",
      "NOTE:    159   256   0.0001            1.676     0.6114    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.663     0.6101    0.08158     0.83\n",
      "NOTE:    161   256   0.0001            1.679     0.6146    0.08158     0.83\n",
      "NOTE:    162   256   0.0001            1.701     0.6439    0.08158     0.82\n",
      "NOTE:    163   256   0.0001            1.669     0.5953    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  10       0.0001           1.695     0.6087   135.44\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.647     0.5741    0.08158     0.83\n",
      "NOTE:      1   256   0.0001             1.72      0.676    0.08158     0.83\n",
      "NOTE:      2   256   0.0001            1.681     0.6207    0.08158     0.82\n",
      "NOTE:      3   256   0.0001            1.655     0.5493    0.08158     0.83\n",
      "NOTE:      4   256   0.0001            1.625     0.5355    0.08158     0.82\n",
      "NOTE:      5   256   0.0001            1.627     0.5282    0.08158     0.82\n",
      "NOTE:      6   256   0.0001            1.647     0.5838    0.08158     0.82\n",
      "NOTE:      7   256   0.0001            1.679     0.6118    0.08158     0.83\n",
      "NOTE:      8   256   0.0001            1.664     0.5861    0.08158     0.83\n",
      "NOTE:      9   256   0.0001            1.666     0.5921    0.08158     0.83\n",
      "NOTE:     10   256   0.0001            1.664     0.6026    0.08158     0.83\n",
      "NOTE:     11   256   0.0001            1.645     0.5601    0.08158     0.83\n",
      "NOTE:     12   256   0.0001             1.61      0.514    0.08158     0.82\n",
      "NOTE:     13   256   0.0001            1.664     0.5899    0.08158     0.82\n",
      "NOTE:     14   256   0.0001            1.672     0.5931    0.08158     0.83\n",
      "NOTE:     15   256   0.0001            1.664     0.5749    0.08158     0.82\n",
      "NOTE:     16   256   0.0001            1.637     0.5412    0.08158     0.82\n",
      "NOTE:     17   256   0.0001            1.642     0.5473    0.08158     0.83\n",
      "NOTE:     18   256   0.0001            1.681     0.5994    0.08158     0.83\n",
      "NOTE:     19   256   0.0001            1.721     0.6865    0.08158     0.82\n",
      "NOTE:     20   256   0.0001             1.68     0.6204    0.08158     0.83\n",
      "NOTE:     21   256   0.0001            1.649     0.5552    0.08158     0.83\n",
      "NOTE:     22   256   0.0001            1.689      0.635    0.08158     0.82\n",
      "NOTE:     23   256   0.0001            1.638     0.5507    0.08158     0.85\n",
      "NOTE:     24   256   0.0001            1.683     0.5824    0.08158     0.82\n",
      "NOTE:     25   256   0.0001            1.675     0.5928    0.08158     0.83\n",
      "NOTE:     26   256   0.0001            1.646     0.5681    0.08158     0.82\n",
      "NOTE:     27   256   0.0001            1.642      0.569    0.08158     0.83\n",
      "NOTE:     28   256   0.0001            1.665     0.5968    0.08158     0.83\n",
      "NOTE:     29   256   0.0001            1.684     0.6253    0.08158     0.82\n",
      "NOTE:     30   256   0.0001            1.642     0.5641    0.08158     0.83\n",
      "NOTE:     31   256   0.0001            1.619     0.5368    0.08158     0.83\n",
      "NOTE:     32   256   0.0001            1.699     0.6434    0.08158     0.82\n",
      "NOTE:     33   256   0.0001            1.675     0.6098    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.703     0.6591    0.08158     0.83\n",
      "NOTE:     35   256   0.0001            1.678     0.6454    0.08158     0.83\n",
      "NOTE:     36   256   0.0001            1.642     0.5407    0.08158     0.82\n",
      "NOTE:     37   256   0.0001            1.654     0.5688    0.08158     0.83\n",
      "NOTE:     38   256   0.0001            1.705      0.669    0.08158     0.83\n",
      "NOTE:     39   256   0.0001            1.617     0.5416    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     40   256   0.0001            1.652     0.5913    0.08158     0.83\n",
      "NOTE:     41   256   0.0001            1.653     0.5763    0.08158     0.83\n",
      "NOTE:     42   256   0.0001            1.641     0.5627    0.08158     0.83\n",
      "NOTE:     43   256   0.0001            1.646     0.5636    0.08158     0.82\n",
      "NOTE:     44   256   0.0001             1.68     0.6216    0.08158     0.82\n",
      "NOTE:     45   256   0.0001            1.653     0.5617    0.08158     0.83\n",
      "NOTE:     46   256   0.0001            1.655     0.5776    0.08158     0.82\n",
      "NOTE:     47   256   0.0001            1.648     0.5634    0.08158     0.82\n",
      "NOTE:     48   256   0.0001             1.67     0.5871    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.665     0.5943    0.08158     0.82\n",
      "NOTE:     50   256   0.0001            1.636     0.5456    0.08158     0.83\n",
      "NOTE:     51   256   0.0001            1.688      0.658    0.08158     0.82\n",
      "NOTE:     52   256   0.0001            1.642     0.5695    0.08158     0.84\n",
      "NOTE:     53   256   0.0001            1.661     0.5671    0.08158     0.82\n",
      "NOTE:     54   256   0.0001            1.708     0.6493    0.08158     0.83\n",
      "NOTE:     55   256   0.0001            1.659     0.5743    0.08158     0.82\n",
      "NOTE:     56   256   0.0001            1.688     0.6222    0.08158     0.82\n",
      "NOTE:     57   256   0.0001            1.668     0.6174    0.08158     0.83\n",
      "NOTE:     58   256   0.0001            1.628     0.5566    0.08158     0.82\n",
      "NOTE:     59   256   0.0001            1.713     0.6809    0.08158     0.82\n",
      "NOTE:     60   256   0.0001            1.651     0.5608    0.08158     0.82\n",
      "NOTE:     61   256   0.0001            1.681     0.6279    0.08158     0.83\n",
      "NOTE:     62   256   0.0001            1.686     0.6202    0.08158     0.83\n",
      "NOTE:     63   256   0.0001            1.663     0.5732    0.08158     0.82\n",
      "NOTE:     64   256   0.0001            1.659     0.5932    0.08158     0.82\n",
      "NOTE:     65   256   0.0001            1.667     0.5835    0.08158     0.82\n",
      "NOTE:     66   256   0.0001             1.66     0.5692    0.08158     0.82\n",
      "NOTE:     67   256   0.0001            1.648     0.5515    0.08158     0.82\n",
      "NOTE:     68   256   0.0001            1.624     0.5381    0.08158     0.82\n",
      "NOTE:     69   256   0.0001            1.669     0.5934    0.08158     0.83\n",
      "NOTE:     70   256   0.0001             1.67     0.5899    0.08158     0.82\n",
      "NOTE:     71   256   0.0001            1.636      0.561    0.08158     0.82\n",
      "NOTE:     72   256   0.0001            1.694     0.6381    0.08158     0.82\n",
      "NOTE:     73   256   0.0001             1.69     0.6246    0.08158     0.82\n",
      "NOTE:     74   256   0.0001            1.653     0.6301    0.08158     0.83\n",
      "NOTE:     75   256   0.0001            1.648     0.5657    0.08158     0.82\n",
      "NOTE:     76   256   0.0001            1.636     0.5676    0.08158     0.83\n",
      "NOTE:     77   256   0.0001            1.627     0.5291    0.08158     0.82\n",
      "NOTE:     78   256   0.0001            1.641     0.5999    0.08158     0.83\n",
      "NOTE:     79   256   0.0001            1.643     0.5791    0.08158     0.82\n",
      "NOTE:     80   256   0.0001            1.662     0.6027    0.08158     0.82\n",
      "NOTE:     81   256   0.0001            1.616     0.5244    0.08158     0.83\n",
      "NOTE:     82   256   0.0001            1.643     0.5665    0.08158     0.83\n",
      "NOTE:     83   256   0.0001            1.661     0.6003    0.08158     0.82\n",
      "NOTE:     84   256   0.0001            1.637     0.5502    0.08158     0.82\n",
      "NOTE:     85   256   0.0001            1.639     0.5718    0.08158     0.83\n",
      "NOTE:     86   256   0.0001             1.66      0.599    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.713     0.6856    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.635      0.557    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.674     0.6228    0.08158     0.82\n",
      "NOTE:     90   256   0.0001             1.68     0.6105    0.08158     0.82\n",
      "NOTE:     91   256   0.0001            1.659     0.5682    0.08158     0.83\n",
      "NOTE:     92   256   0.0001            1.665     0.5963    0.08158     0.82\n",
      "NOTE:     93   256   0.0001            1.657     0.6093    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.702     0.6695    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.647     0.5776    0.08158     0.82\n",
      "NOTE:     96   256   0.0001            1.644     0.5565    0.08158     0.82\n",
      "NOTE:     97   256   0.0001            1.648     0.5868    0.08158     0.82\n",
      "NOTE:     98   256   0.0001            1.653     0.5851    0.08158     0.83\n",
      "NOTE:     99   256   0.0001            1.693     0.6364    0.08158     0.82\n",
      "NOTE:    100   256   0.0001             1.65     0.5542    0.08158     0.81\n",
      "NOTE:    101   256   0.0001              1.7     0.6409    0.08158     0.82\n",
      "NOTE:    102   256   0.0001            1.665     0.5819    0.08158     0.83\n",
      "NOTE:    103   256   0.0001            1.654     0.5826    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.628     0.5612    0.08158     0.82\n",
      "NOTE:    105   256   0.0001            1.673     0.6444    0.08158     0.82\n",
      "NOTE:    106   256   0.0001            1.658     0.5883    0.08158     0.83\n",
      "NOTE:    107   256   0.0001            1.677     0.6333    0.08158     0.82\n",
      "NOTE:    108   256   0.0001            1.671     0.6211    0.08158     0.83\n",
      "NOTE:    109   256   0.0001            1.677     0.6166    0.08158     0.83\n",
      "NOTE:    110   256   0.0001            1.667     0.6225    0.08158     0.83\n",
      "NOTE:    111   256   0.0001            1.649     0.5921    0.08158     0.82\n",
      "NOTE:    112   256   0.0001            1.639     0.5933    0.08158     0.82\n",
      "NOTE:    113   256   0.0001            1.683     0.6315    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.664     0.6103    0.08158     0.82\n",
      "NOTE:    115   256   0.0001             1.63     0.5475    0.08158     0.83\n",
      "NOTE:    116   256   0.0001            1.635      0.556    0.08158     0.82\n",
      "NOTE:    117   256   0.0001            1.634     0.5778    0.08158     0.82\n",
      "NOTE:    118   256   0.0001            1.621     0.5061    0.08158     0.82\n",
      "NOTE:    119   256   0.0001            1.683     0.6229    0.08158     0.83\n",
      "NOTE:    120   256   0.0001            1.582      0.501    0.08158     0.82\n",
      "NOTE:    121   256   0.0001            1.667     0.6105    0.08158     0.82\n",
      "NOTE:    122   256   0.0001            1.648     0.5996    0.08158     0.82\n",
      "NOTE:    123   256   0.0001            1.631     0.5635    0.08158     0.83\n",
      "NOTE:    124   256   0.0001            1.672      0.644    0.08158     0.82\n",
      "NOTE:    125   256   0.0001             1.63     0.5531    0.08158     0.82\n",
      "NOTE:    126   256   0.0001             1.65     0.5712    0.08158     0.82\n",
      "NOTE:    127   256   0.0001            1.682     0.6222    0.08158     0.82\n",
      "NOTE:    128   256   0.0001            1.648     0.6293    0.08158     0.82\n",
      "NOTE:    129   256   0.0001            1.677     0.6104    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.637     0.5795    0.08158     0.83\n",
      "NOTE:    131   256   0.0001            1.637     0.5817    0.08158     0.82\n",
      "NOTE:    132   256   0.0001            1.592     0.5218    0.08158     0.82\n",
      "NOTE:    133   256   0.0001            1.626     0.5641    0.08158     0.83\n",
      "NOTE:    134   256   0.0001            1.674     0.6459    0.08158     0.82\n",
      "NOTE:    135   256   0.0001            1.669     0.6464    0.08158     0.85\n",
      "NOTE:    136   256   0.0001            1.645     0.5884    0.08158     0.82\n",
      "NOTE:    137   256   0.0001            1.623     0.5822    0.08158     0.82\n",
      "NOTE:    138   256   0.0001            1.587     0.5159    0.08158     0.82\n",
      "NOTE:    139   256   0.0001            1.651     0.6137    0.08158     0.83\n",
      "NOTE:    140   256   0.0001            1.605     0.5247    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.606     0.5333    0.08158     0.82\n",
      "NOTE:    142   256   0.0001             1.59     0.5332    0.08158     0.83\n",
      "NOTE:    143   256   0.0001            1.659     0.6081    0.08158     0.83\n",
      "NOTE:    144   256   0.0001            1.649     0.5918    0.08158     0.82\n",
      "NOTE:    145   256   0.0001            1.621     0.5642    0.08158     0.82\n",
      "NOTE:    146   256   0.0001            1.629     0.5574    0.08158     0.82\n",
      "NOTE:    147   256   0.0001            1.638     0.5766    0.08158     0.82\n",
      "NOTE:    148   256   0.0001            1.641      0.588    0.08158     0.82\n",
      "NOTE:    149   256   0.0001            1.617     0.5257    0.08158     0.82\n",
      "NOTE:    150   256   0.0001            1.626     0.5539    0.08158     0.82\n",
      "NOTE:    151   256   0.0001            1.611     0.5269    0.08158     0.82\n",
      "NOTE:    152   256   0.0001            1.611     0.5442    0.08158     0.82\n",
      "NOTE:    153   256   0.0001            1.656     0.5844    0.08158     0.83\n",
      "NOTE:    154   256   0.0001            1.613     0.5719    0.08158     0.82\n",
      "NOTE:    155   256   0.0001            1.615     0.5904    0.08158     0.82\n",
      "NOTE:    156   256   0.0001            1.664     0.6138    0.08158     0.83\n",
      "NOTE:    157   256   0.0001            1.619     0.5281    0.08158     0.83\n",
      "NOTE:    158   256   0.0001            1.589     0.5156    0.08158     0.82\n",
      "NOTE:    159   256   0.0001            1.645     0.6186    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.656       0.59    0.08158     0.83\n",
      "NOTE:    161   256   0.0001            1.613     0.5678    0.08158     0.82\n",
      "NOTE:    162   256   0.0001            1.619     0.5471    0.08158     0.82\n",
      "NOTE:    163   256   0.0001            1.614     0.5363    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  11       0.0001           1.653     0.5858   135.27\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.604     0.5312    0.08158     0.83\n",
      "NOTE:      1   256   0.0001            1.636     0.5833    0.08158     0.82\n",
      "NOTE:      2   256   0.0001            1.668     0.6483    0.08158     0.83\n",
      "NOTE:      3   256   0.0001            1.622     0.5566    0.08158     0.83\n",
      "NOTE:      4   256   0.0001             1.62     0.5454    0.08158     0.83\n",
      "NOTE:      5   256   0.0001            1.585     0.5154    0.08158     0.83\n",
      "NOTE:      6   256   0.0001            1.613     0.5426    0.08158     0.82\n",
      "NOTE:      7   256   0.0001            1.615      0.575    0.08158     0.82\n",
      "NOTE:      8   256   0.0001            1.607     0.5309    0.08158     0.82\n",
      "NOTE:      9   256   0.0001            1.597      0.522    0.08158     0.83\n",
      "NOTE:     10   256   0.0001            1.641     0.5904    0.08158     0.83\n",
      "NOTE:     11   256   0.0001            1.637     0.5892    0.08158     0.82\n",
      "NOTE:     12   256   0.0001            1.668     0.6471    0.08158     0.83\n",
      "NOTE:     13   256   0.0001            1.612     0.5642    0.08158     0.82\n",
      "NOTE:     14   256   0.0001            1.591     0.5568    0.08158     0.82\n",
      "NOTE:     15   256   0.0001            1.625      0.596    0.08158     0.82\n",
      "NOTE:     16   256   0.0001            1.633     0.6129    0.08158     0.82\n",
      "NOTE:     17   256   0.0001             1.62     0.5701    0.08158     0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     18   256   0.0001            1.654     0.6322    0.08158     0.82\n",
      "NOTE:     19   256   0.0001            1.618      0.581    0.08158     0.82\n",
      "NOTE:     20   256   0.0001            1.634     0.5962    0.08158     0.83\n",
      "NOTE:     21   256   0.0001            1.624     0.5934    0.08158     0.82\n",
      "NOTE:     22   256   0.0001            1.656     0.6147    0.08158     0.82\n",
      "NOTE:     23   256   0.0001             1.65     0.5952    0.08158     0.82\n",
      "NOTE:     24   256   0.0001            1.629      0.575    0.08158     0.82\n",
      "NOTE:     25   256   0.0001            1.651     0.6091    0.08158     0.82\n",
      "NOTE:     26   256   0.0001            1.618     0.5615    0.08158     0.82\n",
      "NOTE:     27   256   0.0001            1.576     0.5191    0.08158     0.82\n",
      "NOTE:     28   256   0.0001            1.567     0.4862    0.08158     0.82\n",
      "NOTE:     29   256   0.0001             1.59     0.5433    0.08158     0.83\n",
      "NOTE:     30   256   0.0001            1.646     0.6037    0.08158     0.82\n",
      "NOTE:     31   256   0.0001            1.633     0.6164    0.08158     0.82\n",
      "NOTE:     32   256   0.0001            1.569     0.4907    0.08158     0.82\n",
      "NOTE:     33   256   0.0001            1.614     0.5829    0.08158     0.83\n",
      "NOTE:     34   256   0.0001            1.587     0.5202    0.08158     0.83\n",
      "NOTE:     35   256   0.0001            1.605     0.5491    0.08158     0.82\n",
      "NOTE:     36   256   0.0001            1.632     0.5997    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.624     0.5773    0.08158     0.83\n",
      "NOTE:     38   256   0.0001            1.577     0.5542    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.549     0.4832    0.08158     0.83\n",
      "NOTE:     40   256   0.0001            1.618     0.5865    0.08158     0.83\n",
      "NOTE:     41   256   0.0001            1.639     0.6556    0.08158     0.83\n",
      "NOTE:     42   256   0.0001            1.626     0.5713    0.08158     0.82\n",
      "NOTE:     43   256   0.0001            1.586     0.5199    0.08158     0.83\n",
      "NOTE:     44   256   0.0001            1.636     0.5796    0.08158     0.83\n",
      "NOTE:     45   256   0.0001            1.624     0.5842    0.08158     0.82\n",
      "NOTE:     46   256   0.0001            1.631     0.6063    0.08158     0.82\n",
      "NOTE:     47   256   0.0001            1.619     0.5905    0.08158     0.82\n",
      "NOTE:     48   256   0.0001            1.656     0.6756    0.08158     0.82\n",
      "NOTE:     49   256   0.0001            1.579     0.5204    0.08158     0.82\n",
      "NOTE:     50   256   0.0001            1.638     0.6034    0.08158     0.83\n",
      "NOTE:     51   256   0.0001            1.643     0.6433    0.08158     0.83\n",
      "NOTE:     52   256   0.0001            1.629     0.6172    0.08158     0.82\n",
      "NOTE:     53   256   0.0001            1.633     0.6247    0.08158     0.83\n",
      "NOTE:     54   256   0.0001            1.571     0.4871    0.08158     0.83\n",
      "NOTE:     55   256   0.0001            1.615     0.5914    0.08158     0.82\n",
      "NOTE:     56   256   0.0001            1.624     0.6293    0.08158     0.82\n",
      "NOTE:     57   256   0.0001            1.631     0.5904    0.08158     0.83\n",
      "NOTE:     58   256   0.0001            1.593     0.5677    0.08158     0.83\n",
      "NOTE:     59   256   0.0001            1.608     0.5402    0.08158     0.82\n",
      "NOTE:     60   256   0.0001            1.645     0.6283    0.08158     0.83\n",
      "NOTE:     61   256   0.0001            1.609     0.5742    0.08158     0.82\n",
      "NOTE:     62   256   0.0001            1.566     0.5192    0.08158     0.81\n",
      "NOTE:     63   256   0.0001            1.558     0.5034    0.08158     0.83\n",
      "NOTE:     64   256   0.0001            1.553      0.504    0.08158     0.82\n",
      "NOTE:     65   256   0.0001            1.582     0.5475    0.08158     0.82\n",
      "NOTE:     66   256   0.0001            1.648     0.6344    0.08158     0.82\n",
      "NOTE:     67   256   0.0001            1.598     0.5735    0.08158     0.82\n",
      "NOTE:     68   256   0.0001            1.657      0.646    0.08158     0.83\n",
      "NOTE:     69   256   0.0001            1.575     0.5207    0.08158     0.85\n",
      "NOTE:     70   256   0.0001            1.631     0.6138    0.08158     0.83\n",
      "NOTE:     71   256   0.0001            1.611     0.5801    0.08158     0.82\n",
      "NOTE:     72   256   0.0001            1.605     0.5604    0.08158     0.82\n",
      "NOTE:     73   256   0.0001            1.616     0.5833    0.08158     0.82\n",
      "NOTE:     74   256   0.0001            1.544     0.4718    0.08158     0.83\n",
      "NOTE:     75   256   0.0001            1.594     0.5604    0.08158     0.88\n",
      "NOTE:     76   256   0.0001            1.564     0.5071    0.08158     0.82\n",
      "NOTE:     77   256   0.0001            1.556     0.4802    0.08158     0.82\n",
      "NOTE:     78   256   0.0001            1.562     0.5235    0.08158     0.86\n",
      "NOTE:     79   256   0.0001             1.63     0.6225    0.08158     0.81\n",
      "NOTE:     80   256   0.0001             1.61     0.5812    0.08158     0.82\n",
      "NOTE:     81   256   0.0001            1.563     0.5138    0.08158     0.82\n",
      "NOTE:     82   256   0.0001            1.605      0.595    0.08158     0.83\n",
      "NOTE:     83   256   0.0001            1.555     0.4874    0.08158     0.82\n",
      "NOTE:     84   256   0.0001            1.579     0.5295    0.08158     0.90\n",
      "NOTE:     85   256   0.0001             1.59     0.5702    0.08158     0.81\n",
      "NOTE:     86   256   0.0001            1.571     0.5373    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.597     0.5928    0.08158     0.86\n",
      "NOTE:     88   256   0.0001            1.599     0.5391    0.08158     0.90\n",
      "NOTE:     89   256   0.0001            1.562     0.5219    0.08158     0.91\n",
      "NOTE:     90   256   0.0001             1.61     0.6183    0.08158     0.81\n",
      "NOTE:     91   256   0.0001            1.588     0.5677    0.08158     0.83\n",
      "NOTE:     92   256   0.0001            1.632     0.6318    0.08158     0.82\n",
      "NOTE:     93   256   0.0001            1.575     0.5421    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.604      0.608    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.604     0.5905    0.08158     0.83\n",
      "NOTE:     96   256   0.0001            1.595     0.5628    0.08158     0.82\n",
      "NOTE:     97   256   0.0001            1.627     0.6204    0.08158     0.88\n",
      "NOTE:     98   256   0.0001            1.577     0.5421    0.08158     0.82\n",
      "NOTE:     99   256   0.0001            1.606     0.5422    0.08158     0.82\n",
      "NOTE:    100   256   0.0001            1.605      0.606    0.08158     0.86\n",
      "NOTE:    101   256   0.0001            1.612     0.5665    0.08158     0.82\n",
      "NOTE:    102   256   0.0001            1.559     0.4917    0.08158     0.82\n",
      "NOTE:    103   256   0.0001            1.595       0.56    0.08158     0.82\n",
      "NOTE:    104   256   0.0001            1.666     0.6788    0.08158     0.82\n",
      "NOTE:    105   256   0.0001            1.566     0.5244    0.08158     0.82\n",
      "NOTE:    106   256   0.0001            1.545     0.4917    0.08158     0.87\n",
      "NOTE:    107   256   0.0001            1.568     0.5536    0.08158     0.82\n",
      "NOTE:    108   256   0.0001            1.599     0.5704    0.08158     0.82\n",
      "NOTE:    109   256   0.0001            1.571     0.5336    0.08158     0.89\n",
      "NOTE:    110   256   0.0001            1.559     0.5463    0.08158     0.91\n",
      "NOTE:    111   256   0.0001            1.585     0.5518    0.08158     0.84\n",
      "NOTE:    112   256   0.0001            1.606     0.6392    0.08158     0.82\n",
      "NOTE:    113   256   0.0001            1.548      0.561    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.595     0.5686    0.08158     0.83\n",
      "NOTE:    115   256   0.0001            1.595     0.6026    0.08158     0.83\n",
      "NOTE:    116   256   0.0001            1.625     0.6219    0.08158     0.83\n",
      "NOTE:    117   256   0.0001             1.63     0.6207    0.08158     0.83\n",
      "NOTE:    118   256   0.0001            1.561      0.526    0.08158     0.82\n",
      "NOTE:    119   256   0.0001            1.574     0.5533    0.08158     0.82\n",
      "NOTE:    120   256   0.0001            1.596     0.5801    0.08158     0.90\n",
      "NOTE:    121   256   0.0001            1.555       0.55    0.08158     0.88\n",
      "NOTE:    122   256   0.0001            1.604     0.5855    0.08158     0.83\n",
      "NOTE:    123   256   0.0001            1.599     0.6508    0.08158     0.83\n",
      "NOTE:    124   256   0.0001            1.579      0.555    0.08158     0.83\n",
      "NOTE:    125   256   0.0001            1.535     0.4981    0.08158     0.82\n",
      "NOTE:    126   256   0.0001            1.626      0.608    0.08158     0.83\n",
      "NOTE:    127   256   0.0001            1.606     0.6498    0.08158     0.83\n",
      "NOTE:    128   256   0.0001            1.525     0.4951    0.08158     0.83\n",
      "NOTE:    129   256   0.0001            1.576     0.5376    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.589     0.5547    0.08158     0.82\n",
      "NOTE:    131   256   0.0001            1.547     0.4999    0.08158     0.83\n",
      "NOTE:    132   256   0.0001            1.612     0.6477    0.08158     0.87\n",
      "NOTE:    133   256   0.0001            1.599     0.6231    0.08158     0.84\n",
      "NOTE:    134   256   0.0001            1.599     0.5989    0.08158     0.83\n",
      "NOTE:    135   256   0.0001            1.633     0.6586    0.08158     0.84\n",
      "NOTE:    136   256   0.0001            1.609     0.6098    0.08158     0.82\n",
      "NOTE:    137   256   0.0001            1.554     0.5417    0.08158     0.82\n",
      "NOTE:    138   256   0.0001            1.592     0.5987    0.08158     0.88\n",
      "NOTE:    139   256   0.0001            1.546     0.5171    0.08158     0.82\n",
      "NOTE:    140   256   0.0001            1.554     0.5327    0.08158     0.83\n",
      "NOTE:    141   256   0.0001            1.606     0.5838    0.08158     0.83\n",
      "NOTE:    142   256   0.0001            1.564     0.5824    0.08158     0.82\n",
      "NOTE:    143   256   0.0001            1.585     0.5837    0.08158     0.82\n",
      "NOTE:    144   256   0.0001            1.534     0.5497    0.08158     0.83\n",
      "NOTE:    145   256   0.0001            1.574     0.5612    0.08158     0.83\n",
      "NOTE:    146   256   0.0001            1.523     0.5285    0.08158     0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    147   256   0.0001            1.596     0.5913    0.08158     0.88\n",
      "NOTE:    148   256   0.0001            1.575     0.5588    0.08158     0.82\n",
      "NOTE:    149   256   0.0001            1.584     0.5706    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.587     0.6258    0.08158     0.87\n",
      "NOTE:    151   256   0.0001            1.526     0.5086    0.08158     0.84\n",
      "NOTE:    152   256   0.0001            1.582     0.5329    0.08158     0.83\n",
      "NOTE:    153   256   0.0001            1.537     0.5026    0.08158     0.83\n",
      "NOTE:    154   256   0.0001            1.558     0.5399    0.08158     0.83\n",
      "NOTE:    155   256   0.0001            1.619     0.5933    0.08158     0.83\n",
      "NOTE:    156   256   0.0001            1.541     0.5328    0.08158     0.82\n",
      "NOTE:    157   256   0.0001            1.555      0.527    0.08158     0.82\n",
      "NOTE:    158   256   0.0001            1.535     0.5314    0.08158     0.82\n",
      "NOTE:    159   256   0.0001            1.576     0.5582    0.08158     0.82\n",
      "NOTE:    160   256   0.0001            1.621     0.6171    0.08158     0.82\n",
      "NOTE:    161   256   0.0001            1.517     0.5059    0.08158     0.82\n",
      "NOTE:    162   256   0.0001            1.559     0.5507    0.08158     0.83\n",
      "NOTE:    163   256   0.0001            1.578      0.548    0.08158     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  12       0.0001           1.597     0.5685   136.27\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.546     0.5268    0.08158     0.83\n",
      "NOTE:      1   256   0.0001            1.606      0.635    0.08158     0.83\n",
      "NOTE:      2   256   0.0001            1.509      0.463    0.08158     0.83\n",
      "NOTE:      3   256   0.0001            1.571     0.5646    0.08158     0.82\n",
      "NOTE:      4   256   0.0001            1.567     0.5542    0.08158     0.89\n",
      "NOTE:      5   256   0.0001            1.538     0.5128    0.08158     0.83\n",
      "NOTE:      6   256   0.0001            1.601     0.6023    0.08158     0.82\n",
      "NOTE:      7   256   0.0001            1.602     0.6434    0.08158     0.82\n",
      "NOTE:      8   256   0.0001            1.579     0.6044    0.08158     0.82\n",
      "NOTE:      9   256   0.0001            1.593     0.6422    0.08158     0.83\n",
      "NOTE:     10   256   0.0001            1.555     0.5959    0.08158     0.82\n",
      "NOTE:     11   256   0.0001            1.484       0.46    0.08158     0.82\n",
      "NOTE:     12   256   0.0001            1.594     0.6333    0.08158     0.90\n",
      "NOTE:     13   256   0.0001            1.557     0.5449    0.08158     0.84\n",
      "NOTE:     14   256   0.0001            1.551     0.5493    0.08158     0.88\n",
      "NOTE:     15   256   0.0001            1.535     0.5324    0.08158     0.83\n",
      "NOTE:     16   256   0.0001            1.561     0.5995    0.08158     0.82\n",
      "NOTE:     17   256   0.0001            1.513     0.5662    0.08158     0.81\n",
      "NOTE:     18   256   0.0001            1.527     0.5137    0.08158     0.84\n",
      "NOTE:     19   256   0.0001            1.485     0.4595    0.08158     0.84\n",
      "NOTE:     20   256   0.0001            1.567     0.5411    0.08158     0.91\n",
      "NOTE:     21   256   0.0001            1.517     0.5436    0.08158     0.89\n",
      "NOTE:     22   256   0.0001             1.51     0.4908    0.08158     0.89\n",
      "NOTE:     23   256   0.0001            1.604     0.6639    0.08158     0.84\n",
      "NOTE:     24   256   0.0001            1.533      0.555    0.08158     0.83\n",
      "NOTE:     25   256   0.0001            1.557     0.5973    0.08158     0.83\n",
      "NOTE:     26   256   0.0001            1.519     0.4896    0.08158     0.82\n",
      "NOTE:     27   256   0.0001            1.576     0.6308    0.08158     0.82\n",
      "NOTE:     28   256   0.0001            1.513     0.4908    0.08158     0.82\n",
      "NOTE:     29   256   0.0001            1.502     0.5369    0.08158     0.83\n",
      "NOTE:     30   256   0.0001            1.553      0.554    0.08158     0.84\n",
      "NOTE:     31   256   0.0001            1.532     0.5318    0.08158     0.82\n",
      "NOTE:     32   256   0.0001            1.532     0.5826    0.08158     0.83\n",
      "NOTE:     33   256   0.0001            1.531     0.5663    0.08158     0.82\n",
      "NOTE:     34   256   0.0001            1.567     0.5741    0.08158     0.82\n",
      "NOTE:     35   256   0.0001            1.511      0.536    0.08158     0.82\n",
      "NOTE:     36   256   0.0001            1.547     0.5337    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.516     0.5336    0.08158     0.84\n",
      "NOTE:     38   256   0.0001            1.532     0.5804    0.08158     0.82\n",
      "NOTE:     39   256   0.0001            1.496     0.4696    0.08158     0.82\n",
      "NOTE:     40   256   0.0001            1.577     0.6045    0.08158     0.93\n",
      "NOTE:     41   256   0.0001            1.522     0.5448    0.08158     0.99\n",
      "NOTE:     42   256   0.0001            1.522      0.551    0.08158     0.91\n",
      "NOTE:     43   256   0.0001            1.541     0.5599    0.08158     0.83\n",
      "NOTE:     44   256   0.0001            1.553     0.5886    0.08158     0.82\n",
      "NOTE:     45   256   0.0001            1.529      0.539    0.08158     0.82\n",
      "NOTE:     46   256   0.0001            1.502     0.5297    0.08158     0.83\n",
      "NOTE:     47   256   0.0001            1.528     0.5044    0.08158     0.83\n",
      "NOTE:     48   256   0.0001            1.573     0.6143    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.555     0.5455    0.08158     0.82\n",
      "NOTE:     50   256   0.0001            1.491     0.5025    0.08158     0.82\n",
      "NOTE:     51   256   0.0001            1.501     0.5093    0.08158     0.83\n",
      "NOTE:     52   256   0.0001            1.549     0.5358    0.08158     0.82\n",
      "NOTE:     53   256   0.0001            1.557     0.6221    0.08158     0.85\n",
      "NOTE:     54   256   0.0001            1.583     0.6476    0.08158     0.88\n",
      "NOTE:     55   256   0.0001            1.499     0.5188    0.08158     0.88\n",
      "NOTE:     56   256   0.0001            1.502      0.552    0.08158     0.88\n",
      "NOTE:     57   256   0.0001            1.512     0.5049    0.08158     0.83\n",
      "NOTE:     58   256   0.0001            1.478     0.5014    0.08158     0.82\n",
      "NOTE:     59   256   0.0001            1.543      0.555    0.08158     0.82\n",
      "NOTE:     60   256   0.0001            1.532     0.5328    0.08158     0.82\n",
      "NOTE:     61   256   0.0001            1.547     0.5656    0.08158     0.87\n",
      "NOTE:     62   256   0.0001            1.536     0.5668    0.08158     0.82\n",
      "NOTE:     63   256   0.0001            1.594     0.6311    0.08158     0.82\n",
      "NOTE:     64   256   0.0001            1.509     0.5015    0.08158     0.83\n",
      "NOTE:     65   256   0.0001            1.585     0.6454    0.08158     0.84\n",
      "NOTE:     66   256   0.0001            1.484     0.4814    0.08158     0.83\n",
      "NOTE:     67   256   0.0001             1.52     0.5518    0.08158     0.82\n",
      "NOTE:     68   256   0.0001             1.55     0.5727    0.08158     0.83\n",
      "NOTE:     69   256   0.0001            1.541     0.5483    0.08158     0.81\n",
      "NOTE:     70   256   0.0001            1.545      0.584    0.08158     0.89\n",
      "NOTE:     71   256   0.0001             1.58     0.6025    0.08158     0.82\n",
      "NOTE:     72   256   0.0001            1.588     0.6422    0.08158     0.82\n",
      "NOTE:     73   256   0.0001             1.55     0.5784    0.08158     0.83\n",
      "NOTE:     74   256   0.0001            1.477     0.5313    0.08158     0.82\n",
      "NOTE:     75   256   0.0001            1.518     0.5532    0.08158     0.83\n",
      "NOTE:     76   256   0.0001            1.604     0.6923    0.08158     0.90\n",
      "NOTE:     77   256   0.0001            1.522     0.5877    0.08158     0.85\n",
      "NOTE:     78   256   0.0001            1.562     0.5872    0.08158     0.82\n",
      "NOTE:     79   256   0.0001            1.556     0.5769    0.08158     0.83\n",
      "NOTE:     80   256   0.0001            1.566     0.5934    0.08158     0.83\n",
      "NOTE:     81   256   0.0001            1.601     0.6572    0.08158     0.82\n",
      "NOTE:     82   256   0.0001            1.491     0.5276    0.08158     0.83\n",
      "NOTE:     83   256   0.0001            1.558     0.6022    0.08158     0.87\n",
      "NOTE:     84   256   0.0001            1.515     0.5972    0.08158     0.82\n",
      "NOTE:     85   256   0.0001            1.547     0.6071    0.08158     0.82\n",
      "NOTE:     86   256   0.0001             1.54     0.5703    0.08158     0.82\n",
      "NOTE:     87   256   0.0001            1.559     0.5982    0.08158     0.82\n",
      "NOTE:     88   256   0.0001            1.483     0.5047    0.08158     0.82\n",
      "NOTE:     89   256   0.0001            1.497     0.5392    0.08158     0.82\n",
      "NOTE:     90   256   0.0001            1.469     0.4635    0.08158     0.87\n",
      "NOTE:     91   256   0.0001            1.579     0.6161    0.08158     0.82\n",
      "NOTE:     92   256   0.0001             1.54     0.5542    0.08158     0.87\n",
      "NOTE:     93   256   0.0001            1.589      0.658    0.08158     0.82\n",
      "NOTE:     94   256   0.0001            1.522      0.541    0.08158     0.82\n",
      "NOTE:     95   256   0.0001            1.537     0.5589    0.08158     0.82\n",
      "NOTE:     96   256   0.0001            1.478     0.5305    0.08158     0.84\n",
      "NOTE:     97   256   0.0001            1.578     0.6666    0.08158     0.83\n",
      "NOTE:     98   256   0.0001            1.433     0.4066    0.08158     0.81\n",
      "NOTE:     99   256   0.0001            1.488      0.555    0.08158     0.83\n",
      "NOTE:    100   256   0.0001            1.453     0.5001    0.08158     0.90\n",
      "NOTE:    101   256   0.0001            1.503     0.5649    0.08158     0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:    102   256   0.0001            1.494     0.5428    0.08158     0.83\n",
      "NOTE:    103   256   0.0001            1.464     0.5397    0.08158     0.83\n",
      "NOTE:    104   256   0.0001            1.497     0.5541    0.08158     0.83\n",
      "NOTE:    105   256   0.0001            1.532     0.5336    0.08158     0.82\n",
      "NOTE:    106   256   0.0001             1.55     0.5934    0.08158     0.82\n",
      "NOTE:    107   256   0.0001            1.511     0.5156    0.08158     0.82\n",
      "NOTE:    108   256   0.0001            1.506     0.6467    0.08158     0.82\n",
      "NOTE:    109   256   0.0001            1.528     0.5542    0.08158     0.82\n",
      "NOTE:    110   256   0.0001             1.54      0.568    0.08158     0.86\n",
      "NOTE:    111   256   0.0001            1.527     0.6283    0.08158     0.87\n",
      "NOTE:    112   256   0.0001            1.392     0.4028    0.08158     0.82\n",
      "NOTE:    113   256   0.0001            1.526     0.5949    0.08158     0.82\n",
      "NOTE:    114   256   0.0001            1.539     0.6122    0.08158     0.89\n",
      "NOTE:    115   256   0.0001            1.479      0.541    0.08158     0.89\n",
      "NOTE:    116   256   0.0001            1.499     0.5563    0.08158     0.83\n",
      "NOTE:    117   256   0.0001            1.526     0.6274    0.08158     0.84\n",
      "NOTE:    118   256   0.0001            1.502     0.5487    0.08158     0.83\n",
      "NOTE:    119   256   0.0001            1.522     0.6035    0.08158     0.82\n",
      "NOTE:    120   256   0.0001            1.501     0.5191    0.08158     0.83\n",
      "NOTE:    121   256   0.0001            1.533     0.5497    0.08158     0.83\n",
      "NOTE:    122   256   0.0001            1.528     0.5689    0.08158     0.83\n",
      "NOTE:    123   256   0.0001            1.522     0.6131    0.08158     0.82\n",
      "NOTE:    124   256   0.0001             1.49     0.5237    0.08158     0.83\n",
      "NOTE:    125   256   0.0001            1.513     0.5949    0.08158     0.91\n",
      "NOTE:    126   256   0.0001            1.495     0.5781    0.08158     0.87\n",
      "NOTE:    127   256   0.0001            1.482     0.5169    0.08158     0.88\n",
      "NOTE:    128   256   0.0001            1.467     0.5296    0.08158     0.83\n",
      "NOTE:    129   256   0.0001            1.483     0.5761    0.08158     0.82\n",
      "NOTE:    130   256   0.0001            1.471     0.4972    0.08158     0.84\n",
      "NOTE:    131   256   0.0001            1.503     0.5415    0.08158     0.84\n",
      "NOTE:    132   256   0.0001            1.517     0.5473    0.08158     0.83\n",
      "NOTE:    133   256   0.0001            1.533     0.5945    0.08158     0.83\n",
      "NOTE:    134   256   0.0001            1.439     0.4868    0.08158     0.83\n",
      "NOTE:    135   256   0.0001            1.478     0.5789    0.08158     0.83\n",
      "NOTE:    136   256   0.0001            1.492      0.592    0.08158     0.83\n",
      "NOTE:    137   256   0.0001            1.488     0.5565    0.08158     0.82\n",
      "NOTE:    138   256   0.0001            1.459     0.5242    0.08158     0.83\n",
      "NOTE:    139   256   0.0001            1.432     0.5553    0.08158     0.86\n",
      "NOTE:    140   256   0.0001            1.495      0.562    0.08158     0.82\n",
      "NOTE:    141   256   0.0001            1.519     0.5811    0.08158     0.82\n",
      "NOTE:    142   256   0.0001            1.449     0.5074    0.08158     0.83\n",
      "NOTE:    143   256   0.0001             1.49     0.5523    0.08158     0.83\n",
      "NOTE:    144   256   0.0001            1.431     0.5244    0.08158     0.83\n",
      "NOTE:    145   256   0.0001            1.434     0.5373    0.08158     0.83\n",
      "NOTE:    146   256   0.0001            1.471     0.5596    0.08158     0.84\n",
      "NOTE:    147   256   0.0001            1.497     0.5759    0.08158     0.87\n",
      "NOTE:    148   256   0.0001            1.484     0.6104    0.08158     0.84\n",
      "NOTE:    149   256   0.0001            1.478     0.5814    0.08158     0.83\n",
      "NOTE:    150   256   0.0001            1.513     0.5664    0.08158     0.83\n",
      "NOTE:    151   256   0.0001            1.494     0.5692    0.08158     0.82\n",
      "NOTE:    152   256   0.0001            1.503     0.5693    0.08158     0.83\n",
      "NOTE:    153   256   0.0001            1.453     0.4871    0.08158     0.88\n",
      "NOTE:    154   256   0.0001            1.436     0.4792    0.08158     0.83\n",
      "NOTE:    155   256   0.0001            1.372     0.4589    0.08158     0.83\n",
      "NOTE:    156   256   0.0001            1.501     0.5962    0.08158     0.83\n",
      "NOTE:    157   256   0.0001            1.483     0.5539    0.08158     0.83\n",
      "NOTE:    158   256   0.0001            1.485     0.5864    0.08158     0.90\n",
      "NOTE:    159   256   0.0001            1.387     0.4843    0.08158     0.97\n",
      "NOTE:    160   256   0.0001            1.457     0.5519    0.08158     0.97\n",
      "NOTE:    161   256   0.0001            1.483     0.5422    0.08158     0.97\n",
      "NOTE:    162   256   0.0001            1.454     0.6111    0.08158     0.90\n",
      "NOTE:    163   256   0.0001            1.481     0.6048    0.08158     0.81\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  13       0.0001           1.519     0.5588   138.00\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0   256   0.0001            1.515     0.6708    0.08158     0.82\n",
      "NOTE:      1   256   0.0001            1.498     0.6416    0.08158     0.82\n",
      "NOTE:      2   256   0.0001            1.482     0.6098    0.08158     0.82\n",
      "NOTE:      3   256   0.0001             1.47     0.5473    0.08158     0.82\n",
      "NOTE:      4   256   0.0001            1.444     0.5348    0.08158     0.82\n",
      "NOTE:      5   256   0.0001            1.454     0.5722    0.08158     0.82\n",
      "NOTE:      6   256   0.0001             1.41      0.562    0.08158     0.82\n",
      "NOTE:      7   256   0.0001            1.447     0.5343    0.08158     0.82\n",
      "NOTE:      8   256   0.0001             1.47     0.5329    0.08158     0.87\n",
      "NOTE:      9   256   0.0001            1.405     0.4789    0.08158     0.82\n",
      "NOTE:     10   256   0.0001            1.469     0.5209    0.08158     0.82\n",
      "NOTE:     11   256   0.0001            1.487     0.6219    0.08158     0.82\n",
      "NOTE:     12   256   0.0001            1.444     0.5736    0.08158     0.82\n",
      "NOTE:     13   256   0.0001            1.511     0.6026    0.08158     0.82\n",
      "NOTE:     14   256   0.0001            1.374     0.5224    0.08158     0.82\n",
      "NOTE:     15   256   0.0001             1.45     0.6304    0.08158     0.86\n",
      "NOTE:     16   256   0.0001            1.391     0.5037    0.08158     0.82\n",
      "NOTE:     17   256   0.0001            1.433     0.5467    0.08158     0.82\n",
      "NOTE:     18   256   0.0001            1.445     0.5013    0.08158     0.90\n",
      "NOTE:     19   256   0.0001            1.392     0.4975    0.08158     0.87\n",
      "NOTE:     20   256   0.0001            1.481     0.6027    0.08158     0.83\n",
      "NOTE:     21   256   0.0001             1.48     0.6157    0.08158     0.83\n",
      "NOTE:     22   256   0.0001             1.45      0.575    0.08158     0.83\n",
      "NOTE:     23   256   0.0001            1.476     0.6558    0.08158     0.83\n",
      "NOTE:     24   256   0.0001            1.475     0.6121    0.08158     0.84\n",
      "NOTE:     25   256   0.0001            1.444      0.534    0.08158     0.91\n",
      "NOTE:     26   256   0.0001            1.415     0.5789    0.08158     0.86\n",
      "NOTE:     27   256   0.0001            1.481     0.6781    0.08158     0.87\n",
      "NOTE:     28   256   0.0001            1.447     0.6237    0.08158     0.83\n",
      "NOTE:     29   256   0.0001            1.431      0.583    0.08158     0.83\n",
      "NOTE:     30   256   0.0001            1.443     0.5783    0.08158     0.83\n",
      "NOTE:     31   256   0.0001            1.449     0.6082    0.08158     0.83\n",
      "NOTE:     32   256   0.0001            1.395     0.5133    0.08158     0.84\n",
      "NOTE:     33   256   0.0001            1.504     0.6544    0.08158     0.83\n",
      "NOTE:     34   256   0.0001            1.437     0.5248    0.08158     0.83\n",
      "NOTE:     35   256   0.0001            1.416     0.5295    0.08158     0.83\n",
      "NOTE:     36   256   0.0001            1.479     0.6263    0.08158     0.83\n",
      "NOTE:     37   256   0.0001            1.406     0.5445    0.08158     0.83\n",
      "NOTE:     38   256   0.0001            1.411     0.5035    0.08158     0.83\n",
      "NOTE:     39   256   0.0001            1.402     0.5043    0.08158     0.83\n",
      "NOTE:     40   256   0.0001            1.434     0.5536    0.08158     0.83\n",
      "NOTE:     41   256   0.0001            1.436     0.5883    0.08158     0.82\n",
      "NOTE:     42   256   0.0001            1.413     0.4815    0.08158     0.82\n",
      "NOTE:     43   256   0.0001            1.411     0.5681    0.08158     0.87\n",
      "NOTE:     44   256   0.0001            1.367     0.5263    0.08158     0.81\n",
      "NOTE:     45   256   0.0001             1.43     0.5942    0.08158     0.83\n",
      "NOTE:     46   256   0.0001            1.443     0.5898    0.08158     0.83\n",
      "NOTE:     47   256   0.0001            1.442     0.5835    0.08158     0.82\n",
      "NOTE:     48   256   0.0001            1.441      0.601    0.08158     0.83\n",
      "NOTE:     49   256   0.0001            1.388     0.5862    0.08158     0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:     50   256   0.0001            1.374     0.5437    0.08158     0.83\n",
      "NOTE:     51   256   0.0001            1.418     0.5319    0.08158     0.83\n",
      "NOTE:     52   256   0.0001            1.418     0.5805    0.08158     0.83\n",
      "NOTE:     53   256   0.0001            1.479     0.6415    0.08158     0.83\n",
      "NOTE:     54   256   0.0001            1.397     0.5297    0.08159     0.82\n",
      "NOTE:     55   256   0.0001            1.503     0.7284    0.08159     0.82\n",
      "NOTE:     56   256   0.0001            1.351     0.5181    0.08159     0.83\n",
      "NOTE:     57   256   0.0001            1.408     0.5933    0.08159     0.83\n",
      "NOTE:     58   256   0.0001            1.433     0.5146    0.08159     0.82\n",
      "NOTE:     59   256   0.0001            1.419     0.5737    0.08159     0.83\n",
      "NOTE:     60   256   0.0001            1.485     0.5863    0.08159     0.82\n",
      "NOTE:     61   256   0.0001            1.381       0.56    0.08159     0.83\n",
      "NOTE:     62   256   0.0001            1.447     0.6925    0.08159     0.83\n",
      "NOTE:     63   256   0.0001            1.348      0.501    0.08159     0.83\n",
      "NOTE:     64   256   0.0001            1.405     0.5197    0.08159     0.83\n",
      "NOTE:     65   256   0.0001            1.391     0.4894    0.08159     0.82\n",
      "NOTE:     66   256   0.0001            1.363     0.5003    0.08159     0.82\n",
      "NOTE:     67   256   0.0001            1.431     0.5943    0.08159     0.83\n",
      "NOTE:     68   256   0.0001            1.472     0.6958    0.08159     0.82\n",
      "NOTE:     69   256   0.0001            1.411      0.559    0.08159     0.82\n",
      "NOTE:     70   256   0.0001            1.406       0.57    0.08159     0.83\n",
      "NOTE:     71   256   0.0001            1.487     0.6329    0.08159     0.82\n",
      "NOTE:     72   256   0.0001            1.434     0.6547    0.08159     0.82\n",
      "NOTE:     73   256   0.0001            1.456       0.54    0.08159     0.83\n",
      "NOTE:     74   256   0.0001            1.462     0.6283    0.08159     0.83\n",
      "NOTE:     75   256   0.0001            1.464     0.6878    0.08159     0.82\n",
      "NOTE:     76   256   0.0001            1.392      0.606    0.08159     0.82\n",
      "NOTE:     77   256   0.0001            1.423     0.6082    0.08159     0.82\n",
      "NOTE:     78   256   0.0001            1.399      0.621    0.08159     0.82\n",
      "NOTE:     79   256   0.0001            1.447     0.6437    0.08159     0.83\n",
      "NOTE:     80   256   0.0001            1.434      0.596    0.08159     0.82\n",
      "NOTE:     81   256   0.0001            1.453     0.6463    0.08159     0.82\n",
      "NOTE:     82   256   0.0001            1.425     0.5556    0.08159     0.82\n",
      "NOTE:     83   256   0.0001            1.444     0.6311    0.08159     0.83\n",
      "NOTE:     84   256   0.0001            1.393     0.5978    0.08159     0.83\n",
      "NOTE:     85   256   0.0001            1.428     0.5544    0.08159     0.82\n",
      "NOTE:     86   256   0.0001            1.412     0.6055    0.08159     0.83\n",
      "NOTE:     87   256   0.0001            1.366     0.5679    0.08159     0.82\n",
      "NOTE:     88   256   0.0001            1.388     0.5533    0.08159     0.82\n",
      "NOTE:     89   256   0.0001            1.393     0.6046    0.08159     0.82\n",
      "NOTE:     90   256   0.0001            1.358     0.5591    0.08159     0.82\n",
      "NOTE:     91   256   0.0001            1.403     0.6065    0.08159     0.83\n",
      "NOTE:     92   256   0.0001            1.374     0.5555    0.08159     0.82\n",
      "NOTE:     93   256   0.0001            1.452     0.6986    0.08159     0.82\n",
      "NOTE:     94   256   0.0001             1.41     0.6237    0.08159     0.82\n",
      "NOTE:     95   256   0.0001            1.385     0.5646    0.08159     0.82\n",
      "NOTE:     96   256   0.0001            1.408      0.602    0.08159     0.86\n",
      "NOTE:     97   256   0.0001            1.491      0.749    0.08159     0.84\n",
      "NOTE:     98   256   0.0001            1.356     0.5068    0.08159     0.83\n",
      "NOTE:     99   256   0.0001            1.353     0.6248    0.08159     0.83\n",
      "NOTE:    100   256   0.0001            1.358     0.5689    0.08159     0.84\n",
      "NOTE:    101   256   0.0001            1.392     0.5128    0.08159     0.82\n",
      "NOTE:    102   256   0.0001            1.375      0.655    0.08159     0.82\n",
      "NOTE:    103   256   0.0001            1.523     0.6666    0.08159     0.83\n",
      "NOTE:    104   256   0.0001            1.344     0.5627    0.08159     0.83\n",
      "NOTE:    105   256   0.0001            1.453     0.7083    0.08159     0.83\n",
      "NOTE:    106   256   0.0001            1.371     0.6097    0.08159     0.82\n",
      "NOTE:    107   256   0.0001            1.321     0.4857    0.08159     0.82\n",
      "NOTE:    108   256   0.0001            1.449     0.6695    0.08159     0.87\n",
      "NOTE:    109   256   0.0001             1.37     0.6233    0.08159     0.81\n",
      "NOTE:    110   256   0.0001            1.458     0.6763    0.08159     0.82\n",
      "NOTE:    111   256   0.0001              1.4     0.5309    0.08159     0.83\n",
      "NOTE:    112   256   0.0001            1.443     0.6729    0.08159     0.82\n",
      "NOTE:    113   256   0.0001            1.441     0.6227    0.08159     0.82\n",
      "NOTE:    114   256   0.0001            1.316     0.5079    0.08159     0.83\n",
      "NOTE:    115   256   0.0001            1.368     0.6164    0.08159     0.82\n",
      "NOTE:    116   256   0.0001            1.451     0.6979    0.08159     0.82\n",
      "NOTE:    117   256   0.0001            1.481     0.7638    0.08159     0.83\n",
      "NOTE:    118   256   0.0001            1.434       0.61    0.08159     0.83\n",
      "NOTE:    119   256   0.0001            1.361     0.5875    0.08159     0.82\n",
      "NOTE:    120   256   0.0001            1.369     0.6376    0.08159     0.83\n",
      "NOTE:    121   256   0.0001            1.431      0.646    0.08159     0.82\n",
      "NOTE:    122   256   0.0001            1.431     0.6368    0.08159     0.84\n",
      "NOTE:    123   256   0.0001            1.417      0.689    0.08159     0.81\n",
      "NOTE:    124   256   0.0001            1.347     0.5979    0.08159     0.83\n",
      "NOTE:    125   256   0.0001            1.382     0.6131    0.08159     0.87\n",
      "NOTE:    126   256   0.0001            1.444     0.6192    0.08159     0.83\n",
      "NOTE:    127   256   0.0001            1.387     0.6107    0.08159     0.83\n",
      "NOTE:    128   256   0.0001            1.319     0.5653    0.08159     0.83\n",
      "NOTE:    129   256   0.0001            1.341     0.5524    0.08159     0.83\n",
      "NOTE:    130   256   0.0001            1.402      0.668    0.08159     0.82\n",
      "NOTE:    131   256   0.0001            1.372     0.6212    0.08159     0.82\n",
      "NOTE:    132   256   0.0001            1.355     0.5256    0.08159     0.83\n",
      "NOTE:    133   256   0.0001            1.429     0.6039    0.08159     0.82\n",
      "NOTE:    134   256   0.0001             1.46     0.6433    0.08159     0.82\n",
      "NOTE:    135   256   0.0001            1.403     0.6697    0.08159     0.89\n",
      "NOTE:    136   256   0.0001            1.379     0.6083    0.08159     0.86\n",
      "NOTE:    137   256   0.0001            1.378     0.6341    0.08159     0.83\n",
      "NOTE:    138   256   0.0001            1.421     0.6667    0.08159     0.83\n",
      "NOTE:    139   256   0.0001            1.434     0.6255    0.08159     0.83\n",
      "NOTE:    140   256   0.0001            1.399     0.6357    0.08159     0.83\n",
      "NOTE:    141   256   0.0001            1.419     0.6255    0.08159     0.83\n",
      "NOTE:    142   256   0.0001            1.419     0.6394    0.08159     0.83\n",
      "NOTE:    143   256   0.0001            1.358      0.532    0.08159     0.84\n",
      "NOTE:    144   256   0.0001            1.362     0.5675    0.08159     0.83\n",
      "NOTE:    145   256   0.0001            1.404     0.6323    0.08159     0.83\n",
      "NOTE:    146   256   0.0001            1.408     0.6577    0.08159     0.82\n",
      "NOTE:    147   256   0.0001             1.41     0.6948    0.08159     0.84\n",
      "NOTE:    148   256   0.0001            1.415     0.7251    0.08159     0.83\n",
      "NOTE:    149   256   0.0001            1.339     0.5732    0.08159     0.83\n",
      "NOTE:    150   256   0.0001            1.425     0.7669    0.08159     0.83\n",
      "NOTE:    151   256   0.0001            1.423     0.7493    0.08159     0.82\n",
      "NOTE:    152   256   0.0001             1.41     0.6097    0.08159     0.89\n",
      "NOTE:    153   256   0.0001            1.377     0.6433    0.08159     0.83\n",
      "NOTE:    154   256   0.0001             1.38     0.6253    0.08159     0.82\n",
      "NOTE:    155   256   0.0001            1.326     0.5743    0.08159     0.83\n",
      "NOTE:    156   256   0.0001            1.405     0.6693    0.08159     0.82\n",
      "NOTE:    157   256   0.0001            1.407     0.7393    0.08159     0.82\n",
      "NOTE:    158   256   0.0001             1.38     0.6857    0.08159     0.87\n",
      "NOTE:    159   256   0.0001            1.389     0.6573    0.08159     0.84\n",
      "NOTE:    160   256   0.0001            1.404     0.5892    0.08159     0.82\n",
      "NOTE:    161   256   0.0001            1.306     0.5701    0.08159     0.82\n",
      "NOTE:    162   256   0.0001            1.361     0.6625    0.08159     0.83\n",
      "NOTE:    163   256   0.0001            1.366      0.677    0.08159     0.82\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  14       0.0001           1.416     0.6004   136.22\n",
      "NOTE:  The optimization reached the maximum number of epochs.\n",
      "NOTE:  The total time is    2044.85 (s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Name</td>\n",
       "      <td>model_jclygw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Type</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of Layers</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Input Layers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of Output Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of Convolutional Layers</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Pooling Layers</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Fully Connected Layers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Concatenation Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of FCMP Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of Weight Parameters</td>\n",
       "      <td>415296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Number of Bias Parameters</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total Number of Model Parameters</td>\n",
       "      <td>416112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Approximate Memory Cost for Training (MB)</td>\n",
       "      <td>3274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OptIterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch\">Epoch</th>\n",
       "      <th title=\"LearningRate\">LearningRate</th>\n",
       "      <th title=\"Loss\">Loss</th>\n",
       "      <th title=\"FitError\">FitError</th>\n",
       "      <th title=\"L2Norm\">L2Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.901207</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.081580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.892461</td>\n",
       "      <td>0.823505</td>\n",
       "      <td>0.081579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.881454</td>\n",
       "      <td>0.807543</td>\n",
       "      <td>0.081578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.870138</td>\n",
       "      <td>0.790104</td>\n",
       "      <td>0.081577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.856126</td>\n",
       "      <td>0.769079</td>\n",
       "      <td>0.081576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.840621</td>\n",
       "      <td>0.748006</td>\n",
       "      <td>0.081575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.820467</td>\n",
       "      <td>0.722865</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.793745</td>\n",
       "      <td>0.691079</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.765965</td>\n",
       "      <td>0.664392</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.730607</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.694883</td>\n",
       "      <td>0.608725</td>\n",
       "      <td>0.081575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.652881</td>\n",
       "      <td>0.585819</td>\n",
       "      <td>0.081576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.596851</td>\n",
       "      <td>0.568535</td>\n",
       "      <td>0.081578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.518518</td>\n",
       "      <td>0.558795</td>\n",
       "      <td>0.081581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.416102</td>\n",
       "      <td>0.600361</td>\n",
       "      <td>0.081586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(weshiz)</td>\n",
       "      <td>Model_jcLygW_weights</td>\n",
       "      <td>416112</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('Model_jcLygW_weights', caslib='CASUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 2.05e+03s</span> &#183; <span class=\"cas-user\">user 1.58e+04s</span> &#183; <span class=\"cas-sys\">sys 41.9s</span> &#183; <span class=\"cas-memory\">mem 3.3e+03MB</span></small></p>"
      ],
      "text/plain": [
       "[ModelInfo]\n",
       "\n",
       "                                         Descr                         Value\n",
       " 0                                  Model Name                  model_jclygw\n",
       " 1                                  Model Type  Convolutional Neural Network\n",
       " 2                            Number of Layers                            33\n",
       " 3                      Number of Input Layers                             3\n",
       " 4                     Number of Output Layers                             1\n",
       " 5              Number of Convolutional Layers                            12\n",
       " 6                    Number of Pooling Layers                            12\n",
       " 7            Number of Fully Connected Layers                             3\n",
       " 8              Number of Concatenation Layers                             1\n",
       " 9                       Number of FCMP Layers                             1\n",
       " 10                Number of Weight Parameters                        415296\n",
       " 11                  Number of Bias Parameters                           816\n",
       " 12           Total Number of Model Parameters                        416112\n",
       " 13  Approximate Memory Cost for Training (MB)                          3274\n",
       "\n",
       "[OptIterHistory]\n",
       "\n",
       "     Epoch  LearningRate      Loss  FitError    L2Norm\n",
       " 0       1        0.0001  1.901207  0.837104  0.081580\n",
       " 1       2        0.0001  1.892461  0.823505  0.081579\n",
       " 2       3        0.0001  1.881454  0.807543  0.081578\n",
       " 3       4        0.0001  1.870138  0.790104  0.081577\n",
       " 4       5        0.0001  1.856126  0.769079  0.081576\n",
       " 5       6        0.0001  1.840621  0.748006  0.081575\n",
       " 6       7        0.0001  1.820467  0.722865  0.081574\n",
       " 7       8        0.0001  1.793745  0.691079  0.081574\n",
       " 8       9        0.0001  1.765965  0.664392  0.081574\n",
       " 9      10        0.0001  1.730607  0.630438  0.081574\n",
       " 10     11        0.0001  1.694883  0.608725  0.081575\n",
       " 11     12        0.0001  1.652881  0.585819  0.081576\n",
       " 12     13        0.0001  1.596851  0.568535  0.081578\n",
       " 13     14        0.0001  1.518518  0.558795  0.081581\n",
       " 14     15        0.0001  1.416102  0.600361  0.081586\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                  Name    Rows  Columns  \\\n",
       " 0  CASUSER(weshiz)  Model_jcLygW_weights  416112        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('Model_jcLygW_weights', caslib='CASUS...  \n",
       "\n",
       "+ Elapsed: 2.05e+03s, user: 1.58e+04s, sys: 41.9s, mem: 3.3e+03mb"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_model.fit(data='Arsenal_CSKAMoskow_2018_04_05_triplet_sample',\n",
    "                  optimizer=optimizer,\n",
    "                  n_threads=8,\n",
    "                  data_specs=[{'type':'IMAGE', 'layer':'input_layer_00', 'data':'_image_'},\n",
    "                              {'type':'IMAGE', 'layer':'input_layer_01', 'data':'_image1_'},\n",
    "                              {'type':'IMAGE', 'layer':'input_layer_02', 'data':'_image2_'},\n",
    "                              {'type':'numericnominal', 'layer':'outputLayer_1', 'data':'isSelected'}\n",
    "                             ]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ScoreInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>41788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>41788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Squared Error</td>\n",
       "      <td>0.640536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loss Error</td>\n",
       "      <td>1.35596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 22.7s</span> &#183; <span class=\"cas-user\">user 1.41e+03s</span> &#183; <span class=\"cas-sys\">sys 25.4s</span> &#183; <span class=\"cas-memory\">mem 4.88e+03MB</span></small></p>"
      ],
      "text/plain": [
       "[ScoreInfo]\n",
       "\n",
       "                          Descr         Value\n",
       " 0  Number of Observations Read         41788\n",
       " 1  Number of Observations Used         41788\n",
       " 2           Mean Squared Error      0.640536\n",
       " 3                   Loss Error       1.35596\n",
       "\n",
       "+ Elapsed: 22.7s, user: 1.41e+03s, sys: 25.4s, mem: 4.88e+03mb"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.dlscore(modelTable=triplet_model.model_name,\n",
    "          table=dict(name='Arsenal_CSKAMoskow_2018_04_05_triplet_sample', where='_id_ > 1001204.0'),\n",
    "          initweights=triplet_model.model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Look at a branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Input layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Convolution layer added.\n",
      "NOTE: Pooling layer added.\n",
      "NOTE: Fully-connected layer added.\n",
      "NOTE: Output layer added.\n",
      "NOTE: Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(s, model_table='Simple_CNN')\n",
    "model.add(InputLayer(3, 48, 96, scale=1.0/255, random_mutation='none'))\n",
    "model.add(Conv2d(64, 7, include_bias=True, act='identity'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2))\n",
    "model.add(Conv2d(64, 3,include_bias=True, act='relu'))\n",
    "model.add(Pooling(2)) # 3, 6\n",
    "model.add(Dense(16))\n",
    "model.add(OutputLayer(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Id</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Type</th>\n",
       "      <th>Kernel Size</th>\n",
       "      <th>Stride</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Output Size</th>\n",
       "      <th>Number of Parameters</th>\n",
       "      <th>FLOPS(forward pass)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Input1</td>\n",
       "      <td>input</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>(96, 48, 3)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Convo.1</td>\n",
       "      <td>convo</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Identity</td>\n",
       "      <td>(96, 48, 64)</td>\n",
       "      <td>(9408, 64)</td>\n",
       "      <td>43352064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pool1</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>Max</td>\n",
       "      <td>(48, 24, 64)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Convo.2</td>\n",
       "      <td>convo</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Relu</td>\n",
       "      <td>(48, 24, 64)</td>\n",
       "      <td>(36864, 64)</td>\n",
       "      <td>42467328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pool2</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>Max</td>\n",
       "      <td>(24, 12, 64)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Convo.3</td>\n",
       "      <td>convo</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Relu</td>\n",
       "      <td>(24, 12, 64)</td>\n",
       "      <td>(36864, 64)</td>\n",
       "      <td>10616832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Pool3</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>Max</td>\n",
       "      <td>(12, 6, 64)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Convo.4</td>\n",
       "      <td>convo</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Relu</td>\n",
       "      <td>(12, 6, 64)</td>\n",
       "      <td>(36864, 64)</td>\n",
       "      <td>2654208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Pool4</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>Max</td>\n",
       "      <td>(6, 3, 64)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>F.C.1</td>\n",
       "      <td>fc</td>\n",
       "      <td>(1152, 16)</td>\n",
       "      <td></td>\n",
       "      <td>Relu</td>\n",
       "      <td>16</td>\n",
       "      <td>(18432, 0)</td>\n",
       "      <td>18432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Output1</td>\n",
       "      <td>output</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Softmax</td>\n",
       "      <td>3</td>\n",
       "      <td>(48, 3)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Total number of parameters</td>\n",
       "      <td>Total FLOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summary</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>138,739</td>\n",
       "      <td>99,108,864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer Id    Layer    Type Kernel Size  Stride Activation   Output Size  \\\n",
       "0         0   Input1   input                           None   (96, 48, 3)   \n",
       "1         1  Convo.1   convo      (7, 7)  (1, 1)   Identity  (96, 48, 64)   \n",
       "2         2    Pool1    pool      (2, 2)  (2, 2)        Max  (48, 24, 64)   \n",
       "3         3  Convo.2   convo      (3, 3)  (1, 1)       Relu  (48, 24, 64)   \n",
       "4         4    Pool2    pool      (2, 2)  (2, 2)        Max  (24, 12, 64)   \n",
       "5         5  Convo.3   convo      (3, 3)  (1, 1)       Relu  (24, 12, 64)   \n",
       "6         6    Pool3    pool      (2, 2)  (2, 2)        Max   (12, 6, 64)   \n",
       "7         7  Convo.4   convo      (3, 3)  (1, 1)       Relu   (12, 6, 64)   \n",
       "8         8    Pool4    pool      (2, 2)  (2, 2)        Max    (6, 3, 64)   \n",
       "9         9    F.C.1      fc  (1152, 16)               Relu            16   \n",
       "10       10  Output1  output                        Softmax             3   \n",
       "11                                                                          \n",
       "12  Summary                                                                 \n",
       "\n",
       "          Number of Parameters FLOPS(forward pass)  \n",
       "0                       (0, 0)                   0  \n",
       "1                   (9408, 64)            43352064  \n",
       "2                       (0, 0)                   0  \n",
       "3                  (36864, 64)            42467328  \n",
       "4                       (0, 0)                   0  \n",
       "5                  (36864, 64)            10616832  \n",
       "6                       (0, 0)                   0  \n",
       "7                  (36864, 64)             2654208  \n",
       "8                       (0, 0)                   0  \n",
       "9                   (18432, 0)               18432  \n",
       "10                     (48, 3)                   0  \n",
       "11  Total number of parameters         Total FLOPS  \n",
       "12                     138,739          99,108,864  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageTable('ImageData_nzS3ra', where=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dlpy_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dlpy_tbl.append_where('_label_ not in (\"keeper_Arsenal\", \"keeper_CSKA\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The layer, output1, is not found in Model_jcLygW.\n",
      "WARNING: The layer, input1, is not found in Model_jcLygW.\n",
      "NOTE: Model weights attached successfully!\n"
     ]
    }
   ],
   "source": [
    "weight_tbl = WeightsTable(s, weights_tbl_name=triplet_model.model_weights, model_tbl_name=triplet_model.model_name)\n",
    "model.set_weights(weight_tbl) # inside the function, it should make a new weights table to check if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Due to data distribution, miniBatchSize has been limited to 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ScoreInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Misclassification Error (%)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loss Error</td>\n",
       "      <td>1.000215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(weshiz)</td>\n",
       "      <td>layerout</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>CASTable('layerout', caslib='CASUSER(weshiz)')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.0987s</span> &#183; <span class=\"cas-user\">user 0.208s</span> &#183; <span class=\"cas-sys\">sys 0.373s</span> &#183; <span class=\"cas-memory\">mem 554MB</span></small></p>"
      ],
      "text/plain": [
       "[ScoreInfo]\n",
       "\n",
       "                          Descr         Value\n",
       " 0  Number of Observations Read            25\n",
       " 1  Number of Observations Used            25\n",
       " 2  Misclassification Error (%)            48\n",
       " 3                   Loss Error      1.000215\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib      Name  Rows  Columns  \\\n",
       " 0  CASUSER(weshiz)  layerout    25       17   \n",
       " \n",
       "                                          casTable  \n",
       " 0  CASTable('layerout', caslib='CASUSER(weshiz)')  \n",
       "\n",
       "+ Elapsed: 0.0987s, user: 0.208s, sys: 0.373s, mem: 554mb"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.dlscore(modelTable=model.model_name, layerimagetype='wide', copyvars='_label_',\n",
    "          layers=['F.C.1'], layerout=dict(name='layerout', replace=1),\n",
    "          table=img_dlpy_tbl,\n",
    "          initweights=model.model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table LAYEROUT</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_label_\">_label_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_0_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_1_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_2_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_3_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_4_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_5_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_6_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_7_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_8_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_9_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_10_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_11_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_12_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_13_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_14_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_15_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.569590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.464571</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.864458</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.036013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.170826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288752</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050039</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.035257</td>\n",
       "      <td>0.187176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.209438</td>\n",
       "      <td>0.056442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521342</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270651</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.580013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.478945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.948102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333883</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.417804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.295639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.747417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650790</td>\n",
       "      <td>0.014119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275985</td>\n",
       "      <td>0.105784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.067595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331955</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361322</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.697638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.536376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.771208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735449</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.528359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.585917</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.906449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>referee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.078470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365861</td>\n",
       "      <td>0.016083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673743</td>\n",
       "      <td>0.037080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.604513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.829002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.488415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.214187</td>\n",
       "      <td>0.202637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.701430</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.606772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.339874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381082</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.837165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255254</td>\n",
       "      <td>0.077241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000949s</span> &#183; <span class=\"cas-user\">user 0.000932s</span> &#183; <span class=\"cas-memory\">mem 0.925MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table LAYEROUT\n",
       " \n",
       "     _label_  _LayerAct_9_0_0_0_  _LayerAct_9_0_0_1_  _LayerAct_9_0_0_2_  \\\n",
       " 0   Arsenal                 0.0                 0.0            1.569590   \n",
       " 1   Arsenal                 0.0                 0.0            1.036013   \n",
       " 2      CSKA                 0.0                 0.0            0.729846   \n",
       " 3   Arsenal                 0.0                 0.0            1.050039   \n",
       " 4      CSKA                 0.0                 0.0            0.626161   \n",
       " 5   Arsenal                 0.0                 0.0            1.580013   \n",
       " 6      CSKA                 0.0                 0.0            0.737747   \n",
       " 7   Arsenal                 0.0                 0.0            1.417804   \n",
       " 8      CSKA                 0.0                 0.0            0.884208   \n",
       " 9      CSKA                 0.0                 0.0            1.125029   \n",
       " 10     CSKA                 0.0                 0.0            0.813594   \n",
       " 11  Arsenal                 0.0                 0.0            1.697638   \n",
       " 12  Arsenal                 0.0                 0.0            1.528359   \n",
       " 13  referee                 0.0                 0.0            0.941163   \n",
       " 14     CSKA                 0.0                 0.0            0.798704   \n",
       " 15  Arsenal                 0.0                 0.0            1.604513   \n",
       " 16     CSKA                 0.0                 0.0            0.962096   \n",
       " 17  Arsenal                 0.0                 0.0            1.488415   \n",
       " 18  Arsenal                 0.0                 0.0            1.606772   \n",
       " 19     CSKA                 0.0                 0.0            0.816094   \n",
       " \n",
       "     _LayerAct_9_0_0_3_  _LayerAct_9_0_0_4_  _LayerAct_9_0_0_5_  \\\n",
       " 0             0.000000                 0.0            1.464571   \n",
       " 1             0.000000                 0.0            0.879660   \n",
       " 2             0.000000                 0.0            0.516105   \n",
       " 3             0.008319                 0.0            1.035257   \n",
       " 4             0.000000                 0.0            0.521342   \n",
       " 5             0.000000                 0.0            1.478945   \n",
       " 6             0.000000                 0.0            0.752314   \n",
       " 7             0.000000                 0.0            1.295639   \n",
       " 8             0.000000                 0.0            0.650790   \n",
       " 9             0.000000                 0.0            1.067595   \n",
       " 10            0.000000                 0.0            0.896408   \n",
       " 11            0.000000                 0.0            1.536376   \n",
       " 12            0.000000                 0.0            1.585917   \n",
       " 13            0.000000                 0.0            0.895765   \n",
       " 14            0.000000                 0.0            0.673743   \n",
       " 15            0.000000                 0.0            1.533758   \n",
       " 16            0.000000                 0.0            0.904529   \n",
       " 17            0.000000                 0.0            1.214187   \n",
       " 18            0.000000                 0.0            1.339874   \n",
       " 19            0.000000                 0.0            0.631521   \n",
       " \n",
       "     _LayerAct_9_0_0_6_  _LayerAct_9_0_0_7_  _LayerAct_9_0_0_8_  \\\n",
       " 0             0.029503                 0.0            1.864458   \n",
       " 1             0.000000                 0.0            1.170826   \n",
       " 2             0.000000                 0.0            0.839628   \n",
       " 3             0.187176                 0.0            1.209438   \n",
       " 4             0.001360                 0.0            0.661439   \n",
       " 5             0.000000                 0.0            1.948102   \n",
       " 6             0.000000                 0.0            0.946143   \n",
       " 7             0.000000                 0.0            1.747417   \n",
       " 8             0.014119                 0.0            0.982917   \n",
       " 9             0.000000                 0.0            1.366463   \n",
       " 10            0.000000                 0.0            0.955510   \n",
       " 11            0.000000                 0.0            1.771208   \n",
       " 12            0.037903                 0.0            1.906449   \n",
       " 13            0.020864                 0.0            1.078470   \n",
       " 14            0.037080                 0.0            0.866986   \n",
       " 15            0.000000                 0.0            1.829002   \n",
       " 16            0.000000                 0.0            1.048846   \n",
       " 17            0.202637                 0.0            1.701430   \n",
       " 18            0.000000                 0.0            1.788997   \n",
       " 19            0.000000                 0.0            0.837165   \n",
       " \n",
       "     _LayerAct_9_0_0_9_  _LayerAct_9_0_0_10_  _LayerAct_9_0_0_11_  \\\n",
       " 0             0.035721                  0.0             0.515458   \n",
       " 1             0.000000                  0.0             0.243007   \n",
       " 2             0.000000                  0.0             0.288752   \n",
       " 3             0.056442                  0.0             0.930271   \n",
       " 4             0.000000                  0.0             0.270651   \n",
       " 5             0.000000                  0.0             0.272020   \n",
       " 6             0.000000                  0.0             0.333883   \n",
       " 7             0.000000                  0.0             0.503250   \n",
       " 8             0.000000                  0.0             0.275985   \n",
       " 9             0.000000                  0.0             0.331955   \n",
       " 10            0.000000                  0.0             0.361322   \n",
       " 11            0.000000                  0.0             0.735449   \n",
       " 12            0.000000                  0.0             0.553017   \n",
       " 13            0.000000                  0.0             0.365861   \n",
       " 14            0.000000                  0.0             0.116925   \n",
       " 15            0.000000                  0.0             0.476929   \n",
       " 16            0.000000                  0.0             0.283829   \n",
       " 17            0.085557                  0.0             0.769974   \n",
       " 18            0.000000                  0.0             0.381082   \n",
       " 19            0.000000                  0.0             0.255254   \n",
       " \n",
       "     _LayerAct_9_0_0_12_  _LayerAct_9_0_0_13_  _LayerAct_9_0_0_14_  \\\n",
       " 0              0.000000                  0.0             0.000000   \n",
       " 1              0.000000                  0.0             0.000000   \n",
       " 2              0.111237                  0.0             0.000000   \n",
       " 3              0.000000                  0.0             0.000000   \n",
       " 4              0.035202                  0.0             0.000000   \n",
       " 5              0.000000                  0.0             0.000000   \n",
       " 6              0.016877                  0.0             0.000000   \n",
       " 7              0.000000                  0.0             0.000000   \n",
       " 8              0.105784                  0.0             0.000000   \n",
       " 9              0.028661                  0.0             0.000000   \n",
       " 10             0.012443                  0.0             0.000000   \n",
       " 11             0.005311                  0.0             0.000000   \n",
       " 12             0.000000                  0.0             0.000000   \n",
       " 13             0.016083                  0.0             0.000000   \n",
       " 14             0.000000                  0.0             0.010752   \n",
       " 15             0.000000                  0.0             0.000000   \n",
       " 16             0.000000                  0.0             0.000000   \n",
       " 17             0.000000                  0.0             0.000000   \n",
       " 18             0.023822                  0.0             0.000000   \n",
       " 19             0.077241                  0.0             0.000000   \n",
       " \n",
       "     _LayerAct_9_0_0_15_  \n",
       " 0              0.254296  \n",
       " 1              0.000000  \n",
       " 2              0.013935  \n",
       " 3              0.136564  \n",
       " 4              0.058840  \n",
       " 5              0.000000  \n",
       " 6              0.122780  \n",
       " 7              0.000000  \n",
       " 8              0.083682  \n",
       " 9              0.132426  \n",
       " 10             0.000000  \n",
       " 11             0.000000  \n",
       " 12             0.000000  \n",
       " 13             0.031721  \n",
       " 14             0.000000  \n",
       " 15             0.185032  \n",
       " 16             0.063714  \n",
       " 17             0.341295  \n",
       " 18             0.000000  \n",
       " 19             0.212616  \n",
       "\n",
       "+ Elapsed: 0.000949s, user: 0.000932s, mem: 0.925mb"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fetch('layerout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and check members of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Using SEED=1222693358.\n",
      "NOTE: Running for input data for K 3.\n",
      "NOTE: Clustering is finished. STOPVALUE is satisfied for STOPCRITERION=CLUSTER_CHANGE.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; outputSize</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>{'outputNObs': 25.0, 'outputNVars': 3}</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; NObs</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Number of Observations</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Type\">Type</th>\n",
       "      <th title=\"N\">N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Model Information</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"RowId\">RowId</th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Setting\">Setting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clustering_Algorithm</td>\n",
       "      <td>Clustering Algorithm</td>\n",
       "      <td>K-means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maximum_Iterations</td>\n",
       "      <td>Maximum Iterations</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stop_Criterion</td>\n",
       "      <td>Stop Criterion</td>\n",
       "      <td>Cluster Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop_Criterion_Value</td>\n",
       "      <td>Stop Criterion Value</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clusters</td>\n",
       "      <td>Clusters</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Initialization</td>\n",
       "      <td>Initialization</td>\n",
       "      <td>Forgy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Seed</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1222693358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Distance_For_Interval_Variables</td>\n",
       "      <td>Distance for Interval Variables</td>\n",
       "      <td>Euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Standardization</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Interval_Imputation</td>\n",
       "      <td>Interval Imputation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; DescStats</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Descriptive Statistics</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Variable\">Variable</th>\n",
       "      <th title=\"Mean\">Mean</th>\n",
       "      <th title=\"StdDev\">StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_LayerAct_9_0_0_0_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_LayerAct_9_0_0_1_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_LayerAct_9_0_0_2_</td>\n",
       "      <td>1.218442</td>\n",
       "      <td>0.385217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_LayerAct_9_0_0_3_</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_LayerAct_9_0_0_4_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_LayerAct_9_0_0_5_</td>\n",
       "      <td>1.122260</td>\n",
       "      <td>0.385466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_LayerAct_9_0_0_6_</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>0.054038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_LayerAct_9_0_0_7_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_LayerAct_9_0_0_8_</td>\n",
       "      <td>1.413008</td>\n",
       "      <td>0.463526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_LayerAct_9_0_0_9_</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.020935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_LayerAct_9_0_0_10_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_LayerAct_9_0_0_11_</td>\n",
       "      <td>0.411216</td>\n",
       "      <td>0.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_LayerAct_9_0_0_12_</td>\n",
       "      <td>0.020575</td>\n",
       "      <td>0.034748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>_LayerAct_9_0_0_13_</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>_LayerAct_9_0_0_14_</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>_LayerAct_9_0_0_15_</td>\n",
       "      <td>0.078813</td>\n",
       "      <td>0.094016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; WithinClusStats</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Within Cluster Statistics</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Variable\">Variable</th>\n",
       "      <th title=\"Cluster\">Cluster</th>\n",
       "      <th title=\"Mean\">Mean</th>\n",
       "      <th title=\"StdDev\">StdDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_LayerAct_9_0_0_0_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_LayerAct_9_0_0_1_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_LayerAct_9_0_0_2_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908608</td>\n",
       "      <td>0.159981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1.811716</td>\n",
       "      <td>0.155276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1.568566</td>\n",
       "      <td>0.081690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_LayerAct_9_0_0_3_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.002223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_LayerAct_9_0_0_4_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>_LayerAct_9_0_0_5_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831737</td>\n",
       "      <td>0.209526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1.756722</td>\n",
       "      <td>0.124241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1.433192</td>\n",
       "      <td>0.124006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_LayerAct_9_0_0_6_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.049765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.042635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>0.066395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>_LayerAct_9_0_0_7_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>_LayerAct_9_0_0_8_</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043768</td>\n",
       "      <td>0.216241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.114331</td>\n",
       "      <td>0.144752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1.831531</td>\n",
       "      <td>0.085734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>_LayerAct_9_0_0_9_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.015085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>0.029499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>_LayerAct_9_0_0_10_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>_LayerAct_9_0_0_11_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.203120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.672345</td>\n",
       "      <td>0.013296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.505864</td>\n",
       "      <td>0.166419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>_LayerAct_9_0_0_12_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.041275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.007917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>_LayerAct_9_0_0_13_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>_LayerAct_9_0_0_14_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.010744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>_LayerAct_9_0_0_15_</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071019</td>\n",
       "      <td>0.068287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.097718</td>\n",
       "      <td>0.041317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.086736</td>\n",
       "      <td>0.135867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ClusterSum</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Cluster Summary</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Cluster\">Cluster</th>\n",
       "      <th title=\"Frequency\">Frequency</th>\n",
       "      <th title=\"MinDist\">MinDist</th>\n",
       "      <th title=\"MaxDist\">MaxDist</th>\n",
       "      <th title=\"AvgDist\">AvgDist</th>\n",
       "      <th title=\"SSE\">SSE</th>\n",
       "      <th title=\"StdDeviation\">StdDeviation</th>\n",
       "      <th title=\"NearestClus\">NearestClus</th>\n",
       "      <th title=\"DBtwCentroids\">DBtwCentroids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.103240</td>\n",
       "      <td>0.711709</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>2.165764</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.206854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.179166</td>\n",
       "      <td>0.179166</td>\n",
       "      <td>0.179166</td>\n",
       "      <td>0.064201</td>\n",
       "      <td>0.179166</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.521354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.151712</td>\n",
       "      <td>0.490805</td>\n",
       "      <td>0.250349</td>\n",
       "      <td>0.648102</td>\n",
       "      <td>0.268349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.521354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ClusterCenters</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Cluster Centroids</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_ITERATION_\">_ITERATION_</th>\n",
       "      <th title=\"_CLUSTER_ID_\">_CLUSTER_ID_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_0_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_1_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_2_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_3_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_4_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_5_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_6_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_7_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_8_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_9_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_10_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_11_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_12_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_13_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_14_</th>\n",
       "      <th title=\"Output for Layer f.c.1\">_LayerAct_9_0_0_15_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908608</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831737</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.043768</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.071019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.811716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.756722</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.114331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.568566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.433192</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.831531</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505864</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.086736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; IterStats</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Iteration History</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"IterationNum\">IterationNum</th>\n",
       "      <th title=\"IterationSSE\">IterationSSE</th>\n",
       "      <th title=\"SSEChange\">SSEChange</th>\n",
       "      <th title=\"StopCriterion\">StopCriterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.519168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.878067</td>\n",
       "      <td>-0.6411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(weshiz)</td>\n",
       "      <td>cluster_results_test_u_data</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('cluster_results_test_u_data', caslib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.0249s</span> &#183; <span class=\"cas-user\">user 0.0245s</span> &#183; <span class=\"cas-sys\">sys 0.035s</span> &#183; <span class=\"cas-memory\">mem 169MB</span></small></p>"
      ],
      "text/plain": [
       "[outputSize]\n",
       "\n",
       " {'outputNObs': 25.0, 'outputNVars': 3}\n",
       "\n",
       "[NObs]\n",
       "\n",
       " Number of Observations\n",
       " \n",
       "                           Type     N\n",
       " 0  Number of Observations Read  25.0\n",
       " 1  Number of Observations Used  25.0\n",
       "\n",
       "[ModelInfo]\n",
       "\n",
       " Model Information\n",
       " \n",
       "                              RowId                        Parameter  \\\n",
       " 0             Clustering_Algorithm             Clustering Algorithm   \n",
       " 1               Maximum_Iterations               Maximum Iterations   \n",
       " 2                   Stop_Criterion                   Stop Criterion   \n",
       " 3             Stop_Criterion_Value             Stop Criterion Value   \n",
       " 4                         Clusters                         Clusters   \n",
       " 5                   Initialization                   Initialization   \n",
       " 6                             Seed                             Seed   \n",
       " 7  Distance_For_Interval_Variables  Distance for Interval Variables   \n",
       " 8                  Standardization                  Standardization   \n",
       " 9              Interval_Imputation              Interval Imputation   \n",
       " \n",
       "           Setting  \n",
       " 0         K-means  \n",
       " 1             100  \n",
       " 2  Cluster Change  \n",
       " 3               0  \n",
       " 4               3  \n",
       " 5           Forgy  \n",
       " 6      1222693358  \n",
       " 7       Euclidean  \n",
       " 8            None  \n",
       " 9            None  \n",
       "\n",
       "[DescStats]\n",
       "\n",
       " Descriptive Statistics\n",
       " \n",
       "                Variable      Mean    StdDev\n",
       " 0    _LayerAct_9_0_0_0_  0.000000  0.000000\n",
       " 1    _LayerAct_9_0_0_1_  0.000000  0.000000\n",
       " 2    _LayerAct_9_0_0_2_  1.218442  0.385217\n",
       " 3    _LayerAct_9_0_0_3_  0.000333  0.001664\n",
       " 4    _LayerAct_9_0_0_4_  0.000000  0.000000\n",
       " 5    _LayerAct_9_0_0_5_  1.122260  0.385466\n",
       " 6    _LayerAct_9_0_0_6_  0.023637  0.054038\n",
       " 7    _LayerAct_9_0_0_7_  0.000000  0.000000\n",
       " 8    _LayerAct_9_0_0_8_  1.413008  0.463526\n",
       " 9    _LayerAct_9_0_0_9_  0.007109  0.020935\n",
       " 10  _LayerAct_9_0_0_10_  0.000000  0.000000\n",
       " 11  _LayerAct_9_0_0_11_  0.411216  0.215054\n",
       " 12  _LayerAct_9_0_0_12_  0.020575  0.034748\n",
       " 13  _LayerAct_9_0_0_13_  0.000000  0.000000\n",
       " 14  _LayerAct_9_0_0_14_  0.001719  0.006710\n",
       " 15  _LayerAct_9_0_0_15_  0.078813  0.094016\n",
       "\n",
       "[WithinClusStats]\n",
       "\n",
       " Within Cluster Statistics\n",
       " \n",
       "                Variable  Cluster      Mean    StdDev\n",
       " 0    _LayerAct_9_0_0_0_        1  0.000000  0.000000\n",
       " 1                              2  0.000000  0.000000\n",
       " 2                              3  0.000000  0.000000\n",
       " 3    _LayerAct_9_0_0_1_        1  0.000000  0.000000\n",
       " 4                              2  0.000000  0.000000\n",
       " 5                              3  0.000000  0.000000\n",
       " 6    _LayerAct_9_0_0_2_        1  0.908608  0.159981\n",
       " 7                              2  1.811716  0.155276\n",
       " 8                              3  1.568566  0.081690\n",
       " 9    _LayerAct_9_0_0_3_        1  0.000594  0.002223\n",
       " 10                             2  0.000000  0.000000\n",
       " 11                             3  0.000000  0.000000\n",
       " 12   _LayerAct_9_0_0_4_        1  0.000000  0.000000\n",
       " 13                             2  0.000000  0.000000\n",
       " 14                             3  0.000000  0.000000\n",
       " 15   _LayerAct_9_0_0_5_        1  0.831737  0.209526\n",
       " 16                             2  1.756722  0.124241\n",
       " 17                             3  1.433192  0.124006\n",
       " 18   _LayerAct_9_0_0_6_        1  0.018614  0.049765\n",
       " 19                             2  0.030147  0.042635\n",
       " 20                             3  0.030005  0.066395\n",
       " 21   _LayerAct_9_0_0_7_        1  0.000000  0.000000\n",
       " 22                             2  0.000000  0.000000\n",
       " 23                             3  0.000000  0.000000\n",
       " 24   _LayerAct_9_0_0_8_        1  1.043768  0.216241\n",
       " 25                             2  2.114331  0.144752\n",
       " 26                             3  1.831531  0.085734\n",
       " 27   _LayerAct_9_0_0_9_        1  0.004032  0.015085\n",
       " 28                             2  0.000000  0.000000\n",
       " 29                             3  0.013475  0.029499\n",
       " 30  _LayerAct_9_0_0_10_        1  0.000000  0.000000\n",
       " 31                             2  0.000000  0.000000\n",
       " 32                             3  0.000000  0.000000\n",
       " 33  _LayerAct_9_0_0_11_        1  0.313066  0.203120\n",
       " 34                             2  0.672345  0.013296\n",
       " 35                             3  0.505864  0.166419\n",
       " 36  _LayerAct_9_0_0_12_        1  0.034660  0.041275\n",
       " 37                             2  0.000000  0.000000\n",
       " 38                             3  0.003237  0.007917\n",
       " 39  _LayerAct_9_0_0_13_        1  0.000000  0.000000\n",
       " 40                             2  0.000000  0.000000\n",
       " 41                             3  0.000000  0.000000\n",
       " 42  _LayerAct_9_0_0_14_        1  0.000768  0.002874\n",
       " 43                             2  0.000000  0.000000\n",
       " 44                             3  0.003581  0.010744\n",
       " 45  _LayerAct_9_0_0_15_        1  0.071019  0.068287\n",
       " 46                             2  0.097718  0.041317\n",
       " 47                             3  0.086736  0.135867\n",
       "\n",
       "[ClusterSum]\n",
       "\n",
       " Cluster Summary\n",
       " \n",
       "    Cluster  Frequency   MinDist   MaxDist   AvgDist       SSE  StdDeviation  \\\n",
       " 0        1       14.0  0.103240  0.711709  0.348730  2.165764      0.393316   \n",
       " 1        2        2.0  0.179166  0.179166  0.179166  0.064201      0.179166   \n",
       " 2        3        9.0  0.151712  0.490805  0.250349  0.648102      0.268349   \n",
       " \n",
       "    NearestClus  DBtwCentroids  \n",
       " 0          3.0       1.206854  \n",
       " 1          3.0       0.521354  \n",
       " 2          2.0       0.521354  \n",
       "\n",
       "[ClusterCenters]\n",
       "\n",
       " Cluster Centroids\n",
       " \n",
       "    _ITERATION_  _CLUSTER_ID_  _LayerAct_9_0_0_0_  _LayerAct_9_0_0_1_  \\\n",
       " 0          1.0           1.0                 0.0                 0.0   \n",
       " 1          1.0           2.0                 0.0                 0.0   \n",
       " 2          1.0           3.0                 0.0                 0.0   \n",
       " \n",
       "    _LayerAct_9_0_0_2_  _LayerAct_9_0_0_3_  _LayerAct_9_0_0_4_  \\\n",
       " 0            0.908608            0.000594                 0.0   \n",
       " 1            1.811716            0.000000                 0.0   \n",
       " 2            1.568566            0.000000                 0.0   \n",
       " \n",
       "    _LayerAct_9_0_0_5_  _LayerAct_9_0_0_6_  _LayerAct_9_0_0_7_  \\\n",
       " 0            0.831737            0.018614                 0.0   \n",
       " 1            1.756722            0.030147                 0.0   \n",
       " 2            1.433192            0.030005                 0.0   \n",
       " \n",
       "    _LayerAct_9_0_0_8_  _LayerAct_9_0_0_9_  _LayerAct_9_0_0_10_  \\\n",
       " 0            1.043768            0.004032                  0.0   \n",
       " 1            2.114331            0.000000                  0.0   \n",
       " 2            1.831531            0.013475                  0.0   \n",
       " \n",
       "    _LayerAct_9_0_0_11_  _LayerAct_9_0_0_12_  _LayerAct_9_0_0_13_  \\\n",
       " 0             0.313066             0.034660                  0.0   \n",
       " 1             0.672345             0.000000                  0.0   \n",
       " 2             0.505864             0.003237                  0.0   \n",
       " \n",
       "    _LayerAct_9_0_0_14_  _LayerAct_9_0_0_15_  \n",
       " 0             0.000768             0.071019  \n",
       " 1             0.000000             0.097718  \n",
       " 2             0.003581             0.086736  \n",
       "\n",
       "[IterStats]\n",
       "\n",
       " Iteration History\n",
       " \n",
       "    IterationNum  IterationSSE  SSEChange  StopCriterion\n",
       " 0             0      3.519168        NaN            NaN\n",
       " 1             1      2.878067    -0.6411            0.0\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                         Name Label  Rows  Columns  \\\n",
       " 0  CASUSER(weshiz)  cluster_results_test_u_data          25        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('cluster_results_test_u_data', caslib...  \n",
       "\n",
       "+ Elapsed: 0.0249s, user: 0.0245s, sys: 0.035s, mem: 169mb"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.kclus(table=dict(name='layerout'),\n",
    "        maxClusters=3, maxIters=100, \n",
    "        inputs=list(s.columninfo('layerout').ColumnInfo['Column'].values)[1:],\n",
    "        output=dict(casout=dict(name='cluster_results_test_u_data', replace=True),\n",
    "                    copyvars=['_label_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_label_\">_label_</th>\n",
       "      <th title=\"_CLUSTER_ID_\">_CLUSTER_ID_</th>\n",
       "      <th title=\"_DISTANCE_\">_DISTANCE_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.214917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.208978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.459485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.170965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>referee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.336848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>referee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CSKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000632s</span> &#183; <span class=\"cas-user\">user 0.000617s</span> &#183; <span class=\"cas-sys\">sys 3e-06s</span> &#183; <span class=\"cas-memory\">mem 1.18MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA\n",
       " \n",
       "     _label_  _CLUSTER_ID_  _DISTANCE_\n",
       " 0   Arsenal           1.0    0.214917\n",
       " 1      CSKA           1.0    0.428171\n",
       " 2   Arsenal           1.0    0.711709\n",
       " 3      CSKA           1.0    0.569701\n",
       " 4      CSKA           1.0    0.220963\n",
       " 5      CSKA           1.0    0.208978\n",
       " 6      CSKA           1.0    0.459485\n",
       " 7      CSKA           1.0    0.170965\n",
       " 8   referee           1.0    0.105179\n",
       " 9      CSKA           1.0    0.336848\n",
       " 10     CSKA           1.0    0.103240\n",
       " 11     CSKA           1.0    0.341905\n",
       " 12  referee           1.0    0.434373\n",
       " 13     CSKA           1.0    0.575793\n",
       "\n",
       "+ Elapsed: 0.000632s, user: 0.000617s, sys: 3e-06s, mem: 1.18mb"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fetch(table=dict(name='cluster_results_test_u_data', where='_cluster_id_ eq 1'), sastypes=False, to=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_label_\">_label_</th>\n",
       "      <th title=\"_CLUSTER_ID_\">_CLUSTER_ID_</th>\n",
       "      <th title=\"_DISTANCE_\">_DISTANCE_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.175376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.281291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.239501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.303771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.201415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.151712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.490805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.191283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.217991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00054s</span> &#183; <span class=\"cas-user\">user 0.000528s</span> &#183; <span class=\"cas-memory\">mem 1.17MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA\n",
       " \n",
       "    _label_  _CLUSTER_ID_  _DISTANCE_\n",
       " 0  Arsenal           3.0    0.175376\n",
       " 1  Arsenal           3.0    0.281291\n",
       " 2  Arsenal           3.0    0.239501\n",
       " 3  Arsenal           3.0    0.303771\n",
       " 4  Arsenal           3.0    0.201415\n",
       " 5  Arsenal           3.0    0.151712\n",
       " 6  Arsenal           3.0    0.490805\n",
       " 7  Arsenal           3.0    0.191283\n",
       " 8  Arsenal           3.0    0.217991\n",
       "\n",
       "+ Elapsed: 0.00054s, user: 0.000528s, mem: 1.17mb"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fetch(table=dict(name='cluster_results_test_u_data', where='_cluster_id_ eq 3'), sastypes=False, to=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"_label_\">_label_</th>\n",
       "      <th title=\"_CLUSTER_ID_\">_CLUSTER_ID_</th>\n",
       "      <th title=\"_DISTANCE_\">_DISTANCE_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.179166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.179166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000493s</span> &#183; <span class=\"cas-user\">user 0.000481s</span> &#183; <span class=\"cas-memory\">mem 1.17MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table CLUSTER_RESULTS_TEST_U_DATA\n",
       " \n",
       "    _label_  _CLUSTER_ID_  _DISTANCE_\n",
       " 0  Arsenal           2.0    0.179166\n",
       " 1  Arsenal           2.0    0.179166\n",
       "\n",
       "+ Elapsed: 0.000493s, user: 0.000481s, mem: 1.17mb"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fetch(table=dict(name='cluster_results_test_u_data', where='_cluster_id_ eq 2'), sastypes=False, to=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000115s</span> &#183; <span class=\"cas-user\">user 0.000104s</span> &#183; <span class=\"cas-sys\">sys 2e-06s</span> &#183; <span class=\"cas-memory\">mem 0.205MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.000115s, user: 0.000104s, sys: 2e-06s, mem: 0.205mb"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.endsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
